{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, kstwobign\n",
    "import time\n",
    "\n",
    "# the BDT framework I'll be using\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# helper functions to read in big data files\n",
    "from read_h5_chunk import read_file_in_chunks\n",
    "from mc_reader import MCReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for BDT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZTravel',\n",
       " 'eff_oneweight',\n",
       " 'COGZ',\n",
       " 'COGZSigma',\n",
       " 'RLogL',\n",
       " 'RecoZenith',\n",
       " 'QTot',\n",
       " 'LDir_A',\n",
       " 'NDirPulse_A',\n",
       " 'NDirDOM_A',\n",
       " 'NDirStr_A',\n",
       " 'LDir_B',\n",
       " 'NDirPulse_B',\n",
       " 'NDirDOM_B',\n",
       " 'NDirStr_B',\n",
       " 'LDir_C',\n",
       " 'NDirPulse_C',\n",
       " 'NDirStr_C',\n",
       " 'LDir_E',\n",
       " 'NDirPulse_E',\n",
       " 'NDirStr_E',\n",
       " 'RecoAngSep']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get outkeys\n",
    "all_keys = [\n",
    "              ('ZTravel',       '<f8'),\n",
    "              ('oneweight',     '<f8'),\n",
    "              ('eff_oneweight', '<f8'),\n",
    "              ('COGZ',          '<f8'),\n",
    "              ('COGZSigma',     '<f8'),\n",
    "              ('TrueEnergy',    '<f8'),\n",
    "              ('TrueZenith',    '<f8'),\n",
    "              ('TrueAzimuth',   '<f8'),\n",
    "              ('PrimaryType',   '<f8'),\n",
    "              ('RLogL',         '<f8'),\n",
    "              ('RecoAzimuth',   '<f8'),\n",
    "              ('RecoZenith',    '<f8'),\n",
    "              ('QTot',          '<f8'),\n",
    "              ('LDir_A',        '<f8'),\n",
    "              ('NDirPulse_A',   '<f8'),\n",
    "              ('NDirDOM_A',     '<f8'),\n",
    "              ('NDirStr_A',     '<f8'),\n",
    "              ('LDir_B',        '<f8'),\n",
    "              ('NDirPulse_B',   '<f8'),\n",
    "              ('NDirDOM_B',     '<f8'),\n",
    "              ('NDirStr_B',     '<f8'),\n",
    "              ('LDir_C',        '<f8'),\n",
    "              ('NDirPulse_C',   '<f8'),\n",
    "              ('NDirDOM_C',     '<f8'),\n",
    "              ('NDirStr_C',     '<f8'),\n",
    "              ('LDir_E',        '<f8'),\n",
    "              ('NDirPulse_E',   '<f8'),\n",
    "              ('NDirDOM_E',     '<f8'),\n",
    "              ('NDirStr_E',     '<f8'),\n",
    "              ('RecoAngSep',    '<f8'),\n",
    "              ('BayesRatio',    '<f8')\n",
    "             ]\n",
    "\n",
    "dropkeys = ['oneweight', 'TrueEnergy', 'TrueZenith', 'TrueAzimuth', 'PrimaryType', 'RecoAzimuth', \n",
    "            'NDirDOM_C', 'NDirDOM_E', 'BayesRatio']\n",
    "\n",
    "outkeys = [key for key, _ in all_keys if key not in dropkeys]\n",
    "outkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macros\n",
    "thin = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# read in fluxes\n",
    "conv_flux_nancy_path = '../../../jlazar/solar/data/mc_dn_dz/sibyll23c_conv_l3_b_nancy_merged_holeice-0300_2.npy'\n",
    "solar_flux_nancy_path = '../../../jlazar/solar/data/mc_dn_dz/SIBYLL2.3_pp_HillasGaisser_H4a_l3_b_nancy_merged_holeice-0300_2.npy'\n",
    "conv_flux_genie_path = '../../../jlazar/solar/data/mc_dn_dz/sibyll23c_conv_l3_b_genie_merged_holeice-0300_2.npy'\n",
    "solar_flux_genie_path = '../../../jlazar/solar/data/mc_dn_dz/SIBYLL2.3_pp_HillasGaisser_H4a_l3_b_genie_merged_holeice-0300_2.npy'\n",
    "\n",
    "conv_flux_nancy = np.load(conv_flux_nancy_path)[::thin]\n",
    "solar_flux_nancy = np.load(solar_flux_nancy_path)[::thin]\n",
    "conv_flux_genie = np.load(conv_flux_genie_path)[::thin]\n",
    "solar_flux_genie = np.load(solar_flux_genie_path)[::thin]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genie...\n",
      "Finished in 0:07:22.568544\n"
     ]
    }
   ],
   "source": [
    "# load genie (3 min)\n",
    "print('genie...')\n",
    "genie_path = '../../../jlazar/big_files/solar_atmospherics/l3_b_genie_merged_holeice-0300_2.h5'\n",
    "start_time = time.time()\n",
    "genie = read_file_in_chunks(genie_path, outkeys, thin=thin)\n",
    "end_time = time.time()\n",
    "duration = timedelta(seconds=end_time-start_time)\n",
    "print('Finished in {0}'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nancy...\n",
      "Finished in 3:06:45.012539\n"
     ]
    }
   ],
   "source": [
    "# load nancy (1.5 hrs)\n",
    "print('nancy...')\n",
    "nancy_path = '../../../jlazar/big_files/solar_atmospherics/l3_b_nancy_merged_holeice-0300_2.h5'\n",
    "start_time = time.time()\n",
    "nancy = read_file_in_chunks(nancy_path, outkeys, thin=thin)\n",
    "end_time = time.time()\n",
    "duration = timedelta(seconds=end_time-start_time)\n",
    "print('Finished in {0}'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corsika...\n",
      "Finished in 2:30:14.927173\n"
     ]
    }
   ],
   "source": [
    "# load corsika\n",
    "print('corsika...')\n",
    "corsika_path = '../../../jlazar/big_files/solar_atmospherics/l3_b_corsika_merged_holeice-0300_2.h5'\n",
    "start_time = time.time()\n",
    "corsika = read_file_in_chunks(corsika_path, outkeys, thin=thin)\n",
    "end_time = time.time()\n",
    "duration = timedelta(seconds=end_time-start_time)\n",
    "print('Finished in {0}'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to particle-specific dataframes\n",
    "solar_df = pd.concat([pd.DataFrame(nancy), pd.DataFrame(genie)])\n",
    "conv_df = pd.concat([pd.DataFrame(nancy), pd.DataFrame(genie)])\n",
    "muon_df = pd.DataFrame(corsika)\n",
    "\n",
    "# total flux\n",
    "solar_flux = np.concatenate([solar_flux_nancy, solar_flux_genie])\n",
    "conv_flux = np.concatenate([conv_flux_nancy, conv_flux_genie])\n",
    "\n",
    "# normalized rate information\n",
    "muon_df['norm-rate'] = muon_df['eff_oneweight'].values / np.sum(muon_df['eff_oneweight'])\n",
    "solar_df['norm-rate'] = solar_df['eff_oneweight'] * solar_flux / np.sum(solar_df['eff_oneweight']*solar_flux)\n",
    "conv_df['norm-rate'] = conv_df['eff_oneweight'] * conv_flux / np.sum(conv_df['eff_oneweight']*conv_flux)\n",
    "\n",
    "# add in solar atmospheric info\n",
    "solar_df['solar'] = 1\n",
    "conv_df['solar'] = 0\n",
    "muon_df['solar'] = 0\n",
    "\n",
    "# add in muon info\n",
    "solar_df['muon'] = 0\n",
    "conv_df['muon'] = 0\n",
    "muon_df['muon'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2484596, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZTravel</th>\n",
       "      <th>COGZ</th>\n",
       "      <th>COGZSigma</th>\n",
       "      <th>RLogL</th>\n",
       "      <th>RecoZenith</th>\n",
       "      <th>QTot</th>\n",
       "      <th>LDir_A</th>\n",
       "      <th>NDirPulse_A</th>\n",
       "      <th>NDirDOM_A</th>\n",
       "      <th>NDirStr_A</th>\n",
       "      <th>...</th>\n",
       "      <th>LDir_C</th>\n",
       "      <th>NDirPulse_C</th>\n",
       "      <th>NDirStr_C</th>\n",
       "      <th>LDir_E</th>\n",
       "      <th>NDirPulse_E</th>\n",
       "      <th>NDirStr_E</th>\n",
       "      <th>RecoAngSep</th>\n",
       "      <th>norm-rate</th>\n",
       "      <th>solar</th>\n",
       "      <th>muon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.181664</td>\n",
       "      <td>195.756485</td>\n",
       "      <td>37.022224</td>\n",
       "      <td>33.874021</td>\n",
       "      <td>2.016922</td>\n",
       "      <td>9.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>111.748897</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.811024</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.185846e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.323990</td>\n",
       "      <td>-464.713231</td>\n",
       "      <td>33.373538</td>\n",
       "      <td>11.684740</td>\n",
       "      <td>2.099566</td>\n",
       "      <td>15.725</td>\n",
       "      <td>142.279987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.279987</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.073092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.526237e-04</td>\n",
       "      <td>4.625277e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.034170</td>\n",
       "      <td>-466.306037</td>\n",
       "      <td>52.105987</td>\n",
       "      <td>12.071475</td>\n",
       "      <td>1.492967</td>\n",
       "      <td>12.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.965718</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222.568092</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.484113e-01</td>\n",
       "      <td>1.171941e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.293069</td>\n",
       "      <td>-462.026478</td>\n",
       "      <td>37.073835</td>\n",
       "      <td>10.617668</td>\n",
       "      <td>2.625600</td>\n",
       "      <td>19.375</td>\n",
       "      <td>74.020239</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.686728</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.107589</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.590901e-02</td>\n",
       "      <td>8.185290e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.637226</td>\n",
       "      <td>-425.194122</td>\n",
       "      <td>75.872357</td>\n",
       "      <td>10.144056</td>\n",
       "      <td>2.269713</td>\n",
       "      <td>28.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.763115</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.394320e-01</td>\n",
       "      <td>1.411252e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.439992</td>\n",
       "      <td>-474.452936</td>\n",
       "      <td>31.537926</td>\n",
       "      <td>10.937935</td>\n",
       "      <td>1.453496</td>\n",
       "      <td>22.625</td>\n",
       "      <td>120.236210</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>124.219980</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>242.322049</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.945018e-02</td>\n",
       "      <td>3.551687e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.588457</td>\n",
       "      <td>-387.863182</td>\n",
       "      <td>72.942464</td>\n",
       "      <td>11.232186</td>\n",
       "      <td>2.029082</td>\n",
       "      <td>17.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.738085</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>235.151063</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.954435e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.496668</td>\n",
       "      <td>-467.580232</td>\n",
       "      <td>32.991506</td>\n",
       "      <td>14.477186</td>\n",
       "      <td>1.349810</td>\n",
       "      <td>11.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>124.079864</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>234.812807</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.199066e-02</td>\n",
       "      <td>2.247269e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68.273618</td>\n",
       "      <td>136.590663</td>\n",
       "      <td>84.983082</td>\n",
       "      <td>11.306642</td>\n",
       "      <td>2.348349</td>\n",
       "      <td>21.525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>509.381928</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.125655e-01</td>\n",
       "      <td>3.767076e-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.964165</td>\n",
       "      <td>-456.980061</td>\n",
       "      <td>33.340407</td>\n",
       "      <td>11.488908</td>\n",
       "      <td>2.330539</td>\n",
       "      <td>12.950</td>\n",
       "      <td>149.786888</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>149.786888</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>237.530890</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.201683e-02</td>\n",
       "      <td>1.049830e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-7.344993</td>\n",
       "      <td>-484.685493</td>\n",
       "      <td>17.024304</td>\n",
       "      <td>12.109609</td>\n",
       "      <td>1.648250</td>\n",
       "      <td>16.400</td>\n",
       "      <td>2.616102</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.024518</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>217.910123</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.386817e-01</td>\n",
       "      <td>1.880756e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.574668</td>\n",
       "      <td>-474.698666</td>\n",
       "      <td>30.627802</td>\n",
       "      <td>10.717739</td>\n",
       "      <td>1.493587</td>\n",
       "      <td>20.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.317259</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>321.195350</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.938398e-02</td>\n",
       "      <td>3.270500e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.958337</td>\n",
       "      <td>-351.053748</td>\n",
       "      <td>40.881539</td>\n",
       "      <td>13.911284</td>\n",
       "      <td>1.893010</td>\n",
       "      <td>10.350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>228.108420</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.621369</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.665568e-02</td>\n",
       "      <td>1.114231e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.866674</td>\n",
       "      <td>-485.911098</td>\n",
       "      <td>20.125995</td>\n",
       "      <td>12.806605</td>\n",
       "      <td>2.808304</td>\n",
       "      <td>16.650</td>\n",
       "      <td>32.166839</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.333677</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.749418</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.006518e-03</td>\n",
       "      <td>6.196713e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.724440</td>\n",
       "      <td>-463.907792</td>\n",
       "      <td>41.585590</td>\n",
       "      <td>13.637334</td>\n",
       "      <td>1.810289</td>\n",
       "      <td>8.275</td>\n",
       "      <td>4.132194</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.003245</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>171.384127</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.672764e-01</td>\n",
       "      <td>5.571175e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.157501</td>\n",
       "      <td>-487.617513</td>\n",
       "      <td>23.192410</td>\n",
       "      <td>17.428060</td>\n",
       "      <td>1.560412</td>\n",
       "      <td>7.850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>199.314033</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200.020976</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.615401e-02</td>\n",
       "      <td>2.820614e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20.533895</td>\n",
       "      <td>-460.845730</td>\n",
       "      <td>23.111774</td>\n",
       "      <td>14.287818</td>\n",
       "      <td>1.523360</td>\n",
       "      <td>8.850</td>\n",
       "      <td>123.762079</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201.640610</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>203.254753</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.425353e-02</td>\n",
       "      <td>7.650927e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20.743002</td>\n",
       "      <td>-478.255882</td>\n",
       "      <td>24.011283</td>\n",
       "      <td>12.387277</td>\n",
       "      <td>1.655011</td>\n",
       "      <td>14.750</td>\n",
       "      <td>4.328582</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>125.770396</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240.149573</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.575774e-03</td>\n",
       "      <td>7.874836e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.665336</td>\n",
       "      <td>-351.984015</td>\n",
       "      <td>69.600146</td>\n",
       "      <td>10.888071</td>\n",
       "      <td>1.982909</td>\n",
       "      <td>17.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.817296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.044164</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.963833e-04</td>\n",
       "      <td>1.620622e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-28.362950</td>\n",
       "      <td>-436.859655</td>\n",
       "      <td>63.375744</td>\n",
       "      <td>9.147536</td>\n",
       "      <td>1.310546</td>\n",
       "      <td>22.375</td>\n",
       "      <td>119.906083</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>280.104504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>527.482907</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.871181e-03</td>\n",
       "      <td>1.542208e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30.808965</td>\n",
       "      <td>-468.372936</td>\n",
       "      <td>55.626224</td>\n",
       "      <td>10.777843</td>\n",
       "      <td>2.298335</td>\n",
       "      <td>14.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.305727</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>273.862977</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.349358e-06</td>\n",
       "      <td>5.056482e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>47.028578</td>\n",
       "      <td>-314.055901</td>\n",
       "      <td>37.285253</td>\n",
       "      <td>21.865053</td>\n",
       "      <td>1.596630</td>\n",
       "      <td>7.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.305105</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.490116e-08</td>\n",
       "      <td>8.011030e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50.325621</td>\n",
       "      <td>-436.108328</td>\n",
       "      <td>75.262213</td>\n",
       "      <td>11.622851</td>\n",
       "      <td>2.054228</td>\n",
       "      <td>22.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.636397</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.226407e-01</td>\n",
       "      <td>7.153558e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.290013</td>\n",
       "      <td>-488.137570</td>\n",
       "      <td>14.779874</td>\n",
       "      <td>18.713459</td>\n",
       "      <td>2.131200</td>\n",
       "      <td>9.350</td>\n",
       "      <td>9.046621</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.093225</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.452505</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.177932e-02</td>\n",
       "      <td>1.064937e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-7.513850</td>\n",
       "      <td>-461.529063</td>\n",
       "      <td>40.870183</td>\n",
       "      <td>10.758955</td>\n",
       "      <td>1.693108</td>\n",
       "      <td>14.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>241.018041</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>318.624932</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.783977e-02</td>\n",
       "      <td>1.430052e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.413750</td>\n",
       "      <td>35.163990</td>\n",
       "      <td>29.714933</td>\n",
       "      <td>9.845879</td>\n",
       "      <td>1.385220</td>\n",
       "      <td>24.000</td>\n",
       "      <td>110.054555</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.618066</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.832043</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.589508e-02</td>\n",
       "      <td>9.795333e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15.759998</td>\n",
       "      <td>-465.133344</td>\n",
       "      <td>29.264951</td>\n",
       "      <td>13.698251</td>\n",
       "      <td>2.486082</td>\n",
       "      <td>21.550</td>\n",
       "      <td>26.984762</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.477131</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.069297</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.444699e-02</td>\n",
       "      <td>1.108388e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-6.099169</td>\n",
       "      <td>-460.295291</td>\n",
       "      <td>37.381993</td>\n",
       "      <td>12.055705</td>\n",
       "      <td>1.816040</td>\n",
       "      <td>11.575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.966372</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>332.117157</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.873597e-02</td>\n",
       "      <td>8.910105e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-14.128462</td>\n",
       "      <td>124.713173</td>\n",
       "      <td>40.922090</td>\n",
       "      <td>10.326207</td>\n",
       "      <td>1.448353</td>\n",
       "      <td>13.875</td>\n",
       "      <td>333.799180</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>337.956740</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>526.890386</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.636495e-02</td>\n",
       "      <td>2.006338e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27.140709</td>\n",
       "      <td>-457.975417</td>\n",
       "      <td>59.881486</td>\n",
       "      <td>10.731650</td>\n",
       "      <td>2.825719</td>\n",
       "      <td>20.450</td>\n",
       "      <td>64.711748</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.711748</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222.079710</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.028059e-01</td>\n",
       "      <td>7.775793e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20.529619</td>\n",
       "      <td>-469.705253</td>\n",
       "      <td>38.928039</td>\n",
       "      <td>9.728152</td>\n",
       "      <td>1.333493</td>\n",
       "      <td>21.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.229243</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>475.207924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.450778e-02</td>\n",
       "      <td>9.888695e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>22.139999</td>\n",
       "      <td>-406.214217</td>\n",
       "      <td>86.096859</td>\n",
       "      <td>10.986845</td>\n",
       "      <td>2.636078</td>\n",
       "      <td>16.950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.682416</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>262.179224</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.489299e-02</td>\n",
       "      <td>4.299954e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>28.690002</td>\n",
       "      <td>-479.686626</td>\n",
       "      <td>28.200323</td>\n",
       "      <td>33.149323</td>\n",
       "      <td>2.535236</td>\n",
       "      <td>7.850</td>\n",
       "      <td>27.971696</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.957532</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.705237</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.351976e-03</td>\n",
       "      <td>2.532827e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-1.000440</td>\n",
       "      <td>-442.651597</td>\n",
       "      <td>46.351407</td>\n",
       "      <td>11.473229</td>\n",
       "      <td>1.988314</td>\n",
       "      <td>17.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.826597</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.223961e-01</td>\n",
       "      <td>4.481368e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15.579990</td>\n",
       "      <td>-410.500025</td>\n",
       "      <td>74.755908</td>\n",
       "      <td>13.211676</td>\n",
       "      <td>2.540970</td>\n",
       "      <td>11.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>127.647078</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>273.211869</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.859149e-02</td>\n",
       "      <td>4.953462e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>22.667336</td>\n",
       "      <td>-465.782371</td>\n",
       "      <td>33.257374</td>\n",
       "      <td>11.245568</td>\n",
       "      <td>1.422805</td>\n",
       "      <td>26.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.698848</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.871894e-02</td>\n",
       "      <td>5.657214e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>31.784170</td>\n",
       "      <td>-469.739152</td>\n",
       "      <td>51.656775</td>\n",
       "      <td>10.273003</td>\n",
       "      <td>2.838071</td>\n",
       "      <td>24.050</td>\n",
       "      <td>129.945642</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>179.101114</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>257.816519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.981547e-01</td>\n",
       "      <td>2.008883e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.299989</td>\n",
       "      <td>-453.533298</td>\n",
       "      <td>25.101288</td>\n",
       "      <td>14.522321</td>\n",
       "      <td>1.755184</td>\n",
       "      <td>11.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>207.941063</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>428.265362</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.319812e-04</td>\n",
       "      <td>2.431658e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>27.131000</td>\n",
       "      <td>-441.722770</td>\n",
       "      <td>48.586166</td>\n",
       "      <td>12.965235</td>\n",
       "      <td>2.442139</td>\n",
       "      <td>13.450</td>\n",
       "      <td>39.070805</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>164.299037</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>237.261559</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.526872e-03</td>\n",
       "      <td>3.751768e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16.005709</td>\n",
       "      <td>141.701774</td>\n",
       "      <td>25.028126</td>\n",
       "      <td>19.434401</td>\n",
       "      <td>1.869681</td>\n",
       "      <td>11.575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.494374</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>207.642966</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.448973e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>54.926003</td>\n",
       "      <td>-410.891949</td>\n",
       "      <td>84.750390</td>\n",
       "      <td>12.444850</td>\n",
       "      <td>2.424589</td>\n",
       "      <td>11.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>262.574239</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>272.546712</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.147412e-02</td>\n",
       "      <td>9.281580e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>39.964095</td>\n",
       "      <td>-469.179679</td>\n",
       "      <td>33.499927</td>\n",
       "      <td>12.048013</td>\n",
       "      <td>2.737122</td>\n",
       "      <td>17.025</td>\n",
       "      <td>62.375255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.927225</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>158.876738</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.558776e-02</td>\n",
       "      <td>3.869795e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>49.821818</td>\n",
       "      <td>-441.361417</td>\n",
       "      <td>54.411860</td>\n",
       "      <td>11.791420</td>\n",
       "      <td>1.971071</td>\n",
       "      <td>24.675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>195.566865</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.739927e-05</td>\n",
       "      <td>2.703603e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.266249</td>\n",
       "      <td>-200.249901</td>\n",
       "      <td>27.839796</td>\n",
       "      <td>15.171049</td>\n",
       "      <td>1.976036</td>\n",
       "      <td>7.675</td>\n",
       "      <td>13.419909</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.663322</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>231.294055</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.196484e-01</td>\n",
       "      <td>4.370104e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>60.179990</td>\n",
       "      <td>-441.768688</td>\n",
       "      <td>65.395941</td>\n",
       "      <td>13.039414</td>\n",
       "      <td>2.530278</td>\n",
       "      <td>14.475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>263.942924</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>278.453732</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.504629e-02</td>\n",
       "      <td>3.388397e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.138186</td>\n",
       "      <td>-464.064219</td>\n",
       "      <td>30.273812</td>\n",
       "      <td>12.276700</td>\n",
       "      <td>1.684931</td>\n",
       "      <td>12.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>214.209931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>216.148280</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.686810e-02</td>\n",
       "      <td>1.165312e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>35.216048</td>\n",
       "      <td>-462.314762</td>\n",
       "      <td>40.968848</td>\n",
       "      <td>9.130207</td>\n",
       "      <td>2.125775</td>\n",
       "      <td>25.825</td>\n",
       "      <td>9.231718</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143.935375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>372.164630</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.232548e-02</td>\n",
       "      <td>2.449750e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>44.694444</td>\n",
       "      <td>-442.158144</td>\n",
       "      <td>64.379031</td>\n",
       "      <td>13.223942</td>\n",
       "      <td>2.040930</td>\n",
       "      <td>12.375</td>\n",
       "      <td>149.017298</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>149.017298</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>271.865368</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.429153e-02</td>\n",
       "      <td>6.586212e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>35.689163</td>\n",
       "      <td>-456.396783</td>\n",
       "      <td>43.898828</td>\n",
       "      <td>11.834764</td>\n",
       "      <td>2.211655</td>\n",
       "      <td>14.925</td>\n",
       "      <td>30.527967</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.460213</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>197.988973</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.073631e-02</td>\n",
       "      <td>9.923436e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>29.821251</td>\n",
       "      <td>-443.616173</td>\n",
       "      <td>65.602448</td>\n",
       "      <td>10.673380</td>\n",
       "      <td>2.172849</td>\n",
       "      <td>19.475</td>\n",
       "      <td>20.437818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132.726994</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>433.106084</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.338306e-02</td>\n",
       "      <td>2.674937e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ZTravel        COGZ  COGZSigma      RLogL  RecoZenith    QTot  \\\n",
       "0   16.181664  195.756485  37.022224  33.874021    2.016922   9.025   \n",
       "1   30.323990 -464.713231  33.373538  11.684740    2.099566  15.725   \n",
       "2   33.034170 -466.306037  52.105987  12.071475    1.492967  12.050   \n",
       "3   30.293069 -462.026478  37.073835  10.617668    2.625600  19.375   \n",
       "4   56.637226 -425.194122  75.872357  10.144056    2.269713  28.125   \n",
       "5   21.439992 -474.452936  31.537926  10.937935    1.453496  22.625   \n",
       "6   59.588457 -387.863182  72.942464  11.232186    2.029082  17.125   \n",
       "7    8.496668 -467.580232  32.991506  14.477186    1.349810  11.700   \n",
       "8   68.273618  136.590663  84.983082  11.306642    2.348349  21.525   \n",
       "9    8.964165 -456.980061  33.340407  11.488908    2.330539  12.950   \n",
       "10  -7.344993 -484.685493  17.024304  12.109609    1.648250  16.400   \n",
       "11  20.574668 -474.698666  30.627802  10.717739    1.493587  20.625   \n",
       "12  36.958337 -351.053748  40.881539  13.911284    1.893010  10.350   \n",
       "13   1.866674 -485.911098  20.125995  12.806605    2.808304  16.650   \n",
       "14  21.724440 -463.907792  41.585590  13.637334    1.810289   8.275   \n",
       "15  -2.157501 -487.617513  23.192410  17.428060    1.560412   7.850   \n",
       "16  20.533895 -460.845730  23.111774  14.287818    1.523360   8.850   \n",
       "17  20.743002 -478.255882  24.011283  12.387277    1.655011  14.750   \n",
       "18   9.665336 -351.984015  69.600146  10.888071    1.982909  17.875   \n",
       "19 -28.362950 -436.859655  63.375744   9.147536    1.310546  22.375   \n",
       "20  30.808965 -468.372936  55.626224  10.777843    2.298335  14.050   \n",
       "21  47.028578 -314.055901  37.285253  21.865053    1.596630   7.750   \n",
       "22  50.325621 -436.108328  75.262213  11.622851    2.054228  22.700   \n",
       "23   5.290013 -488.137570  14.779874  18.713459    2.131200   9.350   \n",
       "24  -7.513850 -461.529063  40.870183  10.758955    1.693108  14.900   \n",
       "25  13.413750   35.163990  29.714933   9.845879    1.385220  24.000   \n",
       "26  15.759998 -465.133344  29.264951  13.698251    2.486082  21.550   \n",
       "27  -6.099169 -460.295291  37.381993  12.055705    1.816040  11.575   \n",
       "28 -14.128462  124.713173  40.922090  10.326207    1.448353  13.875   \n",
       "29  27.140709 -457.975417  59.881486  10.731650    2.825719  20.450   \n",
       "30  20.529619 -469.705253  38.928039   9.728152    1.333493  21.375   \n",
       "31  22.139999 -406.214217  86.096859  10.986845    2.636078  16.950   \n",
       "32  28.690002 -479.686626  28.200323  33.149323    2.535236   7.850   \n",
       "33  -1.000440 -442.651597  46.351407  11.473229    1.988314  17.700   \n",
       "34  15.579990 -410.500025  74.755908  13.211676    2.540970  11.900   \n",
       "35  22.667336 -465.782371  33.257374  11.245568    1.422805  26.600   \n",
       "36  31.784170 -469.739152  51.656775  10.273003    2.838071  24.050   \n",
       "37   3.299989 -453.533298  25.101288  14.522321    1.755184  11.600   \n",
       "38  27.131000 -441.722770  48.586166  12.965235    2.442139  13.450   \n",
       "39  16.005709  141.701774  25.028126  19.434401    1.869681  11.575   \n",
       "40  54.926003 -410.891949  84.750390  12.444850    2.424589  11.275   \n",
       "41  39.964095 -469.179679  33.499927  12.048013    2.737122  17.025   \n",
       "42  49.821818 -441.361417  54.411860  11.791420    1.971071  24.675   \n",
       "43   2.266249 -200.249901  27.839796  15.171049    1.976036   7.675   \n",
       "44  60.179990 -441.768688  65.395941  13.039414    2.530278  14.475   \n",
       "45   7.138186 -464.064219  30.273812  12.276700    1.684931  12.800   \n",
       "46  35.216048 -462.314762  40.968848   9.130207    2.125775  25.825   \n",
       "47  44.694444 -442.158144  64.379031  13.223942    2.040930  12.375   \n",
       "48  35.689163 -456.396783  43.898828  11.834764    2.211655  14.925   \n",
       "49  29.821251 -443.616173  65.602448  10.673380    2.172849  19.475   \n",
       "\n",
       "        LDir_A  NDirPulse_A  NDirDOM_A  NDirStr_A  ...       LDir_C  \\\n",
       "0          NaN          1.0        1.0        1.0  ...   111.748897   \n",
       "1   142.279987          2.0        2.0        2.0  ...   142.279987   \n",
       "2          NaN          1.0        1.0        1.0  ...   109.965718   \n",
       "3    74.020239          3.0        3.0        1.0  ...   129.686728   \n",
       "4          NaN          0.0        0.0        0.0  ...          NaN   \n",
       "5   120.236210          3.0        3.0        2.0  ...   124.219980   \n",
       "6          NaN          1.0        1.0        1.0  ...   136.738085   \n",
       "7          NaN          1.0        1.0        1.0  ...   124.079864   \n",
       "8          NaN          0.0        0.0        0.0  ...          NaN   \n",
       "9   149.786888          3.0        3.0        2.0  ...   149.786888   \n",
       "10    2.616102          3.0        3.0        1.0  ...   112.024518   \n",
       "11         NaN          0.0        0.0        0.0  ...    69.317259   \n",
       "12         NaN          1.0        1.0        1.0  ...   228.108420   \n",
       "13   32.166839          4.0        2.0        1.0  ...    64.333677   \n",
       "14    4.132194          2.0        2.0        1.0  ...   120.003245   \n",
       "15         NaN          1.0        1.0        1.0  ...   199.314033   \n",
       "16  123.762079          2.0        2.0        2.0  ...   201.640610   \n",
       "17    4.328582          2.0        2.0        1.0  ...   125.770396   \n",
       "18         NaN          1.0        1.0        1.0  ...     6.817296   \n",
       "19  119.906083          3.0        2.0        2.0  ...   280.104504   \n",
       "20         NaN          1.0        1.0        1.0  ...   105.305727   \n",
       "21         NaN          1.0        1.0        1.0  ...          NaN   \n",
       "22         NaN          0.0        0.0        0.0  ...          NaN   \n",
       "23    9.046621          2.0        2.0        1.0  ...    18.093225   \n",
       "24         NaN          1.0        1.0        1.0  ...   241.018041   \n",
       "25  110.054555          4.0        4.0        2.0  ...   122.618066   \n",
       "26   26.984762          7.0        3.0        1.0  ...    40.477131   \n",
       "27         NaN          1.0        1.0        1.0  ...    24.966372   \n",
       "28  333.799180          4.0        2.0        2.0  ...   337.956740   \n",
       "29   64.711748          3.0        3.0        1.0  ...    64.711748   \n",
       "30         NaN          1.0        1.0        1.0  ...   121.229243   \n",
       "31         NaN          1.0        1.0        1.0  ...    44.682416   \n",
       "32   27.971696          3.0        2.0        1.0  ...    41.957532   \n",
       "33         NaN          0.0        0.0        0.0  ...          NaN   \n",
       "34         NaN          1.0        1.0        1.0  ...   127.647078   \n",
       "35         NaN          0.0        0.0        0.0  ...          NaN   \n",
       "36  129.945642          5.0        3.0        1.0  ...   179.101114   \n",
       "37         NaN          1.0        1.0        1.0  ...   207.941063   \n",
       "38   39.070805          3.0        2.0        1.0  ...   164.299037   \n",
       "39         NaN          1.0        1.0        1.0  ...   128.494374   \n",
       "40         NaN          1.0        1.0        1.0  ...   262.574239   \n",
       "41   62.375255          2.0        2.0        1.0  ...   110.927225   \n",
       "42         NaN          1.0        1.0        1.0  ...          NaN   \n",
       "43   13.419909          3.0        3.0        1.0  ...   121.663322   \n",
       "44         NaN          1.0        1.0        1.0  ...   263.942924   \n",
       "45         NaN          1.0        1.0        1.0  ...   214.209931   \n",
       "46    9.231718          2.0        2.0        1.0  ...   143.935375   \n",
       "47  149.017298          4.0        4.0        2.0  ...   149.017298   \n",
       "48   30.527967          2.0        2.0        1.0  ...   109.460213   \n",
       "49   20.437818          2.0        2.0        1.0  ...   132.726994   \n",
       "\n",
       "    NDirPulse_C  NDirStr_C      LDir_E  NDirPulse_E  NDirStr_E    RecoAngSep  \\\n",
       "0           2.0        2.0  155.811024          9.0        2.0  0.000000e+00   \n",
       "1           7.0        3.0  186.073092         15.0        4.0  5.526237e-04   \n",
       "2           2.0        2.0  222.568092         14.0        4.0  3.484113e-01   \n",
       "3           6.0        2.0  174.107589         23.0        3.0  9.590901e-02   \n",
       "4           0.0        0.0  295.763115         27.0        7.0  2.394320e-01   \n",
       "5           7.0        3.0  242.322049         23.0        6.0  3.945018e-02   \n",
       "6           3.0        2.0  235.151063         15.0        4.0           NaN   \n",
       "7           3.0        2.0  234.812807         12.0        5.0  5.199066e-02   \n",
       "8           1.0        1.0  509.381928         25.0       11.0  1.125655e-01   \n",
       "9           5.0        2.0  237.530890         14.0        5.0  5.201683e-02   \n",
       "10          9.0        3.0  217.910123         16.0        5.0  1.386817e-01   \n",
       "11          2.0        2.0  321.195350         23.0        8.0  5.938398e-02   \n",
       "12          3.0        3.0  258.621369         10.0        4.0  1.665568e-02   \n",
       "13          6.0        1.0  138.749418         16.0        5.0  8.006518e-03   \n",
       "14          5.0        2.0  171.384127          9.0        4.0  1.672764e-01   \n",
       "15          5.0        3.0  200.020976          8.0        4.0  1.615401e-02   \n",
       "16          7.0        4.0  203.254753         10.0        5.0  5.425353e-02   \n",
       "17          5.0        2.0  240.149573         16.0        6.0  9.575774e-03   \n",
       "18          2.0        1.0  354.044164         21.0        5.0  4.963833e-04   \n",
       "19          8.0        4.0  527.482907         25.0       11.0  9.871181e-03   \n",
       "20          4.0        2.0  273.862977         14.0        7.0  1.349358e-06   \n",
       "21          1.0        1.0  119.305105          8.0        3.0  1.490116e-08   \n",
       "22          1.0        1.0  232.636397         24.0        5.0  1.226407e-01   \n",
       "23          5.0        1.0  120.452505         12.0        3.0  8.177932e-02   \n",
       "24          7.0        3.0  318.624932         16.0        6.0  5.783977e-02   \n",
       "25         13.0        3.0  134.832043         24.0        6.0  6.589508e-02   \n",
       "26         14.0        1.0  129.069297         24.0        3.0  7.444699e-02   \n",
       "27          2.0        1.0  332.117157         13.0        7.0  1.873597e-02   \n",
       "28          8.0        4.0  526.890386         15.0        8.0  1.636495e-02   \n",
       "29          6.0        2.0  222.079710         18.0        6.0  1.028059e-01   \n",
       "30          3.0        2.0  475.207924         23.0       12.0  3.450778e-02   \n",
       "31          3.0        1.0  262.179224         16.0        4.0  2.489299e-02   \n",
       "32          5.0        1.0  121.705237          8.0        3.0  5.351976e-03   \n",
       "33          0.0        0.0  230.826597         20.0        7.0  3.223961e-01   \n",
       "34          2.0        2.0  273.211869         10.0        5.0  2.859149e-02   \n",
       "35          0.0        0.0  239.698848         36.0        5.0  8.871894e-02   \n",
       "36         12.0        1.0  257.816519         20.0        6.0  1.981547e-01   \n",
       "37          3.0        2.0  428.265362         14.0        6.0  2.319812e-04   \n",
       "38          7.0        2.0  237.261559         14.0        5.0  1.526872e-03   \n",
       "39          8.0        2.0  207.642966         13.0        3.0  0.000000e+00   \n",
       "40          5.0        3.0  272.546712         13.0        4.0  1.147412e-02   \n",
       "41          7.0        2.0  158.876738         19.0        4.0  4.558776e-02   \n",
       "42          1.0        1.0  195.566865         23.0        4.0  4.739927e-05   \n",
       "43          8.0        2.0  231.294055         15.0        4.0  3.196484e-01   \n",
       "44          3.0        3.0  278.453732         13.0        5.0  1.504629e-02   \n",
       "45          4.0        3.0  216.148280         14.0        4.0  7.686810e-02   \n",
       "46          7.0        2.0  372.164630         29.0       10.0  3.232548e-02   \n",
       "47          7.0        3.0  271.865368         13.0        4.0  3.429153e-02   \n",
       "48          3.0        2.0  197.988973         15.0        6.0  8.073631e-02   \n",
       "49          3.0        2.0  433.106084         19.0        7.0  8.338306e-02   \n",
       "\n",
       "       norm-rate  solar  muon  \n",
       "0   8.185846e-08      0     1  \n",
       "1   4.625277e-08      0     1  \n",
       "2   1.171941e-07      0     1  \n",
       "3   8.185290e-09      0     1  \n",
       "4   1.411252e-07      0     1  \n",
       "5   3.551687e-08      0     1  \n",
       "6   7.954435e-08      0     1  \n",
       "7   2.247269e-07      0     1  \n",
       "8   3.767076e-11      0     1  \n",
       "9   1.049830e-07      0     1  \n",
       "10  1.880756e-07      0     1  \n",
       "11  3.270500e-09      0     1  \n",
       "12  1.114231e-07      0     1  \n",
       "13  6.196713e-08      0     1  \n",
       "14  5.571175e-08      0     1  \n",
       "15  2.820614e-07      0     1  \n",
       "16  7.650927e-09      0     1  \n",
       "17  7.874836e-08      0     1  \n",
       "18  1.620622e-07      0     1  \n",
       "19  1.542208e-07      0     1  \n",
       "20  5.056482e-08      0     1  \n",
       "21  8.011030e-08      0     1  \n",
       "22  7.153558e-08      0     1  \n",
       "23  1.064937e-07      0     1  \n",
       "24  1.430052e-08      0     1  \n",
       "25  9.795333e-08      0     1  \n",
       "26  1.108388e-07      0     1  \n",
       "27  8.910105e-08      0     1  \n",
       "28  2.006338e-08      0     1  \n",
       "29  7.775793e-08      0     1  \n",
       "30  9.888695e-09      0     1  \n",
       "31  4.299954e-08      0     1  \n",
       "32  2.532827e-07      0     1  \n",
       "33  4.481368e-08      0     1  \n",
       "34  4.953462e-08      0     1  \n",
       "35  5.657214e-09      0     1  \n",
       "36  2.008883e-07      0     1  \n",
       "37  2.431658e-07      0     1  \n",
       "38  3.751768e-07      0     1  \n",
       "39  2.448973e-07      0     1  \n",
       "40  9.281580e-08      0     1  \n",
       "41  3.869795e-08      0     1  \n",
       "42  2.703603e-08      0     1  \n",
       "43  4.370104e-09      0     1  \n",
       "44  3.388397e-08      0     1  \n",
       "45  1.165312e-09      0     1  \n",
       "46  2.449750e-08      0     1  \n",
       "47  6.586212e-08      0     1  \n",
       "48  9.923436e-08      0     1  \n",
       "49  2.674937e-07      0     1  \n",
       "\n",
       "[50 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all dataframes\n",
    "data = pd.concat([muon_df, solar_df, conv_df])\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.drop(columns=['eff_oneweight'])\n",
    "\n",
    "print(data.shape)\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZTravel             0\n",
       "COGZ                0\n",
       "COGZSigma           0\n",
       "RLogL               0\n",
       "RecoZenith          0\n",
       "QTot                0\n",
       "LDir_A         851238\n",
       "NDirPulse_A         0\n",
       "NDirDOM_A           0\n",
       "NDirStr_A           0\n",
       "LDir_B         466930\n",
       "NDirPulse_B         0\n",
       "NDirDOM_B           0\n",
       "NDirStr_B           0\n",
       "LDir_C         226138\n",
       "NDirPulse_C         0\n",
       "NDirStr_C           0\n",
       "LDir_E              0\n",
       "NDirPulse_E         0\n",
       "NDirStr_E           0\n",
       "RecoAngSep       1505\n",
       "norm-rate           0\n",
       "solar               0\n",
       "muon                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of nan entries\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets (for muon BDT)\n",
    "X, y_muon, y_solar = data.drop(columns=['solar', 'muon']), data['muon'], data['solar']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_muon)\n",
    "train_weights, test_weights = X_train['norm-rate'], X_test['norm-rate']\n",
    "X_train, X_test = X_train.drop(columns=['norm-rate']), X_test.drop(columns='norm-rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# First-pass BDT fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.282 GB of training data: 1.573 s\n",
      "Binning 0.031 GB of validation data: 0.311 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.61336, val loss: 0.61931, in 5.152s\n",
      "[2/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59484, val loss: 0.60111, in 5.000s\n",
      "[3/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.57969, val loss: 0.58637, in 4.427s\n",
      "[4/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.56598, val loss: 0.57280, in 3.434s\n",
      "[5/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.55459, val loss: 0.56160, in 2.912s\n",
      "[6/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54417, val loss: 0.55127, in 2.216s\n",
      "[7/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.53481, val loss: 0.54217, in 2.167s\n",
      "[8/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.52682, val loss: 0.53432, in 3.882s\n",
      "[9/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.51998, val loss: 0.52762, in 4.162s\n",
      "[10/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.51324, val loss: 0.52075, in 4.149s\n",
      "[11/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.50708, val loss: 0.51476, in 4.831s\n",
      "[12/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.50171, val loss: 0.50949, in 3.987s\n",
      "[13/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.49635, val loss: 0.50429, in 3.971s\n",
      "[14/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.49182, val loss: 0.49997, in 3.920s\n",
      "[15/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.48755, val loss: 0.49599, in 4.032s\n",
      "[16/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.48344, val loss: 0.49212, in 3.896s\n",
      "[17/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.47958, val loss: 0.48838, in 3.751s\n",
      "[18/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.47572, val loss: 0.48476, in 4.833s\n",
      "[19/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.47227, val loss: 0.48157, in 4.616s\n",
      "[20/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.46885, val loss: 0.47835, in 3.959s\n",
      "[21/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.46584, val loss: 0.47560, in 3.961s\n",
      "[22/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.46289, val loss: 0.47288, in 4.014s\n",
      "[23/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.46008, val loss: 0.47025, in 4.251s\n",
      "[24/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.45738, val loss: 0.46780, in 4.187s\n",
      "[25/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.45496, val loss: 0.46541, in 4.477s\n",
      "[26/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.45251, val loss: 0.46317, in 4.475s\n",
      "[27/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.44958, val loss: 0.46044, in 4.066s\n",
      "[28/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.44773, val loss: 0.45870, in 3.880s\n",
      "[29/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.44578, val loss: 0.45696, in 2.640s\n",
      "[30/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.44316, val loss: 0.45462, in 2.191s\n",
      "[31/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.44134, val loss: 0.45291, in 3.401s\n",
      "[32/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.43919, val loss: 0.45081, in 3.999s\n",
      "[33/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.43773, val loss: 0.44955, in 4.540s\n",
      "[34/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.43585, val loss: 0.44774, in 4.680s\n",
      "[35/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.43441, val loss: 0.44639, in 4.030s\n",
      "[36/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.43275, val loss: 0.44482, in 4.031s\n",
      "[37/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.43149, val loss: 0.44372, in 5.091s\n",
      "[38/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.42996, val loss: 0.44226, in 4.408s\n",
      "[39/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.42849, val loss: 0.44082, in 4.035s\n",
      "[40/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.42724, val loss: 0.43970, in 4.640s\n",
      "[41/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.42575, val loss: 0.43821, in 4.465s\n",
      "[42/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.42477, val loss: 0.43731, in 3.847s\n",
      "[43/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.42371, val loss: 0.43642, in 4.056s\n",
      "[44/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.42257, val loss: 0.43539, in 3.962s\n",
      "[45/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.42166, val loss: 0.43453, in 3.940s\n",
      "[46/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.42055, val loss: 0.43348, in 3.935s\n",
      "[47/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.41955, val loss: 0.43247, in 4.436s\n",
      "[48/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.41867, val loss: 0.43176, in 4.933s\n",
      "[49/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.41751, val loss: 0.43073, in 4.006s\n",
      "[50/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.41648, val loss: 0.42988, in 4.104s\n",
      "[51/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.41546, val loss: 0.42905, in 3.790s\n",
      "[52/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.41471, val loss: 0.42839, in 3.009s\n",
      "[53/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.41400, val loss: 0.42781, in 2.326s\n",
      "[54/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.41316, val loss: 0.42701, in 3.515s\n",
      "[55/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.41229, val loss: 0.42620, in 4.306s\n",
      "[56/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.41137, val loss: 0.42531, in 4.570s\n",
      "[57/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.41053, val loss: 0.42448, in 3.901s\n",
      "[58/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.40988, val loss: 0.42390, in 4.035s\n",
      "[59/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.40908, val loss: 0.42327, in 4.031s\n",
      "[60/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.40846, val loss: 0.42274, in 4.197s\n",
      "[61/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.40791, val loss: 0.42236, in 4.221s\n",
      "[62/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.40725, val loss: 0.42183, in 4.134s\n",
      "[63/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.40662, val loss: 0.42130, in 4.483s\n",
      "[64/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.40609, val loss: 0.42096, in 4.201s\n",
      "[65/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.40550, val loss: 0.42042, in 3.801s\n",
      "[66/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.40491, val loss: 0.41995, in 3.839s\n",
      "[67/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.40444, val loss: 0.41954, in 4.207s\n",
      "[68/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.40388, val loss: 0.41899, in 4.356s\n",
      "[69/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.40327, val loss: 0.41850, in 4.072s\n",
      "[70/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.40278, val loss: 0.41811, in 4.689s\n",
      "[71/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.40232, val loss: 0.41773, in 3.031s\n",
      "[72/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.40189, val loss: 0.41740, in 2.679s\n",
      "[73/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.40134, val loss: 0.41692, in 2.874s\n",
      "[74/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.40095, val loss: 0.41662, in 3.643s\n",
      "[75/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.40040, val loss: 0.41608, in 3.898s\n",
      "[76/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.39987, val loss: 0.41562, in 3.862s\n",
      "[77/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.39949, val loss: 0.41536, in 2.568s\n",
      "[78/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.39909, val loss: 0.41497, in 2.122s\n",
      "[79/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.39872, val loss: 0.41468, in 3.399s\n",
      "[80/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.39829, val loss: 0.41434, in 4.131s\n",
      "[81/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.39784, val loss: 0.41393, in 3.746s\n",
      "[82/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.39743, val loss: 0.41358, in 3.901s\n",
      "[83/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.39707, val loss: 0.41329, in 3.760s\n",
      "[84/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.39670, val loss: 0.41298, in 3.847s\n",
      "[85/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.39625, val loss: 0.41257, in 4.082s\n",
      "[86/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.39589, val loss: 0.41228, in 4.017s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.39556, val loss: 0.41199, in 4.269s\n",
      "[88/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.39519, val loss: 0.41172, in 3.929s\n",
      "[89/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.39485, val loss: 0.41149, in 3.830s\n",
      "[90/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.39450, val loss: 0.41118, in 3.847s\n",
      "[91/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.39419, val loss: 0.41100, in 3.690s\n",
      "[92/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.39386, val loss: 0.41067, in 3.100s\n",
      "[93/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.39358, val loss: 0.41041, in 3.021s\n",
      "[94/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.39325, val loss: 0.41013, in 3.940s\n",
      "[95/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.39287, val loss: 0.40987, in 4.871s\n",
      "[96/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.39257, val loss: 0.40960, in 4.620s\n",
      "[97/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.39228, val loss: 0.40937, in 4.211s\n",
      "[98/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.39201, val loss: 0.40919, in 3.902s\n",
      "[99/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.39174, val loss: 0.40900, in 4.009s\n",
      "[100/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.39142, val loss: 0.40882, in 3.877s\n",
      "[101/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.39104, val loss: 0.40846, in 3.968s\n",
      "[102/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.39077, val loss: 0.40822, in 3.955s\n",
      "[103/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.39049, val loss: 0.40801, in 2.521s\n",
      "[104/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.39019, val loss: 0.40779, in 3.073s\n",
      "[105/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.38988, val loss: 0.40753, in 3.080s\n",
      "[106/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38955, val loss: 0.40723, in 3.656s\n",
      "[107/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.38929, val loss: 0.40703, in 3.880s\n",
      "[108/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.38902, val loss: 0.40678, in 3.846s\n",
      "[109/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.38875, val loss: 0.40660, in 4.121s\n",
      "[110/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38854, val loss: 0.40637, in 4.229s\n",
      "[111/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.38831, val loss: 0.40620, in 4.802s\n",
      "[112/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.38807, val loss: 0.40606, in 3.821s\n",
      "[113/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38780, val loss: 0.40584, in 3.402s\n",
      "[114/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38762, val loss: 0.40571, in 3.440s\n",
      "[115/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.38740, val loss: 0.40554, in 3.943s\n",
      "[116/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38719, val loss: 0.40537, in 4.194s\n",
      "[117/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.38698, val loss: 0.40518, in 4.017s\n",
      "[118/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.38672, val loss: 0.40495, in 4.131s\n",
      "[119/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38648, val loss: 0.40478, in 4.081s\n",
      "[120/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38624, val loss: 0.40459, in 3.898s\n",
      "[121/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.38605, val loss: 0.40446, in 3.979s\n",
      "[122/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.38586, val loss: 0.40427, in 3.756s\n",
      "[123/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.38566, val loss: 0.40411, in 3.713s\n",
      "[124/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38539, val loss: 0.40387, in 2.921s\n",
      "[125/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38522, val loss: 0.40373, in 2.501s\n",
      "[126/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.38505, val loss: 0.40360, in 3.184s\n",
      "[127/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38486, val loss: 0.40350, in 2.351s\n",
      "[128/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38471, val loss: 0.40335, in 3.267s\n",
      "[129/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.38449, val loss: 0.40324, in 3.890s\n",
      "[130/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.38423, val loss: 0.40297, in 3.862s\n",
      "[131/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38402, val loss: 0.40285, in 3.342s\n",
      "[132/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38382, val loss: 0.40273, in 2.428s\n",
      "[133/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38363, val loss: 0.40259, in 2.536s\n",
      "[134/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38340, val loss: 0.40237, in 3.512s\n",
      "[135/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38312, val loss: 0.40218, in 3.880s\n",
      "[136/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38292, val loss: 0.40205, in 4.039s\n",
      "[137/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.38275, val loss: 0.40193, in 3.747s\n",
      "[138/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38262, val loss: 0.40180, in 3.695s\n",
      "[139/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38243, val loss: 0.40167, in 3.775s\n",
      "[140/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.38228, val loss: 0.40157, in 3.782s\n",
      "[141/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38208, val loss: 0.40145, in 3.360s\n",
      "[142/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38188, val loss: 0.40127, in 3.713s\n",
      "[143/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38172, val loss: 0.40117, in 4.070s\n",
      "[144/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38152, val loss: 0.40105, in 5.056s\n",
      "[145/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.38137, val loss: 0.40095, in 3.736s\n",
      "[146/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.38124, val loss: 0.40082, in 3.670s\n",
      "[147/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.38106, val loss: 0.40071, in 3.424s\n",
      "[148/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.38089, val loss: 0.40062, in 3.616s\n",
      "[149/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38072, val loss: 0.40049, in 3.903s\n",
      "[150/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38055, val loss: 0.40039, in 3.790s\n",
      "[151/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.38042, val loss: 0.40030, in 3.792s\n",
      "[152/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.38025, val loss: 0.40018, in 3.039s\n",
      "[153/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.38012, val loss: 0.40007, in 3.294s\n",
      "[154/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37999, val loss: 0.39998, in 3.875s\n",
      "[155/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37987, val loss: 0.39991, in 3.748s\n",
      "[156/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37975, val loss: 0.39982, in 3.795s\n",
      "[157/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37958, val loss: 0.39970, in 3.813s\n",
      "[158/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37947, val loss: 0.39962, in 3.940s\n",
      "[159/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37932, val loss: 0.39949, in 3.643s\n",
      "[160/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37915, val loss: 0.39940, in 5.325s\n",
      "[161/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37903, val loss: 0.39934, in 4.884s\n",
      "[162/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37888, val loss: 0.39925, in 3.863s\n",
      "[163/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37873, val loss: 0.39915, in 3.807s\n",
      "[164/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37856, val loss: 0.39908, in 4.029s\n",
      "[165/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37843, val loss: 0.39898, in 3.833s\n",
      "[166/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37824, val loss: 0.39884, in 4.068s\n",
      "[167/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37809, val loss: 0.39872, in 4.826s\n",
      "[168/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37796, val loss: 0.39861, in 3.901s\n",
      "[169/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37786, val loss: 0.39852, in 4.011s\n",
      "[170/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37768, val loss: 0.39838, in 3.854s\n",
      "[171/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37753, val loss: 0.39825, in 3.848s\n",
      "[172/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37744, val loss: 0.39820, in 3.760s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37733, val loss: 0.39815, in 3.843s\n",
      "[174/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37717, val loss: 0.39803, in 3.937s\n",
      "[175/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37705, val loss: 0.39794, in 3.896s\n",
      "[176/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37690, val loss: 0.39785, in 2.077s\n",
      "[177/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37675, val loss: 0.39774, in 4.176s\n",
      "[178/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37659, val loss: 0.39770, in 4.124s\n",
      "[179/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37650, val loss: 0.39762, in 4.266s\n",
      "[180/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37640, val loss: 0.39756, in 4.000s\n",
      "[181/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37629, val loss: 0.39748, in 4.119s\n",
      "[182/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37612, val loss: 0.39739, in 4.374s\n",
      "[183/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37599, val loss: 0.39730, in 3.991s\n",
      "[184/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.37585, val loss: 0.39726, in 3.884s\n",
      "[185/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37573, val loss: 0.39721, in 3.884s\n",
      "[186/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37563, val loss: 0.39716, in 4.038s\n",
      "[187/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37552, val loss: 0.39707, in 4.036s\n",
      "[188/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.37540, val loss: 0.39699, in 3.917s\n",
      "[189/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37525, val loss: 0.39687, in 5.159s\n",
      "[190/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.37512, val loss: 0.39683, in 5.071s\n",
      "[191/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37502, val loss: 0.39674, in 4.125s\n",
      "[192/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37494, val loss: 0.39669, in 3.825s\n",
      "[193/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.37481, val loss: 0.39662, in 4.097s\n",
      "[194/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37468, val loss: 0.39651, in 4.231s\n",
      "[195/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37459, val loss: 0.39644, in 3.770s\n",
      "[196/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37447, val loss: 0.39636, in 3.980s\n",
      "[197/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37429, val loss: 0.39625, in 4.470s\n",
      "[198/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37418, val loss: 0.39618, in 3.799s\n",
      "[199/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37403, val loss: 0.39613, in 2.102s\n",
      "[200/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37392, val loss: 0.39606, in 2.054s\n",
      "[201/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37378, val loss: 0.39599, in 2.040s\n",
      "[202/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.37370, val loss: 0.39596, in 3.518s\n",
      "[203/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37355, val loss: 0.39589, in 3.976s\n",
      "[204/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37341, val loss: 0.39582, in 3.862s\n",
      "[205/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37326, val loss: 0.39574, in 4.650s\n",
      "[206/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37315, val loss: 0.39563, in 5.648s\n",
      "[207/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37305, val loss: 0.39555, in 3.855s\n",
      "[208/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37293, val loss: 0.39553, in 3.866s\n",
      "[209/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37282, val loss: 0.39552, in 3.954s\n",
      "[210/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37274, val loss: 0.39545, in 4.160s\n",
      "[211/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37264, val loss: 0.39536, in 4.131s\n",
      "[212/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37250, val loss: 0.39527, in 5.046s\n",
      "[213/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37240, val loss: 0.39527, in 4.234s\n",
      "[214/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37226, val loss: 0.39517, in 3.859s\n",
      "[215/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37215, val loss: 0.39509, in 3.977s\n",
      "[216/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37201, val loss: 0.39501, in 3.964s\n",
      "[217/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37194, val loss: 0.39496, in 3.951s\n",
      "[218/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37187, val loss: 0.39491, in 3.820s\n",
      "[219/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.37178, val loss: 0.39487, in 4.455s\n",
      "[220/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37169, val loss: 0.39483, in 5.316s\n",
      "[221/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37158, val loss: 0.39479, in 3.820s\n",
      "[222/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37152, val loss: 0.39476, in 4.057s\n",
      "[223/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37144, val loss: 0.39470, in 4.036s\n",
      "[224/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37137, val loss: 0.39467, in 3.368s\n",
      "[225/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37123, val loss: 0.39457, in 2.331s\n",
      "[226/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37114, val loss: 0.39452, in 2.648s\n",
      "[227/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37107, val loss: 0.39447, in 4.609s\n",
      "[228/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37092, val loss: 0.39437, in 4.982s\n",
      "[229/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.37085, val loss: 0.39432, in 4.050s\n",
      "[230/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.37073, val loss: 0.39427, in 4.087s\n",
      "[231/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37066, val loss: 0.39422, in 3.983s\n",
      "[232/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37055, val loss: 0.39417, in 4.084s\n",
      "[233/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37043, val loss: 0.39410, in 3.726s\n",
      "[234/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.37029, val loss: 0.39399, in 4.025s\n",
      "[235/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.37017, val loss: 0.39393, in 5.450s\n",
      "[236/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.37009, val loss: 0.39393, in 4.089s\n",
      "[237/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.37000, val loss: 0.39388, in 3.860s\n",
      "[238/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36986, val loss: 0.39380, in 4.757s\n",
      "[239/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.36977, val loss: 0.39372, in 3.909s\n",
      "[240/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36964, val loss: 0.39364, in 3.895s\n",
      "[241/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36952, val loss: 0.39364, in 3.875s\n",
      "[242/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36943, val loss: 0.39358, in 4.524s\n",
      "[243/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36934, val loss: 0.39352, in 4.034s\n",
      "[244/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.36927, val loss: 0.39346, in 3.941s\n",
      "[245/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36919, val loss: 0.39341, in 3.796s\n",
      "[246/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36907, val loss: 0.39336, in 3.829s\n",
      "[247/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36899, val loss: 0.39331, in 3.866s\n",
      "[248/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36886, val loss: 0.39327, in 3.828s\n",
      "[249/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36875, val loss: 0.39321, in 3.470s\n",
      "[250/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36865, val loss: 0.39319, in 2.569s\n",
      "[251/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36857, val loss: 0.39310, in 2.181s\n",
      "[252/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36848, val loss: 0.39305, in 2.905s\n",
      "[253/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36837, val loss: 0.39299, in 3.997s\n",
      "[254/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.36831, val loss: 0.39293, in 3.918s\n",
      "[255/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36824, val loss: 0.39290, in 3.932s\n",
      "[256/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36816, val loss: 0.39290, in 4.012s\n",
      "[257/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36807, val loss: 0.39282, in 4.205s\n",
      "[258/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36796, val loss: 0.39280, in 4.273s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36783, val loss: 0.39266, in 3.947s\n",
      "[260/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36773, val loss: 0.39260, in 3.533s\n",
      "[261/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36764, val loss: 0.39257, in 3.818s\n",
      "[262/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36753, val loss: 0.39251, in 3.791s\n",
      "[263/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36742, val loss: 0.39243, in 3.732s\n",
      "[264/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36735, val loss: 0.39236, in 3.732s\n",
      "[265/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36727, val loss: 0.39232, in 3.781s\n",
      "[266/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36717, val loss: 0.39228, in 5.491s\n",
      "[267/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.36709, val loss: 0.39220, in 3.865s\n",
      "[268/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36698, val loss: 0.39212, in 3.779s\n",
      "[269/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36690, val loss: 0.39209, in 3.838s\n",
      "[270/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36681, val loss: 0.39201, in 3.957s\n",
      "[271/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36675, val loss: 0.39198, in 3.720s\n",
      "[272/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36667, val loss: 0.39189, in 3.698s\n",
      "[273/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36660, val loss: 0.39184, in 2.754s\n",
      "[274/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36653, val loss: 0.39178, in 2.238s\n",
      "[275/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.36647, val loss: 0.39177, in 3.734s\n",
      "[276/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36640, val loss: 0.39174, in 4.050s\n",
      "[277/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36632, val loss: 0.39174, in 4.005s\n",
      "[278/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36622, val loss: 0.39172, in 4.089s\n",
      "[279/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36611, val loss: 0.39160, in 4.176s\n",
      "[280/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36598, val loss: 0.39148, in 3.819s\n",
      "[281/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36588, val loss: 0.39138, in 4.008s\n",
      "[282/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36580, val loss: 0.39133, in 5.067s\n",
      "[283/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36569, val loss: 0.39117, in 3.973s\n",
      "[284/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.36562, val loss: 0.39114, in 3.810s\n",
      "[285/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36553, val loss: 0.39111, in 3.904s\n",
      "[286/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36548, val loss: 0.39106, in 3.973s\n",
      "[287/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36539, val loss: 0.39104, in 4.015s\n",
      "[288/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36532, val loss: 0.39098, in 3.958s\n",
      "[289/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36524, val loss: 0.39091, in 4.775s\n",
      "[290/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36518, val loss: 0.39087, in 4.066s\n",
      "[291/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36506, val loss: 0.39085, in 3.860s\n",
      "[292/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36497, val loss: 0.39079, in 4.160s\n",
      "[293/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.36490, val loss: 0.39074, in 4.256s\n",
      "[294/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36479, val loss: 0.39068, in 3.827s\n",
      "[295/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36470, val loss: 0.39065, in 3.711s\n",
      "[296/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36464, val loss: 0.39061, in 2.872s\n",
      "[297/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.36455, val loss: 0.39056, in 4.950s\n",
      "[298/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36447, val loss: 0.39048, in 3.978s\n",
      "[299/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36440, val loss: 0.39045, in 3.970s\n",
      "[300/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36431, val loss: 0.39040, in 3.885s\n",
      "[301/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36423, val loss: 0.39034, in 4.001s\n",
      "[302/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36418, val loss: 0.39030, in 4.065s\n",
      "[303/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36412, val loss: 0.39027, in 4.141s\n",
      "[304/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36404, val loss: 0.39022, in 4.885s\n",
      "[305/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36396, val loss: 0.39018, in 4.055s\n",
      "[306/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36387, val loss: 0.39013, in 3.925s\n",
      "[307/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36379, val loss: 0.39010, in 3.736s\n",
      "[308/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.36373, val loss: 0.39006, in 3.850s\n",
      "[309/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36361, val loss: 0.39001, in 3.836s\n",
      "[310/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36352, val loss: 0.38999, in 3.829s\n",
      "[311/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36345, val loss: 0.38996, in 5.791s\n",
      "[312/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36337, val loss: 0.38992, in 4.146s\n",
      "[313/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36328, val loss: 0.38989, in 4.488s\n",
      "[314/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36323, val loss: 0.38984, in 4.767s\n",
      "[315/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.36317, val loss: 0.38978, in 4.534s\n",
      "[316/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36312, val loss: 0.38974, in 4.465s\n",
      "[317/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36303, val loss: 0.38971, in 3.927s\n",
      "[318/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.36298, val loss: 0.38969, in 2.519s\n",
      "[319/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36293, val loss: 0.38965, in 3.274s\n",
      "[320/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36283, val loss: 0.38961, in 4.152s\n",
      "[321/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36276, val loss: 0.38958, in 3.940s\n",
      "[322/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36271, val loss: 0.38956, in 4.029s\n",
      "[323/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.36265, val loss: 0.38951, in 4.019s\n",
      "[324/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36260, val loss: 0.38949, in 3.869s\n",
      "[325/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36253, val loss: 0.38943, in 3.854s\n",
      "[326/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36244, val loss: 0.38940, in 4.979s\n",
      "[327/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36240, val loss: 0.38935, in 4.266s\n",
      "[328/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36229, val loss: 0.38930, in 4.659s\n",
      "[329/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36219, val loss: 0.38926, in 3.774s\n",
      "[330/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36210, val loss: 0.38923, in 3.791s\n",
      "[331/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.36198, val loss: 0.38923, in 3.905s\n",
      "[332/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36194, val loss: 0.38919, in 3.998s\n",
      "[333/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.36185, val loss: 0.38916, in 4.105s\n",
      "[334/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36175, val loss: 0.38912, in 4.059s\n",
      "[335/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36170, val loss: 0.38909, in 3.832s\n",
      "[336/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.36161, val loss: 0.38908, in 3.877s\n",
      "[337/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36150, val loss: 0.38903, in 3.931s\n",
      "[338/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.36140, val loss: 0.38896, in 4.003s\n",
      "[339/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36131, val loss: 0.38893, in 3.950s\n",
      "[340/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.36125, val loss: 0.38890, in 4.239s\n",
      "[341/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36121, val loss: 0.38888, in 4.342s\n",
      "[342/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36112, val loss: 0.38884, in 2.213s\n",
      "[343/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36104, val loss: 0.38875, in 3.882s\n",
      "[344/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36099, val loss: 0.38870, in 3.807s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[345/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.36094, val loss: 0.38867, in 3.866s\n",
      "[346/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36087, val loss: 0.38864, in 4.013s\n",
      "[347/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36076, val loss: 0.38860, in 4.112s\n",
      "[348/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36067, val loss: 0.38856, in 4.229s\n",
      "[349/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.36057, val loss: 0.38857, in 4.461s\n",
      "[350/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.36046, val loss: 0.38853, in 3.870s\n",
      "[351/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.36040, val loss: 0.38848, in 3.943s\n",
      "[352/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.36031, val loss: 0.38845, in 3.820s\n",
      "[353/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36022, val loss: 0.38843, in 3.985s\n",
      "[354/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.36018, val loss: 0.38840, in 4.195s\n",
      "[355/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.36010, val loss: 0.38836, in 3.833s\n",
      "[356/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36001, val loss: 0.38834, in 4.708s\n",
      "[357/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35996, val loss: 0.38832, in 4.161s\n",
      "[358/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35986, val loss: 0.38823, in 3.800s\n",
      "[359/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35980, val loss: 0.38820, in 3.850s\n",
      "[360/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35974, val loss: 0.38817, in 3.919s\n",
      "[361/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35969, val loss: 0.38814, in 3.959s\n",
      "[362/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35963, val loss: 0.38811, in 3.852s\n",
      "[363/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35954, val loss: 0.38800, in 3.854s\n",
      "[364/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35946, val loss: 0.38795, in 4.073s\n",
      "[365/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35942, val loss: 0.38793, in 3.782s\n",
      "[366/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35933, val loss: 0.38788, in 2.759s\n",
      "[367/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35923, val loss: 0.38783, in 2.706s\n",
      "[368/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35915, val loss: 0.38780, in 3.940s\n",
      "[369/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35910, val loss: 0.38776, in 3.846s\n",
      "[370/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35903, val loss: 0.38768, in 3.864s\n",
      "[371/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35893, val loss: 0.38763, in 4.440s\n",
      "[372/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.35884, val loss: 0.38760, in 5.287s\n",
      "[373/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35877, val loss: 0.38758, in 3.816s\n",
      "[374/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35869, val loss: 0.38756, in 3.878s\n",
      "[375/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35862, val loss: 0.38754, in 3.865s\n",
      "[376/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35856, val loss: 0.38750, in 3.969s\n",
      "[377/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35849, val loss: 0.38748, in 4.017s\n",
      "[378/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.35841, val loss: 0.38745, in 4.114s\n",
      "[379/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35835, val loss: 0.38744, in 4.073s\n",
      "[380/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35827, val loss: 0.38738, in 3.837s\n",
      "[381/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35823, val loss: 0.38736, in 3.778s\n",
      "[382/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35815, val loss: 0.38737, in 3.781s\n",
      "[383/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35808, val loss: 0.38734, in 4.652s\n",
      "[384/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35801, val loss: 0.38727, in 3.935s\n",
      "[385/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35792, val loss: 0.38725, in 3.787s\n",
      "[386/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35787, val loss: 0.38720, in 4.434s\n",
      "[387/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35782, val loss: 0.38717, in 4.355s\n",
      "[388/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35776, val loss: 0.38716, in 3.930s\n",
      "[389/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35769, val loss: 0.38712, in 3.815s\n",
      "[390/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35763, val loss: 0.38707, in 3.894s\n",
      "[391/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35759, val loss: 0.38704, in 2.264s\n",
      "[392/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35752, val loss: 0.38700, in 2.126s\n",
      "[393/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35747, val loss: 0.38699, in 2.942s\n",
      "[394/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35738, val loss: 0.38696, in 4.514s\n",
      "[395/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35732, val loss: 0.38693, in 4.512s\n",
      "[396/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.35727, val loss: 0.38690, in 3.859s\n",
      "[397/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35720, val loss: 0.38688, in 4.019s\n",
      "[398/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35716, val loss: 0.38686, in 4.296s\n",
      "[399/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35708, val loss: 0.38682, in 4.100s\n",
      "[400/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35700, val loss: 0.38679, in 3.935s\n",
      "[401/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35692, val loss: 0.38673, in 3.929s\n",
      "[402/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35684, val loss: 0.38669, in 4.816s\n",
      "[403/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35677, val loss: 0.38663, in 4.400s\n",
      "[404/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35669, val loss: 0.38658, in 3.881s\n",
      "[405/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.35662, val loss: 0.38654, in 3.901s\n",
      "[406/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35656, val loss: 0.38650, in 3.888s\n",
      "[407/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35648, val loss: 0.38647, in 3.985s\n",
      "[408/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35642, val loss: 0.38646, in 4.032s\n",
      "[409/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35635, val loss: 0.38643, in 3.914s\n",
      "[410/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.35631, val loss: 0.38642, in 5.340s\n",
      "[411/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35625, val loss: 0.38639, in 3.873s\n",
      "[412/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35621, val loss: 0.38639, in 3.819s\n",
      "[413/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35614, val loss: 0.38636, in 3.050s\n",
      "[414/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35607, val loss: 0.38630, in 2.084s\n",
      "[415/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35599, val loss: 0.38628, in 4.141s\n",
      "[416/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35592, val loss: 0.38628, in 4.082s\n",
      "[417/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35584, val loss: 0.38625, in 4.270s\n",
      "[418/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35575, val loss: 0.38620, in 4.091s\n",
      "[419/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35572, val loss: 0.38616, in 3.792s\n",
      "[420/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35568, val loss: 0.38613, in 3.850s\n",
      "[421/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35563, val loss: 0.38611, in 4.157s\n",
      "[422/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.35558, val loss: 0.38609, in 3.942s\n",
      "[423/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35552, val loss: 0.38609, in 3.898s\n",
      "[424/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.35545, val loss: 0.38605, in 3.903s\n",
      "[425/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35538, val loss: 0.38604, in 4.427s\n",
      "[426/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35532, val loss: 0.38598, in 3.979s\n",
      "[427/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35525, val loss: 0.38594, in 3.859s\n",
      "[428/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35516, val loss: 0.38591, in 3.955s\n",
      "[429/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35510, val loss: 0.38588, in 3.909s\n",
      "[430/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35502, val loss: 0.38587, in 3.788s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[431/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35496, val loss: 0.38580, in 3.837s\n",
      "[432/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35492, val loss: 0.38577, in 4.691s\n",
      "[433/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35486, val loss: 0.38576, in 5.338s\n",
      "[434/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35478, val loss: 0.38571, in 3.792s\n",
      "[435/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35473, val loss: 0.38568, in 3.664s\n",
      "[436/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35470, val loss: 0.38566, in 2.219s\n",
      "[437/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35465, val loss: 0.38563, in 2.112s\n",
      "[438/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35459, val loss: 0.38563, in 2.141s\n",
      "[439/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35452, val loss: 0.38562, in 3.160s\n",
      "[440/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.35447, val loss: 0.38563, in 4.314s\n",
      "[441/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35440, val loss: 0.38560, in 4.705s\n",
      "[442/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35433, val loss: 0.38557, in 4.044s\n",
      "[443/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35426, val loss: 0.38557, in 4.102s\n",
      "[444/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35422, val loss: 0.38556, in 4.316s\n",
      "[445/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35419, val loss: 0.38554, in 3.810s\n",
      "[446/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35412, val loss: 0.38555, in 3.825s\n",
      "[447/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35407, val loss: 0.38553, in 4.120s\n",
      "[448/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35400, val loss: 0.38549, in 4.522s\n",
      "[449/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35391, val loss: 0.38542, in 4.153s\n",
      "[450/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35387, val loss: 0.38538, in 3.770s\n",
      "[451/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35380, val loss: 0.38537, in 3.751s\n",
      "[452/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.35376, val loss: 0.38534, in 3.753s\n",
      "[453/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35370, val loss: 0.38528, in 3.884s\n",
      "[454/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35362, val loss: 0.38528, in 4.312s\n",
      "[455/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35356, val loss: 0.38526, in 3.852s\n",
      "[456/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35350, val loss: 0.38524, in 4.673s\n",
      "[457/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35344, val loss: 0.38521, in 3.733s\n",
      "[458/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35340, val loss: 0.38520, in 3.666s\n",
      "[459/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35336, val loss: 0.38520, in 3.861s\n",
      "[460/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35329, val loss: 0.38518, in 3.768s\n",
      "[461/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35323, val loss: 0.38518, in 3.027s\n",
      "[462/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35317, val loss: 0.38518, in 2.070s\n",
      "[463/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.35310, val loss: 0.38515, in 2.047s\n",
      "[464/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35305, val loss: 0.38511, in 2.877s\n",
      "[465/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35297, val loss: 0.38509, in 5.645s\n",
      "[466/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.35293, val loss: 0.38506, in 3.896s\n",
      "[467/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35288, val loss: 0.38501, in 3.754s\n",
      "[468/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35284, val loss: 0.38497, in 3.867s\n",
      "[469/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.35278, val loss: 0.38495, in 3.866s\n",
      "[470/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35273, val loss: 0.38491, in 4.106s\n",
      "[471/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35268, val loss: 0.38489, in 3.871s\n",
      "[472/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.35264, val loss: 0.38487, in 3.951s\n",
      "[473/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.35260, val loss: 0.38486, in 3.874s\n",
      "[474/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35257, val loss: 0.38482, in 3.757s\n",
      "[475/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.35252, val loss: 0.38481, in 3.750s\n",
      "[476/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35246, val loss: 0.38478, in 3.680s\n",
      "[477/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35239, val loss: 0.38477, in 3.369s\n",
      "[478/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35236, val loss: 0.38477, in 3.509s\n",
      "[479/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35232, val loss: 0.38477, in 3.191s\n",
      "[480/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35227, val loss: 0.38471, in 3.945s\n",
      "[481/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35222, val loss: 0.38470, in 4.194s\n",
      "[482/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35216, val loss: 0.38465, in 3.624s\n",
      "[483/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35212, val loss: 0.38464, in 4.503s\n",
      "[484/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35209, val loss: 0.38461, in 3.946s\n",
      "[485/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35203, val loss: 0.38457, in 3.775s\n",
      "[486/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.35198, val loss: 0.38453, in 3.853s\n",
      "[487/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35191, val loss: 0.38451, in 3.857s\n",
      "[488/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35185, val loss: 0.38449, in 2.585s\n",
      "[489/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35179, val loss: 0.38447, in 2.585s\n",
      "[490/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35172, val loss: 0.38444, in 3.159s\n",
      "[491/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35164, val loss: 0.38439, in 4.060s\n",
      "[492/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35158, val loss: 0.38436, in 3.805s\n",
      "[493/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35152, val loss: 0.38432, in 3.853s\n",
      "[494/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.35146, val loss: 0.38430, in 3.915s\n",
      "[495/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35143, val loss: 0.38426, in 3.894s\n",
      "[496/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35137, val loss: 0.38427, in 4.721s\n",
      "[497/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35133, val loss: 0.38426, in 4.645s\n",
      "[498/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35128, val loss: 0.38426, in 3.902s\n",
      "[499/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35124, val loss: 0.38422, in 4.021s\n",
      "[500/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.35117, val loss: 0.38418, in 3.888s\n",
      "[501/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35113, val loss: 0.38416, in 4.158s\n",
      "[502/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35109, val loss: 0.38414, in 4.035s\n",
      "[503/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35102, val loss: 0.38408, in 3.990s\n",
      "[504/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.35097, val loss: 0.38405, in 4.524s\n",
      "[505/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35093, val loss: 0.38403, in 3.771s\n",
      "[506/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35087, val loss: 0.38398, in 3.790s\n",
      "[507/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35083, val loss: 0.38393, in 3.996s\n",
      "[508/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35079, val loss: 0.38391, in 3.845s\n",
      "[509/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.35074, val loss: 0.38387, in 3.789s\n",
      "[510/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.35070, val loss: 0.38384, in 3.798s\n",
      "[511/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.35065, val loss: 0.38381, in 4.897s\n",
      "[512/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.35062, val loss: 0.38379, in 4.029s\n",
      "[513/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35054, val loss: 0.38378, in 2.449s\n",
      "[514/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35049, val loss: 0.38378, in 2.061s\n",
      "[515/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.35043, val loss: 0.38377, in 3.294s\n",
      "[516/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35038, val loss: 0.38373, in 4.353s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[517/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.35033, val loss: 0.38371, in 3.967s\n",
      "[518/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.35026, val loss: 0.38370, in 3.874s\n",
      "[519/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35020, val loss: 0.38367, in 4.184s\n",
      "[520/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35014, val loss: 0.38366, in 4.739s\n",
      "[521/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35009, val loss: 0.38362, in 3.762s\n",
      "[522/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.35003, val loss: 0.38358, in 4.759s\n",
      "[523/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.35000, val loss: 0.38358, in 3.254s\n",
      "[524/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34996, val loss: 0.38357, in 3.743s\n",
      "[525/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34992, val loss: 0.38355, in 3.692s\n",
      "[526/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.34989, val loss: 0.38354, in 3.791s\n",
      "[527/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34986, val loss: 0.38353, in 4.212s\n",
      "[528/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34981, val loss: 0.38350, in 4.026s\n",
      "[529/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34974, val loss: 0.38345, in 3.931s\n",
      "[530/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34967, val loss: 0.38340, in 3.866s\n",
      "[531/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34961, val loss: 0.38334, in 3.811s\n",
      "[532/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34955, val loss: 0.38331, in 4.009s\n",
      "[533/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34949, val loss: 0.38329, in 3.998s\n",
      "[534/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34943, val loss: 0.38325, in 3.935s\n",
      "[535/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34939, val loss: 0.38326, in 3.967s\n",
      "[536/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.34935, val loss: 0.38327, in 3.676s\n",
      "[537/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34930, val loss: 0.38322, in 3.832s\n",
      "[538/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34924, val loss: 0.38320, in 3.778s\n",
      "[539/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34917, val loss: 0.38317, in 2.920s\n",
      "[540/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34912, val loss: 0.38317, in 2.740s\n",
      "[541/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34909, val loss: 0.38315, in 3.283s\n",
      "[542/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34903, val loss: 0.38315, in 4.098s\n",
      "[543/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34898, val loss: 0.38316, in 4.796s\n",
      "[544/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34892, val loss: 0.38313, in 4.521s\n",
      "[545/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.34885, val loss: 0.38313, in 3.930s\n",
      "[546/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34879, val loss: 0.38310, in 4.267s\n",
      "[547/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34875, val loss: 0.38310, in 3.953s\n",
      "[548/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34868, val loss: 0.38306, in 3.901s\n",
      "[549/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34864, val loss: 0.38303, in 4.183s\n",
      "[550/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34858, val loss: 0.38298, in 4.606s\n",
      "[551/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34852, val loss: 0.38297, in 4.335s\n",
      "[552/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34848, val loss: 0.38293, in 3.913s\n",
      "[553/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34842, val loss: 0.38289, in 5.035s\n",
      "[554/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34838, val loss: 0.38287, in 3.832s\n",
      "[555/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34833, val loss: 0.38284, in 3.868s\n",
      "[556/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34830, val loss: 0.38282, in 4.088s\n",
      "[557/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34824, val loss: 0.38278, in 5.212s\n",
      "[558/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34819, val loss: 0.38275, in 4.183s\n",
      "[559/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34814, val loss: 0.38274, in 3.744s\n",
      "[560/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34811, val loss: 0.38272, in 3.743s\n",
      "[561/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34807, val loss: 0.38269, in 2.209s\n",
      "[562/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34802, val loss: 0.38271, in 2.714s\n",
      "[563/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34795, val loss: 0.38267, in 4.259s\n",
      "[564/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34789, val loss: 0.38263, in 4.187s\n",
      "[565/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34783, val loss: 0.38260, in 4.516s\n",
      "[566/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34777, val loss: 0.38257, in 4.224s\n",
      "[567/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34773, val loss: 0.38254, in 4.135s\n",
      "[568/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34766, val loss: 0.38248, in 4.094s\n",
      "[569/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34759, val loss: 0.38247, in 4.126s\n",
      "[570/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34754, val loss: 0.38242, in 3.885s\n",
      "[571/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34748, val loss: 0.38239, in 3.800s\n",
      "[572/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34743, val loss: 0.38236, in 4.160s\n",
      "[573/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34738, val loss: 0.38234, in 4.384s\n",
      "[574/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34734, val loss: 0.38231, in 3.952s\n",
      "[575/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34727, val loss: 0.38226, in 3.913s\n",
      "[576/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34722, val loss: 0.38220, in 3.917s\n",
      "[577/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34716, val loss: 0.38217, in 4.320s\n",
      "[578/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34711, val loss: 0.38213, in 4.939s\n",
      "[579/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34705, val loss: 0.38212, in 4.141s\n",
      "[580/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34702, val loss: 0.38211, in 4.524s\n",
      "[581/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34698, val loss: 0.38208, in 4.184s\n",
      "[582/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34693, val loss: 0.38208, in 3.883s\n",
      "[583/5000] 1 tree, 31 leaves, max depth = 22, train loss: 0.34690, val loss: 0.38206, in 2.463s\n",
      "[584/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34686, val loss: 0.38204, in 2.179s\n",
      "[585/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34680, val loss: 0.38203, in 2.161s\n",
      "[586/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34678, val loss: 0.38200, in 3.831s\n",
      "[587/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34673, val loss: 0.38200, in 3.921s\n",
      "[588/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34667, val loss: 0.38198, in 5.324s\n",
      "[589/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34662, val loss: 0.38196, in 4.305s\n",
      "[590/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34660, val loss: 0.38193, in 3.971s\n",
      "[591/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34656, val loss: 0.38194, in 4.262s\n",
      "[592/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34652, val loss: 0.38190, in 4.236s\n",
      "[593/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34647, val loss: 0.38188, in 4.377s\n",
      "[594/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34641, val loss: 0.38183, in 4.469s\n",
      "[595/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34636, val loss: 0.38181, in 4.586s\n",
      "[596/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34633, val loss: 0.38179, in 4.117s\n",
      "[597/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.34628, val loss: 0.38178, in 4.141s\n",
      "[598/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34624, val loss: 0.38173, in 3.492s\n",
      "[599/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34617, val loss: 0.38167, in 4.217s\n",
      "[600/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34612, val loss: 0.38167, in 4.131s\n",
      "[601/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34608, val loss: 0.38162, in 4.000s\n",
      "[602/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34602, val loss: 0.38160, in 4.476s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[603/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34598, val loss: 0.38159, in 4.474s\n",
      "[604/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34592, val loss: 0.38157, in 4.074s\n",
      "[605/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34586, val loss: 0.38151, in 4.237s\n",
      "[606/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34582, val loss: 0.38148, in 3.092s\n",
      "[607/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34578, val loss: 0.38148, in 2.518s\n",
      "[608/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34572, val loss: 0.38144, in 2.276s\n",
      "[609/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34566, val loss: 0.38142, in 4.276s\n",
      "[610/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34562, val loss: 0.38140, in 4.503s\n",
      "[611/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34556, val loss: 0.38138, in 4.557s\n",
      "[612/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.34553, val loss: 0.38136, in 3.982s\n",
      "[613/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34550, val loss: 0.38136, in 3.919s\n",
      "[614/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34547, val loss: 0.38136, in 3.414s\n",
      "[615/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34543, val loss: 0.38134, in 2.856s\n",
      "[616/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34538, val loss: 0.38134, in 3.134s\n",
      "[617/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34534, val loss: 0.38132, in 3.227s\n",
      "[618/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34530, val loss: 0.38129, in 4.646s\n",
      "[619/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34526, val loss: 0.38125, in 4.761s\n",
      "[620/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34519, val loss: 0.38123, in 3.777s\n",
      "[621/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34515, val loss: 0.38122, in 3.925s\n",
      "[622/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34508, val loss: 0.38115, in 3.984s\n",
      "[623/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34505, val loss: 0.38113, in 4.249s\n",
      "[624/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34502, val loss: 0.38114, in 3.815s\n",
      "[625/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34496, val loss: 0.38112, in 4.054s\n",
      "[626/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34491, val loss: 0.38111, in 4.114s\n",
      "[627/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34485, val loss: 0.38107, in 3.375s\n",
      "[628/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34480, val loss: 0.38104, in 3.275s\n",
      "[629/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34476, val loss: 0.38104, in 3.460s\n",
      "[630/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34472, val loss: 0.38101, in 2.793s\n",
      "[631/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34464, val loss: 0.38099, in 2.707s\n",
      "[632/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34461, val loss: 0.38097, in 2.673s\n",
      "[633/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34458, val loss: 0.38096, in 2.111s\n",
      "[634/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34455, val loss: 0.38094, in 3.587s\n",
      "[635/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34449, val loss: 0.38094, in 4.657s\n",
      "[636/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34444, val loss: 0.38092, in 4.498s\n",
      "[637/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34442, val loss: 0.38090, in 3.896s\n",
      "[638/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34438, val loss: 0.38091, in 3.987s\n",
      "[639/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34434, val loss: 0.38090, in 3.730s\n",
      "[640/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34429, val loss: 0.38088, in 3.641s\n",
      "[641/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34423, val loss: 0.38085, in 3.389s\n",
      "[642/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34419, val loss: 0.38083, in 4.163s\n",
      "[643/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34416, val loss: 0.38080, in 4.672s\n",
      "[644/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34413, val loss: 0.38077, in 3.854s\n",
      "[645/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34407, val loss: 0.38074, in 4.341s\n",
      "[646/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34402, val loss: 0.38073, in 3.744s\n",
      "[647/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34397, val loss: 0.38072, in 3.770s\n",
      "[648/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34391, val loss: 0.38068, in 4.069s\n",
      "[649/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34386, val loss: 0.38066, in 3.956s\n",
      "[650/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34384, val loss: 0.38065, in 5.836s\n",
      "[651/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34379, val loss: 0.38063, in 4.281s\n",
      "[652/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34374, val loss: 0.38060, in 3.789s\n",
      "[653/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34371, val loss: 0.38057, in 3.880s\n",
      "[654/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34366, val loss: 0.38054, in 3.935s\n",
      "[655/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34361, val loss: 0.38051, in 4.082s\n",
      "[656/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34354, val loss: 0.38050, in 3.607s\n",
      "[657/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34349, val loss: 0.38049, in 2.765s\n",
      "[658/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.34344, val loss: 0.38049, in 4.304s\n",
      "[659/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34339, val loss: 0.38046, in 3.817s\n",
      "[660/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34334, val loss: 0.38046, in 4.020s\n",
      "[661/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34329, val loss: 0.38044, in 3.958s\n",
      "[662/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34324, val loss: 0.38044, in 3.954s\n",
      "[663/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34318, val loss: 0.38042, in 3.925s\n",
      "[664/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34312, val loss: 0.38041, in 3.826s\n",
      "[665/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34308, val loss: 0.38040, in 5.286s\n",
      "[666/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34304, val loss: 0.38038, in 3.983s\n",
      "[667/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34299, val loss: 0.38036, in 4.211s\n",
      "[668/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34294, val loss: 0.38033, in 4.021s\n",
      "[669/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34288, val loss: 0.38032, in 3.920s\n",
      "[670/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34283, val loss: 0.38029, in 3.848s\n",
      "[671/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34278, val loss: 0.38028, in 3.377s\n",
      "[672/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34272, val loss: 0.38024, in 3.980s\n",
      "[673/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34268, val loss: 0.38021, in 4.856s\n",
      "[674/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34262, val loss: 0.38018, in 4.060s\n",
      "[675/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34256, val loss: 0.38015, in 4.144s\n",
      "[676/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.34251, val loss: 0.38009, in 4.067s\n",
      "[677/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34247, val loss: 0.38011, in 4.062s\n",
      "[678/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34243, val loss: 0.38011, in 4.152s\n",
      "[679/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34239, val loss: 0.38009, in 4.118s\n",
      "[680/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34234, val loss: 0.38007, in 4.150s\n",
      "[681/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34230, val loss: 0.38008, in 2.685s\n",
      "[682/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34225, val loss: 0.38006, in 3.047s\n",
      "[683/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34219, val loss: 0.38003, in 3.977s\n",
      "[684/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34213, val loss: 0.37998, in 3.807s\n",
      "[685/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34209, val loss: 0.37997, in 4.390s\n",
      "[686/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34204, val loss: 0.37996, in 4.247s\n",
      "[687/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34202, val loss: 0.37996, in 4.305s\n",
      "[688/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34197, val loss: 0.37992, in 4.823s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[689/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34192, val loss: 0.37990, in 4.212s\n",
      "[690/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34186, val loss: 0.37988, in 3.931s\n",
      "[691/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34182, val loss: 0.37986, in 3.970s\n",
      "[692/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34178, val loss: 0.37982, in 4.073s\n",
      "[693/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34172, val loss: 0.37980, in 3.959s\n",
      "[694/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34167, val loss: 0.37980, in 4.490s\n",
      "[695/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34162, val loss: 0.37980, in 4.693s\n",
      "[696/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34157, val loss: 0.37978, in 3.858s\n",
      "[697/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34152, val loss: 0.37976, in 3.859s\n",
      "[698/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34148, val loss: 0.37975, in 3.800s\n",
      "[699/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34145, val loss: 0.37973, in 3.855s\n",
      "[700/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34139, val loss: 0.37967, in 4.168s\n",
      "[701/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34134, val loss: 0.37966, in 4.124s\n",
      "[702/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34128, val loss: 0.37965, in 3.835s\n",
      "[703/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34123, val loss: 0.37962, in 2.584s\n",
      "[704/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34119, val loss: 0.37959, in 2.094s\n",
      "[705/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34115, val loss: 0.37957, in 2.871s\n",
      "[706/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34113, val loss: 0.37956, in 4.163s\n",
      "[707/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34107, val loss: 0.37952, in 4.243s\n",
      "[708/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34105, val loss: 0.37951, in 3.893s\n",
      "[709/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34102, val loss: 0.37949, in 3.832s\n",
      "[710/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34097, val loss: 0.37945, in 5.170s\n",
      "[711/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.34094, val loss: 0.37942, in 5.435s\n",
      "[712/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34089, val loss: 0.37940, in 4.978s\n",
      "[713/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34087, val loss: 0.37939, in 5.148s\n",
      "[714/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34082, val loss: 0.37940, in 4.731s\n",
      "[715/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34078, val loss: 0.37938, in 4.802s\n",
      "[716/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34074, val loss: 0.37935, in 4.807s\n",
      "[717/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34070, val loss: 0.37935, in 4.853s\n",
      "[718/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.34065, val loss: 0.37935, in 3.877s\n",
      "[719/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34062, val loss: 0.37933, in 4.033s\n",
      "[720/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34058, val loss: 0.37931, in 3.855s\n",
      "[721/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34053, val loss: 0.37927, in 4.017s\n",
      "[722/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.34048, val loss: 0.37923, in 4.019s\n",
      "[723/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34043, val loss: 0.37923, in 4.735s\n",
      "[724/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.34040, val loss: 0.37921, in 5.249s\n",
      "[725/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34035, val loss: 0.37918, in 2.361s\n",
      "[726/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34031, val loss: 0.37916, in 2.290s\n",
      "[727/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.34028, val loss: 0.37914, in 4.550s\n",
      "[728/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34024, val loss: 0.37913, in 4.770s\n",
      "[729/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.34019, val loss: 0.37911, in 4.264s\n",
      "[730/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.34015, val loss: 0.37910, in 4.032s\n",
      "[731/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.34011, val loss: 0.37908, in 4.328s\n",
      "[732/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.34006, val loss: 0.37901, in 4.638s\n",
      "[733/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.34001, val loss: 0.37900, in 4.647s\n",
      "[734/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33997, val loss: 0.37898, in 4.180s\n",
      "[735/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33993, val loss: 0.37897, in 4.693s\n",
      "[736/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33989, val loss: 0.37893, in 4.069s\n",
      "[737/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33984, val loss: 0.37889, in 4.016s\n",
      "[738/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33980, val loss: 0.37887, in 4.863s\n",
      "[739/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33976, val loss: 0.37885, in 4.066s\n",
      "[740/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33973, val loss: 0.37883, in 4.147s\n",
      "[741/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33969, val loss: 0.37882, in 4.143s\n",
      "[742/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33965, val loss: 0.37883, in 4.075s\n",
      "[743/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33960, val loss: 0.37881, in 4.128s\n",
      "[744/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33956, val loss: 0.37880, in 4.075s\n",
      "[745/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33952, val loss: 0.37882, in 4.464s\n",
      "[746/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33948, val loss: 0.37880, in 4.591s\n",
      "[747/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33943, val loss: 0.37877, in 3.590s\n",
      "[748/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33940, val loss: 0.37876, in 2.387s\n",
      "[749/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33937, val loss: 0.37875, in 2.105s\n",
      "[750/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33932, val loss: 0.37870, in 3.539s\n",
      "[751/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33928, val loss: 0.37870, in 4.025s\n",
      "[752/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33924, val loss: 0.37870, in 3.854s\n",
      "[753/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33921, val loss: 0.37865, in 4.411s\n",
      "[754/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33916, val loss: 0.37863, in 4.703s\n",
      "[755/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33912, val loss: 0.37861, in 3.966s\n",
      "[756/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33908, val loss: 0.37860, in 3.507s\n",
      "[757/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33904, val loss: 0.37858, in 3.981s\n",
      "[758/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33901, val loss: 0.37854, in 3.987s\n",
      "[759/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33897, val loss: 0.37853, in 3.930s\n",
      "[760/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33894, val loss: 0.37852, in 4.005s\n",
      "[761/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33890, val loss: 0.37853, in 4.674s\n",
      "[762/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33886, val loss: 0.37852, in 4.097s\n",
      "[763/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33882, val loss: 0.37850, in 3.574s\n",
      "[764/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33878, val loss: 0.37846, in 3.228s\n",
      "[765/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33873, val loss: 0.37843, in 5.074s\n",
      "[766/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33869, val loss: 0.37842, in 4.016s\n",
      "[767/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33865, val loss: 0.37840, in 4.028s\n",
      "[768/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33860, val loss: 0.37840, in 4.584s\n",
      "[769/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33858, val loss: 0.37839, in 4.768s\n",
      "[770/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33853, val loss: 0.37836, in 3.957s\n",
      "[771/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33849, val loss: 0.37834, in 3.946s\n",
      "[772/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33845, val loss: 0.37833, in 3.108s\n",
      "[773/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33840, val loss: 0.37831, in 2.893s\n",
      "[774/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33837, val loss: 0.37828, in 4.111s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[775/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33833, val loss: 0.37826, in 3.973s\n",
      "[776/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33829, val loss: 0.37823, in 4.294s\n",
      "[777/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33826, val loss: 0.37821, in 4.055s\n",
      "[778/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33821, val loss: 0.37819, in 3.992s\n",
      "[779/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33819, val loss: 0.37817, in 3.865s\n",
      "[780/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33815, val loss: 0.37815, in 3.826s\n",
      "[781/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33812, val loss: 0.37815, in 4.143s\n",
      "[782/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.33808, val loss: 0.37816, in 3.913s\n",
      "[783/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33804, val loss: 0.37815, in 4.754s\n",
      "[784/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33800, val loss: 0.37816, in 4.888s\n",
      "[785/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33796, val loss: 0.37812, in 3.842s\n",
      "[786/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33792, val loss: 0.37809, in 3.887s\n",
      "[787/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33788, val loss: 0.37808, in 4.148s\n",
      "[788/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33783, val loss: 0.37806, in 4.222s\n",
      "[789/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33778, val loss: 0.37806, in 4.274s\n",
      "[790/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33775, val loss: 0.37803, in 5.043s\n",
      "[791/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33771, val loss: 0.37804, in 3.968s\n",
      "[792/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33768, val loss: 0.37802, in 3.720s\n",
      "[793/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33763, val loss: 0.37801, in 4.109s\n",
      "[794/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33758, val loss: 0.37797, in 3.751s\n",
      "[795/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33755, val loss: 0.37798, in 3.695s\n",
      "[796/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33751, val loss: 0.37793, in 2.786s\n",
      "[797/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33745, val loss: 0.37794, in 2.203s\n",
      "[798/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33742, val loss: 0.37794, in 4.485s\n",
      "[799/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33738, val loss: 0.37794, in 5.342s\n",
      "[800/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.33735, val loss: 0.37795, in 4.227s\n",
      "[801/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33732, val loss: 0.37792, in 4.448s\n",
      "[802/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33728, val loss: 0.37791, in 4.045s\n",
      "[803/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33726, val loss: 0.37789, in 4.329s\n",
      "[804/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33721, val loss: 0.37789, in 4.260s\n",
      "[805/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33718, val loss: 0.37789, in 4.309s\n",
      "[806/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33714, val loss: 0.37787, in 3.999s\n",
      "[807/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33710, val loss: 0.37786, in 3.995s\n",
      "[808/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33708, val loss: 0.37783, in 3.975s\n",
      "[809/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33704, val loss: 0.37781, in 4.162s\n",
      "[810/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33702, val loss: 0.37781, in 3.995s\n",
      "[811/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33700, val loss: 0.37780, in 3.872s\n",
      "[812/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33697, val loss: 0.37779, in 4.527s\n",
      "[813/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33695, val loss: 0.37779, in 5.395s\n",
      "[814/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33689, val loss: 0.37776, in 4.078s\n",
      "[815/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33687, val loss: 0.37776, in 3.919s\n",
      "[816/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33682, val loss: 0.37776, in 4.061s\n",
      "[817/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33678, val loss: 0.37774, in 4.060s\n",
      "[818/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33674, val loss: 0.37770, in 3.412s\n",
      "[819/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.33670, val loss: 0.37771, in 3.626s\n",
      "[820/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33666, val loss: 0.37774, in 3.347s\n",
      "[821/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33663, val loss: 0.37771, in 2.414s\n",
      "[822/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33659, val loss: 0.37767, in 2.098s\n",
      "[823/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33656, val loss: 0.37765, in 2.759s\n",
      "[824/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33653, val loss: 0.37763, in 3.410s\n",
      "[825/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33651, val loss: 0.37760, in 3.945s\n",
      "[826/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33646, val loss: 0.37757, in 4.060s\n",
      "[827/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33641, val loss: 0.37754, in 3.979s\n",
      "[828/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33639, val loss: 0.37753, in 4.020s\n",
      "[829/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33636, val loss: 0.37751, in 4.705s\n",
      "[830/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33634, val loss: 0.37750, in 3.808s\n",
      "[831/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33630, val loss: 0.37749, in 4.097s\n",
      "[832/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33627, val loss: 0.37748, in 3.906s\n",
      "[833/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33623, val loss: 0.37746, in 4.059s\n",
      "[834/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33619, val loss: 0.37744, in 3.283s\n",
      "[835/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33616, val loss: 0.37743, in 3.339s\n",
      "[836/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33612, val loss: 0.37740, in 4.323s\n",
      "[837/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33608, val loss: 0.37736, in 4.500s\n",
      "[838/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33604, val loss: 0.37734, in 3.902s\n",
      "[839/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33600, val loss: 0.37733, in 3.833s\n",
      "[840/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33597, val loss: 0.37732, in 3.815s\n",
      "[841/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33593, val loss: 0.37730, in 3.733s\n",
      "[842/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33589, val loss: 0.37728, in 3.616s\n",
      "[843/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33585, val loss: 0.37723, in 3.805s\n",
      "[844/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33581, val loss: 0.37720, in 3.844s\n",
      "[845/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33576, val loss: 0.37717, in 3.119s\n",
      "[846/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33571, val loss: 0.37714, in 3.741s\n",
      "[847/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33567, val loss: 0.37713, in 3.724s\n",
      "[848/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33562, val loss: 0.37711, in 3.737s\n",
      "[849/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33560, val loss: 0.37709, in 4.050s\n",
      "[850/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33555, val loss: 0.37705, in 4.010s\n",
      "[851/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33550, val loss: 0.37705, in 3.861s\n",
      "[852/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33546, val loss: 0.37705, in 4.055s\n",
      "[853/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33543, val loss: 0.37705, in 5.138s\n",
      "[854/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33540, val loss: 0.37706, in 3.981s\n",
      "[855/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33537, val loss: 0.37704, in 3.887s\n",
      "[856/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33534, val loss: 0.37702, in 3.806s\n",
      "[857/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33529, val loss: 0.37702, in 3.843s\n",
      "[858/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33524, val loss: 0.37696, in 4.011s\n",
      "[859/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33519, val loss: 0.37695, in 4.303s\n",
      "[860/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33515, val loss: 0.37692, in 4.183s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[861/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33512, val loss: 0.37691, in 3.852s\n",
      "[862/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33510, val loss: 0.37691, in 3.934s\n",
      "[863/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33506, val loss: 0.37690, in 4.046s\n",
      "[864/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33502, val loss: 0.37689, in 4.058s\n",
      "[865/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33498, val loss: 0.37687, in 4.090s\n",
      "[866/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33494, val loss: 0.37686, in 4.338s\n",
      "[867/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33491, val loss: 0.37685, in 3.925s\n",
      "[868/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33487, val loss: 0.37680, in 2.328s\n",
      "[869/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33482, val loss: 0.37677, in 4.107s\n",
      "[870/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33479, val loss: 0.37672, in 3.906s\n",
      "[871/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33476, val loss: 0.37670, in 4.023s\n",
      "[872/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33471, val loss: 0.37669, in 3.796s\n",
      "[873/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33467, val loss: 0.37664, in 3.739s\n",
      "[874/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33464, val loss: 0.37661, in 4.616s\n",
      "[875/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33460, val loss: 0.37658, in 5.423s\n",
      "[876/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33455, val loss: 0.37656, in 4.036s\n",
      "[877/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33450, val loss: 0.37654, in 3.990s\n",
      "[878/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33446, val loss: 0.37651, in 4.170s\n",
      "[879/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33441, val loss: 0.37647, in 3.954s\n",
      "[880/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33438, val loss: 0.37648, in 3.020s\n",
      "[881/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33434, val loss: 0.37647, in 3.116s\n",
      "[882/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33431, val loss: 0.37645, in 2.774s\n",
      "[883/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33427, val loss: 0.37643, in 3.876s\n",
      "[884/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33423, val loss: 0.37643, in 4.061s\n",
      "[885/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33420, val loss: 0.37640, in 3.767s\n",
      "[886/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33415, val loss: 0.37642, in 3.983s\n",
      "[887/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33413, val loss: 0.37641, in 3.546s\n",
      "[888/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33411, val loss: 0.37641, in 3.033s\n",
      "[889/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33409, val loss: 0.37638, in 2.705s\n",
      "[890/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33404, val loss: 0.37635, in 3.309s\n",
      "[891/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33401, val loss: 0.37634, in 3.954s\n",
      "[892/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33397, val loss: 0.37631, in 3.380s\n",
      "[893/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.33394, val loss: 0.37628, in 2.280s\n",
      "[894/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33391, val loss: 0.37629, in 4.442s\n",
      "[895/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33387, val loss: 0.37627, in 4.098s\n",
      "[896/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33383, val loss: 0.37624, in 4.362s\n",
      "[897/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33379, val loss: 0.37625, in 4.476s\n",
      "[898/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33375, val loss: 0.37625, in 4.107s\n",
      "[899/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33371, val loss: 0.37623, in 4.999s\n",
      "[900/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33368, val loss: 0.37624, in 4.398s\n",
      "[901/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33364, val loss: 0.37626, in 2.480s\n",
      "[902/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.33361, val loss: 0.37622, in 2.458s\n",
      "[903/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33358, val loss: 0.37621, in 2.997s\n",
      "[904/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33354, val loss: 0.37619, in 3.939s\n",
      "[905/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33351, val loss: 0.37617, in 3.286s\n",
      "[906/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33348, val loss: 0.37618, in 3.976s\n",
      "[907/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33345, val loss: 0.37615, in 4.717s\n",
      "[908/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33342, val loss: 0.37613, in 4.390s\n",
      "[909/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33338, val loss: 0.37611, in 3.692s\n",
      "[910/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33334, val loss: 0.37610, in 3.633s\n",
      "[911/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33331, val loss: 0.37609, in 3.709s\n",
      "[912/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.33329, val loss: 0.37606, in 4.060s\n",
      "[913/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33325, val loss: 0.37603, in 5.158s\n",
      "[914/5000] 1 tree, 31 leaves, max depth = 21, train loss: 0.33322, val loss: 0.37602, in 2.802s\n",
      "[915/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33319, val loss: 0.37603, in 2.830s\n",
      "[916/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33317, val loss: 0.37601, in 3.845s\n",
      "[917/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33314, val loss: 0.37598, in 2.382s\n",
      "[918/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33312, val loss: 0.37595, in 2.195s\n",
      "[919/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33310, val loss: 0.37594, in 2.822s\n",
      "[920/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.33307, val loss: 0.37593, in 4.015s\n",
      "[921/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33303, val loss: 0.37590, in 4.390s\n",
      "[922/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33300, val loss: 0.37589, in 4.276s\n",
      "[923/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33295, val loss: 0.37587, in 5.557s\n",
      "[924/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33291, val loss: 0.37586, in 4.666s\n",
      "[925/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33287, val loss: 0.37586, in 4.082s\n",
      "[926/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33284, val loss: 0.37587, in 5.004s\n",
      "[927/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33281, val loss: 0.37584, in 4.509s\n",
      "[928/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33278, val loss: 0.37584, in 3.505s\n",
      "[929/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33274, val loss: 0.37584, in 3.162s\n",
      "[930/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33269, val loss: 0.37583, in 2.713s\n",
      "[931/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33266, val loss: 0.37583, in 3.188s\n",
      "[932/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33263, val loss: 0.37580, in 3.572s\n",
      "[933/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33258, val loss: 0.37575, in 3.233s\n",
      "[934/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33255, val loss: 0.37572, in 9.102s\n",
      "[935/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33252, val loss: 0.37569, in 5.109s\n",
      "[936/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33248, val loss: 0.37570, in 3.895s\n",
      "[937/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33245, val loss: 0.37567, in 4.580s\n",
      "[938/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33242, val loss: 0.37568, in 3.579s\n",
      "[939/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33240, val loss: 0.37567, in 4.099s\n",
      "[940/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33237, val loss: 0.37566, in 3.920s\n",
      "[941/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33234, val loss: 0.37567, in 2.208s\n",
      "[942/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33230, val loss: 0.37567, in 2.964s\n",
      "[943/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33227, val loss: 0.37566, in 3.798s\n",
      "[944/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33224, val loss: 0.37566, in 4.053s\n",
      "[945/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33221, val loss: 0.37565, in 3.398s\n",
      "[946/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33218, val loss: 0.37564, in 3.560s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[947/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33215, val loss: 0.37563, in 4.686s\n",
      "[948/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33212, val loss: 0.37562, in 3.770s\n",
      "[949/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33208, val loss: 0.37561, in 3.960s\n",
      "[950/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33206, val loss: 0.37560, in 4.013s\n",
      "[951/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33201, val loss: 0.37556, in 4.017s\n",
      "[952/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33197, val loss: 0.37554, in 4.138s\n",
      "[953/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33195, val loss: 0.37552, in 5.378s\n",
      "[954/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33192, val loss: 0.37550, in 12.780s\n",
      "[955/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.33190, val loss: 0.37549, in 4.958s\n",
      "[956/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33188, val loss: 0.37547, in 3.416s\n",
      "[957/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33184, val loss: 0.37544, in 3.898s\n",
      "[958/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33181, val loss: 0.37542, in 4.110s\n",
      "[959/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33179, val loss: 0.37541, in 4.349s\n",
      "[960/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33176, val loss: 0.37538, in 3.856s\n",
      "[961/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33172, val loss: 0.37538, in 3.945s\n",
      "[962/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33169, val loss: 0.37538, in 3.919s\n",
      "[963/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33165, val loss: 0.37536, in 3.933s\n",
      "[964/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33162, val loss: 0.37534, in 4.053s\n",
      "[965/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33159, val loss: 0.37535, in 3.883s\n",
      "[966/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33155, val loss: 0.37533, in 2.914s\n",
      "[967/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33151, val loss: 0.37529, in 2.172s\n",
      "[968/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33149, val loss: 0.37528, in 2.303s\n",
      "[969/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33144, val loss: 0.37524, in 3.329s\n",
      "[970/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33140, val loss: 0.37522, in 4.082s\n",
      "[971/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33137, val loss: 0.37521, in 4.329s\n",
      "[972/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33134, val loss: 0.37519, in 4.223s\n",
      "[973/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33130, val loss: 0.37519, in 4.231s\n",
      "[974/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33126, val loss: 0.37520, in 5.102s\n",
      "[975/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33122, val loss: 0.37518, in 4.090s\n",
      "[976/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33118, val loss: 0.37513, in 3.989s\n",
      "[977/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33114, val loss: 0.37512, in 4.089s\n",
      "[978/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33112, val loss: 0.37512, in 7.894s\n",
      "[979/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33108, val loss: 0.37509, in 4.185s\n",
      "[980/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33105, val loss: 0.37508, in 4.911s\n",
      "[981/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33101, val loss: 0.37509, in 4.072s\n",
      "[982/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33098, val loss: 0.37507, in 3.751s\n",
      "[983/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33094, val loss: 0.37504, in 3.862s\n",
      "[984/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.33091, val loss: 0.37502, in 3.892s\n",
      "[985/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33088, val loss: 0.37502, in 4.199s\n",
      "[986/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33085, val loss: 0.37500, in 9.634s\n",
      "[987/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33082, val loss: 0.37500, in 3.154s\n",
      "[988/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33079, val loss: 0.37499, in 3.685s\n",
      "[989/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33077, val loss: 0.37499, in 3.709s\n",
      "[990/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33072, val loss: 0.37496, in 2.154s\n",
      "[991/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33069, val loss: 0.37495, in 4.080s\n",
      "[992/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.33064, val loss: 0.37495, in 4.044s\n",
      "[993/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33061, val loss: 0.37495, in 4.199s\n",
      "[994/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33059, val loss: 0.37494, in 4.412s\n",
      "[995/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.33055, val loss: 0.37492, in 4.423s\n",
      "[996/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33053, val loss: 0.37493, in 3.873s\n",
      "[997/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33050, val loss: 0.37491, in 4.250s\n",
      "[998/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.33047, val loss: 0.37486, in 4.486s\n",
      "[999/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33045, val loss: 0.37486, in 4.664s\n",
      "[1000/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33042, val loss: 0.37487, in 4.087s\n",
      "[1001/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33039, val loss: 0.37485, in 4.309s\n",
      "[1002/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33037, val loss: 0.37485, in 4.724s\n",
      "[1003/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33035, val loss: 0.37482, in 4.397s\n",
      "[1004/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33032, val loss: 0.37481, in 12.660s\n",
      "[1005/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.33030, val loss: 0.37478, in 3.927s\n",
      "[1006/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.33028, val loss: 0.37479, in 4.222s\n",
      "[1007/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33026, val loss: 0.37478, in 4.740s\n",
      "[1008/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.33022, val loss: 0.37475, in 4.308s\n",
      "[1009/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.33019, val loss: 0.37477, in 8.878s\n",
      "[1010/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.33016, val loss: 0.37474, in 3.026s\n",
      "[1011/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.33013, val loss: 0.37472, in 2.163s\n",
      "[1012/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.33010, val loss: 0.37471, in 2.097s\n",
      "[1013/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.33007, val loss: 0.37471, in 2.953s\n",
      "[1014/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.33004, val loss: 0.37470, in 4.663s\n",
      "[1015/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.33002, val loss: 0.37469, in 4.575s\n",
      "[1016/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32999, val loss: 0.37468, in 4.251s\n",
      "[1017/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32996, val loss: 0.37466, in 4.231s\n",
      "[1018/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32993, val loss: 0.37465, in 3.698s\n",
      "[1019/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32989, val loss: 0.37466, in 3.901s\n",
      "[1020/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32986, val loss: 0.37461, in 4.659s\n",
      "[1021/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32984, val loss: 0.37460, in 5.535s\n",
      "[1022/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32981, val loss: 0.37459, in 4.137s\n",
      "[1023/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32977, val loss: 0.37460, in 4.051s\n",
      "[1024/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32973, val loss: 0.37458, in 4.110s\n",
      "[1025/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32970, val loss: 0.37458, in 4.640s\n",
      "[1026/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32966, val loss: 0.37456, in 4.684s\n",
      "[1027/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32963, val loss: 0.37456, in 7.112s\n",
      "[1028/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32960, val loss: 0.37458, in 4.927s\n",
      "[1029/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32958, val loss: 0.37456, in 3.828s\n",
      "[1030/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32955, val loss: 0.37453, in 4.221s\n",
      "[1031/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32951, val loss: 0.37453, in 4.335s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1032/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32949, val loss: 0.37449, in 4.854s\n",
      "[1033/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32945, val loss: 0.37449, in 4.557s\n",
      "[1034/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32942, val loss: 0.37445, in 2.965s\n",
      "[1035/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32939, val loss: 0.37445, in 2.144s\n",
      "[1036/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32936, val loss: 0.37442, in 3.284s\n",
      "[1037/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32932, val loss: 0.37440, in 4.285s\n",
      "[1038/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.32928, val loss: 0.37438, in 4.148s\n",
      "[1039/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32924, val loss: 0.37436, in 4.387s\n",
      "[1040/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32920, val loss: 0.37435, in 4.111s\n",
      "[1041/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32918, val loss: 0.37435, in 4.002s\n",
      "[1042/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32915, val loss: 0.37433, in 4.721s\n",
      "[1043/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32911, val loss: 0.37434, in 3.964s\n",
      "[1044/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32909, val loss: 0.37433, in 3.924s\n",
      "[1045/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32907, val loss: 0.37430, in 4.131s\n",
      "[1046/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32903, val loss: 0.37428, in 4.014s\n",
      "[1047/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32901, val loss: 0.37427, in 3.946s\n",
      "[1048/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32899, val loss: 0.37424, in 4.269s\n",
      "[1049/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32896, val loss: 0.37423, in 4.910s\n",
      "[1050/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32892, val loss: 0.37420, in 4.239s\n",
      "[1051/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32890, val loss: 0.37420, in 3.886s\n",
      "[1052/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32886, val loss: 0.37417, in 4.702s\n",
      "[1053/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.32884, val loss: 0.37416, in 4.093s\n",
      "[1054/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32880, val loss: 0.37416, in 4.193s\n",
      "[1055/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32877, val loss: 0.37414, in 4.105s\n",
      "[1056/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32874, val loss: 0.37413, in 4.690s\n",
      "[1057/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32871, val loss: 0.37413, in 4.271s\n",
      "[1058/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32870, val loss: 0.37411, in 3.671s\n",
      "[1059/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32866, val loss: 0.37409, in 2.931s\n",
      "[1060/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32864, val loss: 0.37408, in 2.277s\n",
      "[1061/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32861, val loss: 0.37409, in 2.730s\n",
      "[1062/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32858, val loss: 0.37408, in 4.131s\n",
      "[1063/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32854, val loss: 0.37404, in 4.117s\n",
      "[1064/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32851, val loss: 0.37403, in 5.347s\n",
      "[1065/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32848, val loss: 0.37403, in 4.120s\n",
      "[1066/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32844, val loss: 0.37403, in 3.820s\n",
      "[1067/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32840, val loss: 0.37402, in 3.876s\n",
      "[1068/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32837, val loss: 0.37402, in 3.865s\n",
      "[1069/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32832, val loss: 0.37397, in 4.177s\n",
      "[1070/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32830, val loss: 0.37397, in 3.950s\n",
      "[1071/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32826, val loss: 0.37397, in 3.952s\n",
      "[1072/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32824, val loss: 0.37397, in 4.269s\n",
      "[1073/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32820, val loss: 0.37394, in 3.871s\n",
      "[1074/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32817, val loss: 0.37390, in 3.810s\n",
      "[1075/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32813, val loss: 0.37391, in 3.604s\n",
      "[1076/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32810, val loss: 0.37389, in 3.837s\n",
      "[1077/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32807, val loss: 0.37387, in 3.664s\n",
      "[1078/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32804, val loss: 0.37387, in 3.835s\n",
      "[1079/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32800, val loss: 0.37385, in 4.189s\n",
      "[1080/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32798, val loss: 0.37387, in 3.684s\n",
      "[1081/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.32793, val loss: 0.37386, in 3.914s\n",
      "[1082/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32790, val loss: 0.37388, in 3.977s\n",
      "[1083/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32787, val loss: 0.37387, in 3.906s\n",
      "[1084/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32785, val loss: 0.37388, in 3.869s\n",
      "[1085/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32781, val loss: 0.37386, in 3.403s\n",
      "[1086/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32779, val loss: 0.37385, in 2.554s\n",
      "[1087/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32777, val loss: 0.37383, in 2.189s\n",
      "[1088/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32773, val loss: 0.37382, in 3.590s\n",
      "[1089/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.32770, val loss: 0.37381, in 3.840s\n",
      "[1090/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32767, val loss: 0.37378, in 3.898s\n",
      "[1091/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32766, val loss: 0.37378, in 3.865s\n",
      "[1092/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32763, val loss: 0.37377, in 4.155s\n",
      "[1093/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32760, val loss: 0.37376, in 3.824s\n",
      "[1094/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32758, val loss: 0.37375, in 3.834s\n",
      "[1095/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32756, val loss: 0.37373, in 5.182s\n",
      "[1096/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32754, val loss: 0.37371, in 5.013s\n",
      "[1097/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32751, val loss: 0.37370, in 4.364s\n",
      "[1098/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32748, val loss: 0.37367, in 4.277s\n",
      "[1099/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32745, val loss: 0.37365, in 4.644s\n",
      "[1100/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32742, val loss: 0.37365, in 4.670s\n",
      "[1101/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32740, val loss: 0.37365, in 5.043s\n",
      "[1102/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32737, val loss: 0.37363, in 5.192s\n",
      "[1103/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32735, val loss: 0.37364, in 5.017s\n",
      "[1104/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32732, val loss: 0.37362, in 4.128s\n",
      "[1105/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32729, val loss: 0.37361, in 4.111s\n",
      "[1106/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32727, val loss: 0.37360, in 4.076s\n",
      "[1107/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32723, val loss: 0.37361, in 3.890s\n",
      "[1108/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32720, val loss: 0.37357, in 4.911s\n",
      "[1109/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32718, val loss: 0.37357, in 4.490s\n",
      "[1110/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32715, val loss: 0.37354, in 3.795s\n",
      "[1111/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32713, val loss: 0.37352, in 2.684s\n",
      "[1112/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32710, val loss: 0.37352, in 2.170s\n",
      "[1113/5000] 1 tree, 31 leaves, max depth = 22, train loss: 0.32707, val loss: 0.37350, in 2.122s\n",
      "[1114/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32703, val loss: 0.37348, in 2.132s\n",
      "[1115/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32701, val loss: 0.37346, in 2.284s\n",
      "[1116/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32698, val loss: 0.37346, in 3.691s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1117/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32694, val loss: 0.37346, in 4.158s\n",
      "[1118/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32691, val loss: 0.37344, in 4.338s\n",
      "[1119/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32689, val loss: 0.37343, in 3.887s\n",
      "[1120/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32686, val loss: 0.37342, in 3.391s\n",
      "[1121/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32684, val loss: 0.37341, in 3.837s\n",
      "[1122/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32682, val loss: 0.37340, in 3.801s\n",
      "[1123/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32680, val loss: 0.37337, in 3.897s\n",
      "[1124/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32677, val loss: 0.37336, in 3.810s\n",
      "[1125/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32674, val loss: 0.37334, in 4.700s\n",
      "[1126/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32670, val loss: 0.37332, in 5.261s\n",
      "[1127/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32667, val loss: 0.37331, in 4.563s\n",
      "[1128/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32664, val loss: 0.37329, in 3.990s\n",
      "[1129/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32662, val loss: 0.37329, in 3.835s\n",
      "[1130/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32660, val loss: 0.37327, in 4.341s\n",
      "[1131/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32657, val loss: 0.37327, in 3.898s\n",
      "[1132/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32654, val loss: 0.37326, in 3.965s\n",
      "[1133/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32650, val loss: 0.37325, in 4.541s\n",
      "[1134/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32647, val loss: 0.37321, in 4.389s\n",
      "[1135/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32644, val loss: 0.37322, in 3.885s\n",
      "[1136/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32642, val loss: 0.37323, in 3.304s\n",
      "[1137/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32640, val loss: 0.37322, in 2.643s\n",
      "[1138/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32638, val loss: 0.37321, in 3.670s\n",
      "[1139/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32636, val loss: 0.37320, in 3.735s\n",
      "[1140/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32634, val loss: 0.37318, in 3.868s\n",
      "[1141/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32630, val loss: 0.37314, in 4.526s\n",
      "[1142/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32628, val loss: 0.37314, in 3.826s\n",
      "[1143/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32625, val loss: 0.37313, in 3.835s\n",
      "[1144/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32622, val loss: 0.37313, in 3.939s\n",
      "[1145/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32619, val loss: 0.37310, in 3.858s\n",
      "[1146/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32617, val loss: 0.37310, in 3.919s\n",
      "[1147/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32615, val loss: 0.37309, in 4.213s\n",
      "[1148/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32613, val loss: 0.37310, in 4.264s\n",
      "[1149/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32610, val loss: 0.37308, in 4.298s\n",
      "[1150/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32608, val loss: 0.37307, in 3.925s\n",
      "[1151/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32606, val loss: 0.37306, in 3.980s\n",
      "[1152/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32605, val loss: 0.37307, in 3.817s\n",
      "[1153/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32602, val loss: 0.37306, in 3.860s\n",
      "[1154/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32599, val loss: 0.37306, in 3.865s\n",
      "[1155/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32596, val loss: 0.37304, in 4.864s\n",
      "[1156/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32592, val loss: 0.37304, in 4.437s\n",
      "[1157/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32589, val loss: 0.37304, in 3.887s\n",
      "[1158/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32586, val loss: 0.37302, in 3.817s\n",
      "[1159/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32583, val loss: 0.37300, in 3.865s\n",
      "[1160/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32580, val loss: 0.37298, in 3.216s\n",
      "[1161/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32577, val loss: 0.37295, in 2.287s\n",
      "[1162/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32574, val loss: 0.37293, in 3.307s\n",
      "[1163/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32571, val loss: 0.37295, in 4.298s\n",
      "[1164/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32569, val loss: 0.37296, in 4.484s\n",
      "[1165/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32565, val loss: 0.37293, in 3.966s\n",
      "[1166/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32561, val loss: 0.37293, in 3.854s\n",
      "[1167/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32558, val loss: 0.37294, in 4.055s\n",
      "[1168/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32555, val loss: 0.37293, in 3.956s\n",
      "[1169/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32552, val loss: 0.37294, in 4.125s\n",
      "[1170/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32549, val loss: 0.37293, in 4.548s\n",
      "[1171/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32546, val loss: 0.37292, in 4.969s\n",
      "[1172/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32543, val loss: 0.37291, in 4.008s\n",
      "[1173/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32540, val loss: 0.37291, in 3.859s\n",
      "[1174/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32537, val loss: 0.37292, in 4.335s\n",
      "[1175/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32534, val loss: 0.37291, in 4.169s\n",
      "[1176/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32531, val loss: 0.37291, in 4.000s\n",
      "[1177/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32528, val loss: 0.37289, in 4.601s\n",
      "[1178/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32525, val loss: 0.37289, in 4.676s\n",
      "[1179/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32522, val loss: 0.37290, in 3.915s\n",
      "[1180/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32519, val loss: 0.37288, in 4.094s\n",
      "[1181/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32515, val loss: 0.37287, in 4.102s\n",
      "[1182/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32513, val loss: 0.37285, in 4.060s\n",
      "[1183/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32511, val loss: 0.37284, in 3.893s\n",
      "[1184/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32508, val loss: 0.37283, in 4.020s\n",
      "[1185/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32506, val loss: 0.37284, in 4.261s\n",
      "[1186/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32504, val loss: 0.37283, in 2.652s\n",
      "[1187/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32502, val loss: 0.37285, in 4.950s\n",
      "[1188/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32499, val loss: 0.37282, in 4.472s\n",
      "[1189/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32496, val loss: 0.37279, in 4.667s\n",
      "[1190/5000] 1 tree, 31 leaves, max depth = 22, train loss: 0.32494, val loss: 0.37278, in 4.621s\n",
      "[1191/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32491, val loss: 0.37276, in 5.471s\n",
      "[1192/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32488, val loss: 0.37274, in 5.175s\n",
      "[1193/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32485, val loss: 0.37275, in 4.040s\n",
      "[1194/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32482, val loss: 0.37271, in 5.811s\n",
      "[1195/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32480, val loss: 0.37270, in 6.052s\n",
      "[1196/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32478, val loss: 0.37267, in 5.229s\n",
      "[1197/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32475, val loss: 0.37266, in 6.633s\n",
      "[1198/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32473, val loss: 0.37264, in 5.286s\n",
      "[1199/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32470, val loss: 0.37265, in 4.950s\n",
      "[1200/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32466, val loss: 0.37266, in 5.323s\n",
      "[1201/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32463, val loss: 0.37267, in 4.942s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1202/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32461, val loss: 0.37266, in 4.176s\n",
      "[1203/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.32459, val loss: 0.37265, in 5.293s\n",
      "[1204/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32456, val loss: 0.37264, in 5.366s\n",
      "[1205/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32454, val loss: 0.37262, in 4.033s\n",
      "[1206/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32451, val loss: 0.37260, in 3.059s\n",
      "[1207/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32448, val loss: 0.37259, in 4.290s\n",
      "[1208/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32446, val loss: 0.37259, in 4.596s\n",
      "[1209/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32443, val loss: 0.37256, in 4.819s\n",
      "[1210/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32441, val loss: 0.37256, in 5.748s\n",
      "[1211/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32438, val loss: 0.37257, in 4.260s\n",
      "[1212/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32436, val loss: 0.37256, in 4.212s\n",
      "[1213/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32434, val loss: 0.37256, in 4.276s\n",
      "[1214/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32432, val loss: 0.37256, in 4.463s\n",
      "[1215/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.32429, val loss: 0.37255, in 4.194s\n",
      "[1216/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.32426, val loss: 0.37253, in 4.919s\n",
      "[1217/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.32425, val loss: 0.37253, in 5.181s\n",
      "[1218/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32423, val loss: 0.37252, in 4.559s\n",
      "[1219/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32421, val loss: 0.37249, in 4.370s\n",
      "[1220/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32419, val loss: 0.37248, in 3.924s\n",
      "[1221/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32417, val loss: 0.37247, in 4.973s\n",
      "[1222/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.32414, val loss: 0.37249, in 4.967s\n",
      "[1223/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32410, val loss: 0.37249, in 4.759s\n",
      "[1224/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32407, val loss: 0.37248, in 4.039s\n",
      "[1225/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32404, val loss: 0.37248, in 3.831s\n",
      "[1226/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32401, val loss: 0.37248, in 3.943s\n",
      "[1227/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32398, val loss: 0.37246, in 3.708s\n",
      "[1228/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32396, val loss: 0.37246, in 3.771s\n",
      "[1229/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32393, val loss: 0.37245, in 2.619s\n",
      "[1230/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32390, val loss: 0.37244, in 2.320s\n",
      "[1231/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32387, val loss: 0.37242, in 4.217s\n",
      "[1232/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32384, val loss: 0.37241, in 4.459s\n",
      "[1233/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32382, val loss: 0.37239, in 3.995s\n",
      "[1234/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32378, val loss: 0.37237, in 3.941s\n",
      "[1235/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32375, val loss: 0.37236, in 3.826s\n",
      "[1236/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32371, val loss: 0.37236, in 3.568s\n",
      "[1237/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32369, val loss: 0.37235, in 3.760s\n",
      "[1238/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32367, val loss: 0.37233, in 4.159s\n",
      "[1239/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32364, val loss: 0.37230, in 4.940s\n",
      "[1240/5000] 1 tree, 31 leaves, max depth = 20, train loss: 0.32360, val loss: 0.37228, in 3.751s\n",
      "[1241/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32358, val loss: 0.37226, in 3.565s\n",
      "[1242/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32355, val loss: 0.37224, in 3.753s\n",
      "[1243/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32352, val loss: 0.37225, in 3.861s\n",
      "[1244/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32350, val loss: 0.37223, in 4.048s\n",
      "[1245/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32348, val loss: 0.37221, in 4.211s\n",
      "[1246/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32346, val loss: 0.37221, in 4.564s\n",
      "[1247/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32343, val loss: 0.37217, in 4.300s\n",
      "[1248/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.32341, val loss: 0.37217, in 4.291s\n",
      "[1249/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32339, val loss: 0.37214, in 2.778s\n",
      "[1250/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32336, val loss: 0.37216, in 2.525s\n",
      "[1251/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32334, val loss: 0.37215, in 3.945s\n",
      "[1252/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32332, val loss: 0.37216, in 3.901s\n",
      "[1253/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32329, val loss: 0.37214, in 3.747s\n",
      "[1254/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32326, val loss: 0.37214, in 4.938s\n",
      "[1255/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32323, val loss: 0.37213, in 2.970s\n",
      "[1256/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32321, val loss: 0.37214, in 2.197s\n",
      "[1257/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32319, val loss: 0.37212, in 2.508s\n",
      "[1258/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32316, val loss: 0.37209, in 3.098s\n",
      "[1259/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32313, val loss: 0.37209, in 3.553s\n",
      "[1260/5000] 1 tree, 31 leaves, max depth = 21, train loss: 0.32310, val loss: 0.37206, in 3.793s\n",
      "[1261/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32307, val loss: 0.37206, in 4.050s\n",
      "[1262/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32304, val loss: 0.37206, in 3.797s\n",
      "[1263/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32301, val loss: 0.37203, in 3.626s\n",
      "[1264/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32297, val loss: 0.37201, in 3.918s\n",
      "[1265/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32294, val loss: 0.37200, in 3.375s\n",
      "[1266/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32292, val loss: 0.37201, in 3.803s\n",
      "[1267/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32290, val loss: 0.37200, in 3.796s\n",
      "[1268/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32287, val loss: 0.37199, in 3.796s\n",
      "[1269/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32285, val loss: 0.37198, in 3.852s\n",
      "[1270/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32282, val loss: 0.37196, in 4.291s\n",
      "[1271/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32279, val loss: 0.37194, in 4.543s\n",
      "[1272/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32277, val loss: 0.37192, in 3.755s\n",
      "[1273/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32275, val loss: 0.37194, in 3.625s\n",
      "[1274/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32273, val loss: 0.37193, in 3.752s\n",
      "[1275/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32272, val loss: 0.37193, in 3.746s\n",
      "[1276/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32269, val loss: 0.37192, in 4.044s\n",
      "[1277/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32268, val loss: 0.37192, in 3.768s\n",
      "[1278/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32266, val loss: 0.37191, in 3.735s\n",
      "[1279/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32264, val loss: 0.37188, in 4.185s\n",
      "[1280/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32261, val loss: 0.37187, in 2.545s\n",
      "[1281/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32259, val loss: 0.37187, in 2.095s\n",
      "[1282/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32257, val loss: 0.37186, in 3.100s\n",
      "[1283/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32254, val loss: 0.37187, in 3.777s\n",
      "[1284/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32251, val loss: 0.37185, in 3.814s\n",
      "[1285/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32248, val loss: 0.37185, in 3.743s\n",
      "[1286/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32246, val loss: 0.37185, in 3.742s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1287/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32244, val loss: 0.37183, in 4.305s\n",
      "[1288/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32241, val loss: 0.37182, in 4.205s\n",
      "[1289/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32239, val loss: 0.37181, in 3.762s\n",
      "[1290/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32237, val loss: 0.37181, in 3.981s\n",
      "[1291/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32234, val loss: 0.37179, in 3.810s\n",
      "[1292/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32231, val loss: 0.37175, in 3.491s\n",
      "[1293/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32228, val loss: 0.37174, in 3.955s\n",
      "[1294/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32226, val loss: 0.37175, in 3.848s\n",
      "[1295/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32224, val loss: 0.37175, in 4.170s\n",
      "[1296/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.32221, val loss: 0.37174, in 3.930s\n",
      "[1297/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32218, val loss: 0.37173, in 3.703s\n",
      "[1298/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32216, val loss: 0.37173, in 3.643s\n",
      "[1299/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32212, val loss: 0.37172, in 3.677s\n",
      "[1300/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32209, val loss: 0.37170, in 3.783s\n",
      "[1301/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32206, val loss: 0.37170, in 3.721s\n",
      "[1302/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32202, val loss: 0.37167, in 4.042s\n",
      "[1303/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32199, val loss: 0.37167, in 4.699s\n",
      "[1304/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32197, val loss: 0.37165, in 3.493s\n",
      "[1305/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32195, val loss: 0.37163, in 2.311s\n",
      "[1306/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32192, val loss: 0.37165, in 2.281s\n",
      "[1307/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32189, val loss: 0.37163, in 3.742s\n",
      "[1308/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32186, val loss: 0.37163, in 3.719s\n",
      "[1309/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32183, val loss: 0.37162, in 3.904s\n",
      "[1310/5000] 1 tree, 31 leaves, max depth = 21, train loss: 0.32180, val loss: 0.37158, in 3.875s\n",
      "[1311/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32178, val loss: 0.37156, in 3.942s\n",
      "[1312/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32176, val loss: 0.37159, in 3.923s\n",
      "[1313/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32173, val loss: 0.37158, in 3.780s\n",
      "[1314/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32171, val loss: 0.37155, in 3.659s\n",
      "[1315/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32168, val loss: 0.37155, in 5.404s\n",
      "[1316/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32166, val loss: 0.37154, in 3.901s\n",
      "[1317/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32164, val loss: 0.37152, in 3.767s\n",
      "[1318/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32161, val loss: 0.37152, in 3.841s\n",
      "[1319/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32158, val loss: 0.37148, in 4.215s\n",
      "[1320/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32156, val loss: 0.37147, in 3.615s\n",
      "[1321/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32152, val loss: 0.37142, in 3.707s\n",
      "[1322/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32149, val loss: 0.37140, in 3.843s\n",
      "[1323/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32148, val loss: 0.37140, in 3.668s\n",
      "[1324/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32144, val loss: 0.37139, in 3.748s\n",
      "[1325/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32142, val loss: 0.37141, in 3.987s\n",
      "[1326/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.32138, val loss: 0.37140, in 3.907s\n",
      "[1327/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32136, val loss: 0.37139, in 4.127s\n",
      "[1328/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32133, val loss: 0.37137, in 4.077s\n",
      "[1329/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32130, val loss: 0.37137, in 3.358s\n",
      "[1330/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32129, val loss: 0.37137, in 2.317s\n",
      "[1331/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32126, val loss: 0.37136, in 2.105s\n",
      "[1332/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32124, val loss: 0.37135, in 2.219s\n",
      "[1333/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32121, val loss: 0.37133, in 3.711s\n",
      "[1334/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32119, val loss: 0.37136, in 3.489s\n",
      "[1335/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32116, val loss: 0.37137, in 3.827s\n",
      "[1336/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32114, val loss: 0.37136, in 4.195s\n",
      "[1337/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.32111, val loss: 0.37134, in 3.798s\n",
      "[1338/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32109, val loss: 0.37132, in 3.784s\n",
      "[1339/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32106, val loss: 0.37133, in 3.719s\n",
      "[1340/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32103, val loss: 0.37130, in 3.699s\n",
      "[1341/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.32100, val loss: 0.37128, in 3.662s\n",
      "[1342/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32098, val loss: 0.37129, in 3.828s\n",
      "[1343/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32095, val loss: 0.37128, in 3.826s\n",
      "[1344/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32093, val loss: 0.37128, in 3.776s\n",
      "[1345/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32090, val loss: 0.37126, in 4.437s\n",
      "[1346/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32087, val loss: 0.37125, in 3.996s\n",
      "[1347/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32084, val loss: 0.37120, in 3.674s\n",
      "[1348/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32081, val loss: 0.37118, in 2.804s\n",
      "[1349/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.32078, val loss: 0.37117, in 3.616s\n",
      "[1350/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32075, val loss: 0.37117, in 3.763s\n",
      "[1351/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32073, val loss: 0.37117, in 3.882s\n",
      "[1352/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32070, val loss: 0.37116, in 3.954s\n",
      "[1353/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32068, val loss: 0.37115, in 3.696s\n",
      "[1354/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32065, val loss: 0.37116, in 3.799s\n",
      "[1355/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32062, val loss: 0.37111, in 3.842s\n",
      "[1356/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32059, val loss: 0.37109, in 3.717s\n",
      "[1357/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32057, val loss: 0.37109, in 3.728s\n",
      "[1358/5000] 1 tree, 31 leaves, max depth = 20, train loss: 0.32054, val loss: 0.37109, in 2.402s\n",
      "[1359/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32052, val loss: 0.37109, in 3.343s\n",
      "[1360/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32050, val loss: 0.37109, in 4.505s\n",
      "[1361/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32047, val loss: 0.37106, in 4.045s\n",
      "[1362/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32044, val loss: 0.37106, in 3.815s\n",
      "[1363/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32041, val loss: 0.37104, in 3.884s\n",
      "[1364/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32039, val loss: 0.37103, in 3.809s\n",
      "[1365/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32036, val loss: 0.37102, in 3.829s\n",
      "[1366/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32033, val loss: 0.37100, in 3.982s\n",
      "[1367/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32031, val loss: 0.37100, in 4.946s\n",
      "[1368/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32028, val loss: 0.37098, in 4.185s\n",
      "[1369/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.32026, val loss: 0.37097, in 3.746s\n",
      "[1370/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.32023, val loss: 0.37096, in 3.782s\n",
      "[1371/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32020, val loss: 0.37094, in 5.369s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1372/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.32017, val loss: 0.37096, in 4.134s\n",
      "[1373/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32014, val loss: 0.37093, in 3.982s\n",
      "[1374/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.32012, val loss: 0.37089, in 3.490s\n",
      "[1375/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.32009, val loss: 0.37087, in 4.026s\n",
      "[1376/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.32008, val loss: 0.37087, in 4.302s\n",
      "[1377/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.32005, val loss: 0.37086, in 3.819s\n",
      "[1378/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.32002, val loss: 0.37082, in 3.813s\n",
      "[1379/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31999, val loss: 0.37080, in 3.929s\n",
      "[1380/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31996, val loss: 0.37079, in 3.847s\n",
      "[1381/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31994, val loss: 0.37077, in 4.006s\n",
      "[1382/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31991, val loss: 0.37076, in 4.179s\n",
      "[1383/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31988, val loss: 0.37076, in 2.537s\n",
      "[1384/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31986, val loss: 0.37075, in 3.965s\n",
      "[1385/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31983, val loss: 0.37073, in 4.220s\n",
      "[1386/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31979, val loss: 0.37072, in 3.728s\n",
      "[1387/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31976, val loss: 0.37070, in 4.055s\n",
      "[1388/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31973, val loss: 0.37069, in 3.887s\n",
      "[1389/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31970, val loss: 0.37067, in 3.864s\n",
      "[1390/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31967, val loss: 0.37066, in 3.948s\n",
      "[1391/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31963, val loss: 0.37067, in 4.284s\n",
      "[1392/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31960, val loss: 0.37070, in 3.956s\n",
      "[1393/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31958, val loss: 0.37068, in 3.753s\n",
      "[1394/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31955, val loss: 0.37068, in 3.753s\n",
      "[1395/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31952, val loss: 0.37067, in 3.771s\n",
      "[1396/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31950, val loss: 0.37066, in 3.826s\n",
      "[1397/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31947, val loss: 0.37066, in 4.007s\n",
      "[1398/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31945, val loss: 0.37065, in 4.733s\n",
      "[1399/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31943, val loss: 0.37066, in 3.688s\n",
      "[1400/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31941, val loss: 0.37064, in 3.709s\n",
      "[1401/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31939, val loss: 0.37065, in 3.641s\n",
      "[1402/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31937, val loss: 0.37062, in 3.794s\n",
      "[1403/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31933, val loss: 0.37063, in 3.764s\n",
      "[1404/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31931, val loss: 0.37060, in 3.985s\n",
      "[1405/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31928, val loss: 0.37057, in 3.848s\n",
      "[1406/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31925, val loss: 0.37055, in 3.956s\n",
      "[1407/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31922, val loss: 0.37055, in 3.868s\n",
      "[1408/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31920, val loss: 0.37056, in 2.255s\n",
      "[1409/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31918, val loss: 0.37056, in 2.106s\n",
      "[1410/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31916, val loss: 0.37055, in 2.693s\n",
      "[1411/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31914, val loss: 0.37054, in 3.519s\n",
      "[1412/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31912, val loss: 0.37055, in 3.943s\n",
      "[1413/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31910, val loss: 0.37054, in 3.858s\n",
      "[1414/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31909, val loss: 0.37053, in 4.375s\n",
      "[1415/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31907, val loss: 0.37053, in 4.153s\n",
      "[1416/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31904, val loss: 0.37052, in 3.877s\n",
      "[1417/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31901, val loss: 0.37048, in 3.878s\n",
      "[1418/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31899, val loss: 0.37046, in 4.018s\n",
      "[1419/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31897, val loss: 0.37044, in 3.929s\n",
      "[1420/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31895, val loss: 0.37044, in 4.236s\n",
      "[1421/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31892, val loss: 0.37043, in 3.888s\n",
      "[1422/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31890, val loss: 0.37042, in 3.975s\n",
      "[1423/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31887, val loss: 0.37040, in 4.281s\n",
      "[1424/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31885, val loss: 0.37043, in 3.906s\n",
      "[1425/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31883, val loss: 0.37042, in 4.953s\n",
      "[1426/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31881, val loss: 0.37041, in 3.716s\n",
      "[1427/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31879, val loss: 0.37039, in 3.748s\n",
      "[1428/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31876, val loss: 0.37039, in 3.821s\n",
      "[1429/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31873, val loss: 0.37038, in 4.638s\n",
      "[1430/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31871, val loss: 0.37037, in 4.210s\n",
      "[1431/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31869, val loss: 0.37037, in 2.238s\n",
      "[1432/5000] 1 tree, 31 leaves, max depth = 7, train loss: 0.31866, val loss: 0.37035, in 3.306s\n",
      "[1433/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31865, val loss: 0.37034, in 3.750s\n",
      "[1434/5000] 1 tree, 31 leaves, max depth = 20, train loss: 0.31863, val loss: 0.37032, in 3.754s\n",
      "[1435/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31861, val loss: 0.37032, in 3.756s\n",
      "[1436/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31858, val loss: 0.37032, in 3.763s\n",
      "[1437/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31855, val loss: 0.37032, in 3.825s\n",
      "[1438/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31853, val loss: 0.37031, in 3.948s\n",
      "[1439/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31849, val loss: 0.37029, in 3.933s\n",
      "[1440/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31847, val loss: 0.37025, in 3.260s\n",
      "[1441/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31845, val loss: 0.37024, in 3.478s\n",
      "[1442/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31844, val loss: 0.37024, in 3.800s\n",
      "[1443/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31842, val loss: 0.37023, in 3.755s\n",
      "[1444/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31839, val loss: 0.37020, in 3.773s\n",
      "[1445/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31836, val loss: 0.37018, in 4.063s\n",
      "[1446/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31833, val loss: 0.37016, in 4.242s\n",
      "[1447/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31830, val loss: 0.37016, in 3.749s\n",
      "[1448/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31829, val loss: 0.37015, in 3.783s\n",
      "[1449/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31826, val loss: 0.37016, in 3.726s\n",
      "[1450/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31823, val loss: 0.37017, in 3.754s\n",
      "[1451/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31820, val loss: 0.37018, in 4.270s\n",
      "[1452/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31818, val loss: 0.37017, in 4.245s\n",
      "[1453/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31816, val loss: 0.37015, in 3.644s\n",
      "[1454/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31813, val loss: 0.37015, in 4.505s\n",
      "[1455/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31812, val loss: 0.37015, in 2.748s\n",
      "[1456/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31809, val loss: 0.37013, in 2.616s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1457/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31806, val loss: 0.37012, in 3.913s\n",
      "[1458/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31803, val loss: 0.37011, in 3.762s\n",
      "[1459/5000] 1 tree, 31 leaves, max depth = 20, train loss: 0.31800, val loss: 0.37009, in 3.812s\n",
      "[1460/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31798, val loss: 0.37008, in 3.900s\n",
      "[1461/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31795, val loss: 0.37006, in 4.427s\n",
      "[1462/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31793, val loss: 0.37004, in 4.316s\n",
      "[1463/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31792, val loss: 0.37004, in 3.763s\n",
      "[1464/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31790, val loss: 0.37005, in 4.156s\n",
      "[1465/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31787, val loss: 0.37004, in 3.753s\n",
      "[1466/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31786, val loss: 0.37004, in 3.619s\n",
      "[1467/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31784, val loss: 0.37003, in 3.813s\n",
      "[1468/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31781, val loss: 0.37004, in 3.827s\n",
      "[1469/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31779, val loss: 0.37002, in 3.807s\n",
      "[1470/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31777, val loss: 0.37003, in 4.329s\n",
      "[1471/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31774, val loss: 0.37004, in 3.752s\n",
      "[1472/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31773, val loss: 0.37004, in 5.008s\n",
      "[1473/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31770, val loss: 0.37002, in 3.753s\n",
      "[1474/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31768, val loss: 0.37002, in 3.699s\n",
      "[1475/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31765, val loss: 0.36999, in 3.712s\n",
      "[1476/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31762, val loss: 0.36997, in 4.472s\n",
      "[1477/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31761, val loss: 0.36997, in 4.019s\n",
      "[1478/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31758, val loss: 0.36996, in 3.781s\n",
      "[1479/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31757, val loss: 0.36996, in 2.879s\n",
      "[1480/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31754, val loss: 0.36995, in 2.300s\n",
      "[1481/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31751, val loss: 0.36995, in 2.133s\n",
      "[1482/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31748, val loss: 0.36994, in 3.797s\n",
      "[1483/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31746, val loss: 0.36994, in 3.870s\n",
      "[1484/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31743, val loss: 0.36994, in 3.845s\n",
      "[1485/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31740, val loss: 0.36992, in 3.689s\n",
      "[1486/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31739, val loss: 0.36992, in 4.106s\n",
      "[1487/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31736, val loss: 0.36992, in 3.872s\n",
      "[1488/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31733, val loss: 0.36993, in 3.729s\n",
      "[1489/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31731, val loss: 0.36992, in 3.798s\n",
      "[1490/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31729, val loss: 0.36988, in 3.669s\n",
      "[1491/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31726, val loss: 0.36984, in 3.833s\n",
      "[1492/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31725, val loss: 0.36983, in 4.170s\n",
      "[1493/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31723, val loss: 0.36982, in 4.225s\n",
      "[1494/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31721, val loss: 0.36981, in 3.138s\n",
      "[1495/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31719, val loss: 0.36982, in 3.630s\n",
      "[1496/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31716, val loss: 0.36982, in 3.881s\n",
      "[1497/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31714, val loss: 0.36981, in 4.053s\n",
      "[1498/5000] 1 tree, 31 leaves, max depth = 20, train loss: 0.31712, val loss: 0.36980, in 4.039s\n",
      "[1499/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31711, val loss: 0.36981, in 4.304s\n",
      "[1500/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31709, val loss: 0.36981, in 4.127s\n",
      "[1501/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31708, val loss: 0.36981, in 3.894s\n",
      "[1502/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31705, val loss: 0.36982, in 4.235s\n",
      "[1503/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31703, val loss: 0.36982, in 3.732s\n",
      "[1504/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31701, val loss: 0.36980, in 3.729s\n",
      "[1505/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31698, val loss: 0.36979, in 3.280s\n",
      "[1506/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31696, val loss: 0.36977, in 2.570s\n",
      "[1507/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31695, val loss: 0.36977, in 2.288s\n",
      "[1508/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31693, val loss: 0.36977, in 3.041s\n",
      "[1509/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31691, val loss: 0.36975, in 4.149s\n",
      "[1510/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31690, val loss: 0.36974, in 3.258s\n",
      "[1511/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31686, val loss: 0.36971, in 3.424s\n",
      "[1512/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31684, val loss: 0.36970, in 3.431s\n",
      "[1513/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31681, val loss: 0.36967, in 3.684s\n",
      "[1514/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31678, val loss: 0.36965, in 3.654s\n",
      "[1515/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31675, val loss: 0.36963, in 4.380s\n",
      "[1516/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31673, val loss: 0.36961, in 3.620s\n",
      "[1517/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31670, val loss: 0.36961, in 2.871s\n",
      "[1518/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31668, val loss: 0.36962, in 3.075s\n",
      "[1519/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31666, val loss: 0.36960, in 3.914s\n",
      "[1520/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31664, val loss: 0.36961, in 3.548s\n",
      "[1521/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31662, val loss: 0.36959, in 3.686s\n",
      "[1522/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31659, val loss: 0.36958, in 3.800s\n",
      "[1523/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31657, val loss: 0.36957, in 3.349s\n",
      "[1524/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31655, val loss: 0.36957, in 2.977s\n",
      "[1525/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31653, val loss: 0.36955, in 3.659s\n",
      "[1526/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31651, val loss: 0.36955, in 4.176s\n",
      "[1527/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31649, val loss: 0.36952, in 3.766s\n",
      "[1528/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31646, val loss: 0.36953, in 3.642s\n",
      "[1529/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31644, val loss: 0.36952, in 3.557s\n",
      "[1530/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31642, val loss: 0.36952, in 3.618s\n",
      "[1531/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31639, val loss: 0.36950, in 3.587s\n",
      "[1532/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31636, val loss: 0.36948, in 3.761s\n",
      "[1533/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31634, val loss: 0.36950, in 3.281s\n",
      "[1534/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31631, val loss: 0.36948, in 2.321s\n",
      "[1535/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31629, val loss: 0.36946, in 2.246s\n",
      "[1536/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31626, val loss: 0.36946, in 2.006s\n",
      "[1537/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31623, val loss: 0.36946, in 3.772s\n",
      "[1538/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31620, val loss: 0.36945, in 3.027s\n",
      "[1539/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31617, val loss: 0.36942, in 3.421s\n",
      "[1540/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31615, val loss: 0.36943, in 3.191s\n",
      "[1541/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31613, val loss: 0.36942, in 3.623s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1542/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31609, val loss: 0.36940, in 3.423s\n",
      "[1543/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31607, val loss: 0.36939, in 3.352s\n",
      "[1544/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31605, val loss: 0.36938, in 4.873s\n",
      "[1545/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31603, val loss: 0.36937, in 3.643s\n",
      "[1546/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31601, val loss: 0.36936, in 3.684s\n",
      "[1547/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31599, val loss: 0.36936, in 3.597s\n",
      "[1548/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31597, val loss: 0.36933, in 3.657s\n",
      "[1549/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31595, val loss: 0.36932, in 3.675s\n",
      "[1550/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31593, val loss: 0.36933, in 3.773s\n",
      "[1551/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31592, val loss: 0.36932, in 3.929s\n",
      "[1552/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31590, val loss: 0.36930, in 3.703s\n",
      "[1553/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31589, val loss: 0.36929, in 3.946s\n",
      "[1554/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31587, val loss: 0.36929, in 3.392s\n",
      "[1555/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31585, val loss: 0.36929, in 3.656s\n",
      "[1556/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31582, val loss: 0.36929, in 5.177s\n",
      "[1557/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31579, val loss: 0.36927, in 3.452s\n",
      "[1558/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31577, val loss: 0.36927, in 3.526s\n",
      "[1559/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31574, val loss: 0.36927, in 3.769s\n",
      "[1560/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31572, val loss: 0.36926, in 4.230s\n",
      "[1561/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31570, val loss: 0.36926, in 3.852s\n",
      "[1562/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31568, val loss: 0.36923, in 3.735s\n",
      "[1563/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31565, val loss: 0.36921, in 2.075s\n",
      "[1564/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31562, val loss: 0.36921, in 2.575s\n",
      "[1565/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31560, val loss: 0.36920, in 3.885s\n",
      "[1566/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31558, val loss: 0.36920, in 2.936s\n",
      "[1567/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31556, val loss: 0.36921, in 3.301s\n",
      "[1568/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31552, val loss: 0.36919, in 3.853s\n",
      "[1569/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31550, val loss: 0.36919, in 3.782s\n",
      "[1570/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31547, val loss: 0.36917, in 3.934s\n",
      "[1571/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31545, val loss: 0.36916, in 3.423s\n",
      "[1572/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31542, val loss: 0.36913, in 3.576s\n",
      "[1573/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31540, val loss: 0.36910, in 3.532s\n",
      "[1574/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31538, val loss: 0.36911, in 3.600s\n",
      "[1575/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31535, val loss: 0.36912, in 3.635s\n",
      "[1576/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31534, val loss: 0.36911, in 3.952s\n",
      "[1577/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31531, val loss: 0.36911, in 4.807s\n",
      "[1578/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31530, val loss: 0.36911, in 3.805s\n",
      "[1579/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31527, val loss: 0.36907, in 3.364s\n",
      "[1580/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31524, val loss: 0.36906, in 3.146s\n",
      "[1581/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31521, val loss: 0.36907, in 3.476s\n",
      "[1582/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31519, val loss: 0.36905, in 3.380s\n",
      "[1583/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31516, val loss: 0.36904, in 3.823s\n",
      "[1584/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31514, val loss: 0.36903, in 3.755s\n",
      "[1585/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31512, val loss: 0.36904, in 3.541s\n",
      "[1586/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31510, val loss: 0.36902, in 3.444s\n",
      "[1587/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31508, val loss: 0.36903, in 2.966s\n",
      "[1588/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31505, val loss: 0.36901, in 2.068s\n",
      "[1589/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31503, val loss: 0.36900, in 2.505s\n",
      "[1590/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31501, val loss: 0.36899, in 3.607s\n",
      "[1591/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31497, val loss: 0.36896, in 3.713s\n",
      "[1592/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31495, val loss: 0.36895, in 3.752s\n",
      "[1593/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31493, val loss: 0.36895, in 3.850s\n",
      "[1594/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31491, val loss: 0.36895, in 4.370s\n",
      "[1595/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31488, val loss: 0.36895, in 3.314s\n",
      "[1596/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31487, val loss: 0.36894, in 3.431s\n",
      "[1597/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31484, val loss: 0.36893, in 3.550s\n",
      "[1598/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31482, val loss: 0.36893, in 3.820s\n",
      "[1599/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31479, val loss: 0.36890, in 3.457s\n",
      "[1600/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31477, val loss: 0.36888, in 4.754s\n",
      "[1601/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31476, val loss: 0.36888, in 3.808s\n",
      "[1602/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31474, val loss: 0.36886, in 3.731s\n",
      "[1603/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31472, val loss: 0.36886, in 3.848s\n",
      "[1604/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31470, val loss: 0.36886, in 3.861s\n",
      "[1605/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31468, val loss: 0.36885, in 3.601s\n",
      "[1606/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31466, val loss: 0.36883, in 3.822s\n",
      "[1607/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31463, val loss: 0.36882, in 3.759s\n",
      "[1608/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31461, val loss: 0.36882, in 3.239s\n",
      "[1609/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31459, val loss: 0.36883, in 2.836s\n",
      "[1610/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31456, val loss: 0.36883, in 4.429s\n",
      "[1611/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31455, val loss: 0.36882, in 3.969s\n",
      "[1612/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31452, val loss: 0.36880, in 3.590s\n",
      "[1613/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31449, val loss: 0.36878, in 2.241s\n",
      "[1614/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31447, val loss: 0.36878, in 2.706s\n",
      "[1615/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31445, val loss: 0.36876, in 3.261s\n",
      "[1616/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31443, val loss: 0.36873, in 3.779s\n",
      "[1617/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.31440, val loss: 0.36873, in 3.620s\n",
      "[1618/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31437, val loss: 0.36871, in 3.466s\n",
      "[1619/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31435, val loss: 0.36869, in 3.696s\n",
      "[1620/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31432, val loss: 0.36868, in 4.095s\n",
      "[1621/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31430, val loss: 0.36866, in 3.739s\n",
      "[1622/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31427, val loss: 0.36866, in 3.628s\n",
      "[1623/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31425, val loss: 0.36866, in 3.478s\n",
      "[1624/5000] 1 tree, 31 leaves, max depth = 22, train loss: 0.31423, val loss: 0.36866, in 3.680s\n",
      "[1625/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31422, val loss: 0.36865, in 3.498s\n",
      "[1626/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31420, val loss: 0.36864, in 3.697s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1627/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31417, val loss: 0.36863, in 4.414s\n",
      "[1628/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31416, val loss: 0.36864, in 3.755s\n",
      "[1629/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31413, val loss: 0.36862, in 3.697s\n",
      "[1630/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31410, val loss: 0.36861, in 3.614s\n",
      "[1631/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31408, val loss: 0.36859, in 3.523s\n",
      "[1632/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31405, val loss: 0.36858, in 3.503s\n",
      "[1633/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31404, val loss: 0.36857, in 3.905s\n",
      "[1634/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31402, val loss: 0.36857, in 3.709s\n",
      "[1635/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31401, val loss: 0.36856, in 4.338s\n",
      "[1636/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31398, val loss: 0.36856, in 3.680s\n",
      "[1637/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31396, val loss: 0.36856, in 3.801s\n",
      "[1638/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31394, val loss: 0.36857, in 3.684s\n",
      "[1639/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31392, val loss: 0.36856, in 3.112s\n",
      "[1640/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31391, val loss: 0.36854, in 2.059s\n",
      "[1641/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31388, val loss: 0.36853, in 3.796s\n",
      "[1642/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31386, val loss: 0.36853, in 3.729s\n",
      "[1643/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31384, val loss: 0.36852, in 4.183s\n",
      "[1644/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31381, val loss: 0.36850, in 4.236s\n",
      "[1645/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31379, val loss: 0.36848, in 3.709s\n",
      "[1646/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31377, val loss: 0.36847, in 3.487s\n",
      "[1647/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31375, val loss: 0.36847, in 3.489s\n",
      "[1648/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31373, val loss: 0.36847, in 3.617s\n",
      "[1649/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31371, val loss: 0.36846, in 2.704s\n",
      "[1650/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31369, val loss: 0.36844, in 3.026s\n",
      "[1651/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31366, val loss: 0.36844, in 3.477s\n",
      "[1652/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31364, val loss: 0.36843, in 3.715s\n",
      "[1653/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31362, val loss: 0.36842, in 3.605s\n",
      "[1654/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31360, val loss: 0.36840, in 3.524s\n",
      "[1655/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31358, val loss: 0.36839, in 3.678s\n",
      "[1656/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31356, val loss: 0.36839, in 3.468s\n",
      "[1657/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31354, val loss: 0.36837, in 3.561s\n",
      "[1658/5000] 1 tree, 31 leaves, max depth = 21, train loss: 0.31352, val loss: 0.36836, in 3.608s\n",
      "[1659/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31350, val loss: 0.36834, in 3.911s\n",
      "[1660/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31348, val loss: 0.36832, in 4.480s\n",
      "[1661/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31345, val loss: 0.36832, in 3.765s\n",
      "[1662/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31343, val loss: 0.36830, in 3.782s\n",
      "[1663/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31341, val loss: 0.36829, in 3.373s\n",
      "[1664/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31339, val loss: 0.36828, in 2.930s\n",
      "[1665/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31336, val loss: 0.36828, in 3.633s\n",
      "[1666/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31334, val loss: 0.36828, in 3.092s\n",
      "[1667/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31331, val loss: 0.36827, in 2.480s\n",
      "[1668/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31329, val loss: 0.36827, in 2.080s\n",
      "[1669/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31327, val loss: 0.36825, in 3.797s\n",
      "[1670/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31324, val loss: 0.36824, in 3.865s\n",
      "[1671/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31322, val loss: 0.36823, in 3.752s\n",
      "[1672/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31320, val loss: 0.36822, in 3.586s\n",
      "[1673/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31318, val loss: 0.36822, in 3.616s\n",
      "[1674/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31316, val loss: 0.36821, in 3.662s\n",
      "[1675/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31314, val loss: 0.36818, in 3.441s\n",
      "[1676/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31312, val loss: 0.36818, in 3.633s\n",
      "[1677/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31309, val loss: 0.36818, in 3.619s\n",
      "[1678/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31307, val loss: 0.36817, in 3.923s\n",
      "[1679/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31306, val loss: 0.36817, in 3.329s\n",
      "[1680/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31303, val loss: 0.36817, in 3.662s\n",
      "[1681/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31301, val loss: 0.36818, in 3.643s\n",
      "[1682/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31298, val loss: 0.36815, in 3.372s\n",
      "[1683/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31296, val loss: 0.36815, in 3.661s\n",
      "[1684/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31294, val loss: 0.36814, in 3.528s\n",
      "[1685/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31292, val loss: 0.36814, in 3.707s\n",
      "[1686/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31290, val loss: 0.36813, in 3.677s\n",
      "[1687/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31287, val loss: 0.36812, in 3.726s\n",
      "[1688/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31284, val loss: 0.36812, in 3.838s\n",
      "[1689/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31283, val loss: 0.36811, in 3.478s\n",
      "[1690/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31280, val loss: 0.36810, in 3.632s\n",
      "[1691/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31279, val loss: 0.36810, in 3.804s\n",
      "[1692/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31277, val loss: 0.36809, in 3.047s\n",
      "[1693/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31275, val loss: 0.36809, in 4.587s\n",
      "[1694/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31273, val loss: 0.36806, in 3.785s\n",
      "[1695/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31271, val loss: 0.36804, in 2.429s\n",
      "[1696/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31269, val loss: 0.36803, in 3.204s\n",
      "[1697/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31267, val loss: 0.36802, in 3.658s\n",
      "[1698/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31265, val loss: 0.36801, in 3.546s\n",
      "[1699/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31262, val loss: 0.36800, in 3.717s\n",
      "[1700/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31259, val loss: 0.36799, in 3.609s\n",
      "[1701/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31257, val loss: 0.36800, in 3.757s\n",
      "[1702/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31255, val loss: 0.36800, in 3.637s\n",
      "[1703/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31252, val loss: 0.36799, in 3.690s\n",
      "[1704/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31250, val loss: 0.36799, in 4.005s\n",
      "[1705/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31249, val loss: 0.36797, in 3.772s\n",
      "[1706/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31247, val loss: 0.36797, in 3.638s\n",
      "[1707/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31245, val loss: 0.36795, in 2.747s\n",
      "[1708/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31244, val loss: 0.36793, in 3.005s\n",
      "[1709/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.31243, val loss: 0.36792, in 3.734s\n",
      "[1710/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31242, val loss: 0.36792, in 3.647s\n",
      "[1711/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31240, val loss: 0.36792, in 3.978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1712/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31239, val loss: 0.36791, in 4.002s\n",
      "[1713/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31238, val loss: 0.36791, in 3.650s\n",
      "[1714/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31236, val loss: 0.36789, in 3.694s\n",
      "[1715/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31234, val loss: 0.36791, in 3.690s\n",
      "[1716/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31232, val loss: 0.36788, in 3.586s\n",
      "[1717/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31230, val loss: 0.36787, in 3.709s\n",
      "[1718/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31228, val loss: 0.36789, in 3.681s\n",
      "[1719/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31226, val loss: 0.36787, in 3.854s\n",
      "[1720/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31224, val loss: 0.36786, in 3.315s\n",
      "[1721/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31222, val loss: 0.36786, in 3.578s\n",
      "[1722/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31221, val loss: 0.36786, in 2.074s\n",
      "[1723/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31218, val loss: 0.36787, in 2.099s\n",
      "[1724/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31216, val loss: 0.36786, in 2.432s\n",
      "[1725/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31214, val loss: 0.36783, in 3.501s\n",
      "[1726/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31212, val loss: 0.36782, in 3.692s\n",
      "[1727/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31210, val loss: 0.36781, in 3.653s\n",
      "[1728/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31208, val loss: 0.36781, in 4.330s\n",
      "[1729/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31205, val loss: 0.36778, in 4.291s\n",
      "[1730/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31203, val loss: 0.36777, in 3.581s\n",
      "[1731/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31201, val loss: 0.36777, in 3.734s\n",
      "[1732/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31199, val loss: 0.36776, in 4.189s\n",
      "[1733/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31196, val loss: 0.36774, in 3.682s\n",
      "[1734/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31195, val loss: 0.36775, in 3.704s\n",
      "[1735/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31193, val loss: 0.36776, in 3.988s\n",
      "[1736/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31190, val loss: 0.36778, in 3.510s\n",
      "[1737/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31188, val loss: 0.36777, in 3.264s\n",
      "[1738/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31186, val loss: 0.36778, in 3.968s\n",
      "[1739/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31184, val loss: 0.36776, in 3.633s\n",
      "[1740/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31181, val loss: 0.36776, in 3.706s\n",
      "[1741/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31179, val loss: 0.36776, in 4.352s\n",
      "[1742/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31177, val loss: 0.36774, in 3.685s\n",
      "[1743/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31175, val loss: 0.36773, in 3.663s\n",
      "[1744/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31173, val loss: 0.36772, in 4.162s\n",
      "[1745/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31171, val loss: 0.36772, in 4.145s\n",
      "[1746/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31169, val loss: 0.36773, in 2.688s\n",
      "[1747/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31167, val loss: 0.36771, in 2.101s\n",
      "[1748/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31164, val loss: 0.36772, in 3.860s\n",
      "[1749/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31162, val loss: 0.36770, in 3.843s\n",
      "[1750/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31160, val loss: 0.36770, in 3.130s\n",
      "[1751/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31158, val loss: 0.36769, in 3.384s\n",
      "[1752/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31156, val loss: 0.36767, in 3.749s\n",
      "[1753/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31155, val loss: 0.36768, in 3.707s\n",
      "[1754/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31153, val loss: 0.36767, in 4.125s\n",
      "[1755/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31152, val loss: 0.36766, in 3.724s\n",
      "[1756/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31149, val loss: 0.36766, in 3.789s\n",
      "[1757/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31147, val loss: 0.36766, in 3.601s\n",
      "[1758/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31146, val loss: 0.36764, in 3.612s\n",
      "[1759/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31144, val loss: 0.36764, in 3.749s\n",
      "[1760/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31141, val loss: 0.36765, in 3.731s\n",
      "[1761/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.31139, val loss: 0.36764, in 4.883s\n",
      "[1762/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31137, val loss: 0.36763, in 3.849s\n",
      "[1763/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31134, val loss: 0.36763, in 3.308s\n",
      "[1764/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31133, val loss: 0.36763, in 3.399s\n",
      "[1765/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31131, val loss: 0.36761, in 3.704s\n",
      "[1766/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31129, val loss: 0.36761, in 3.708s\n",
      "[1767/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31126, val loss: 0.36761, in 3.738s\n",
      "[1768/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31125, val loss: 0.36761, in 3.745s\n",
      "[1769/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31123, val loss: 0.36761, in 3.783s\n",
      "[1770/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31121, val loss: 0.36762, in 3.448s\n",
      "[1771/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31119, val loss: 0.36762, in 2.162s\n",
      "[1772/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31117, val loss: 0.36761, in 3.698s\n",
      "[1773/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31115, val loss: 0.36760, in 3.416s\n",
      "[1774/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31113, val loss: 0.36761, in 3.614s\n",
      "[1775/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31112, val loss: 0.36761, in 3.729s\n",
      "[1776/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31110, val loss: 0.36758, in 3.829s\n",
      "[1777/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31108, val loss: 0.36759, in 3.661s\n",
      "[1778/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.31107, val loss: 0.36760, in 3.941s\n",
      "[1779/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31105, val loss: 0.36760, in 2.748s\n",
      "[1780/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31104, val loss: 0.36760, in 2.941s\n",
      "[1781/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.31103, val loss: 0.36759, in 3.485s\n",
      "[1782/5000] 1 tree, 31 leaves, max depth = 20, train loss: 0.31102, val loss: 0.36757, in 3.955s\n",
      "[1783/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31101, val loss: 0.36758, in 3.676s\n",
      "[1784/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31100, val loss: 0.36757, in 3.919s\n",
      "[1785/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31098, val loss: 0.36755, in 3.779s\n",
      "[1786/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31096, val loss: 0.36754, in 3.806s\n",
      "[1787/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31094, val loss: 0.36756, in 4.011s\n",
      "[1788/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31092, val loss: 0.36756, in 3.788s\n",
      "[1789/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31090, val loss: 0.36753, in 3.521s\n",
      "[1790/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31087, val loss: 0.36751, in 3.451s\n",
      "[1791/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31085, val loss: 0.36750, in 3.922s\n",
      "[1792/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31083, val loss: 0.36749, in 3.427s\n",
      "[1793/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31080, val loss: 0.36750, in 3.368s\n",
      "[1794/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31078, val loss: 0.36750, in 4.722s\n",
      "[1795/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31077, val loss: 0.36749, in 3.711s\n",
      "[1796/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31075, val loss: 0.36748, in 2.416s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1797/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31073, val loss: 0.36747, in 2.082s\n",
      "[1798/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31070, val loss: 0.36747, in 2.158s\n",
      "[1799/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31068, val loss: 0.36747, in 3.770s\n",
      "[1800/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31067, val loss: 0.36746, in 3.631s\n",
      "[1801/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31064, val loss: 0.36745, in 3.879s\n",
      "[1802/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31063, val loss: 0.36746, in 3.795s\n",
      "[1803/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31062, val loss: 0.36744, in 3.748s\n",
      "[1804/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.31058, val loss: 0.36743, in 4.009s\n",
      "[1805/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.31057, val loss: 0.36742, in 3.670s\n",
      "[1806/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.31055, val loss: 0.36742, in 3.431s\n",
      "[1807/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31052, val loss: 0.36740, in 3.521s\n",
      "[1808/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31050, val loss: 0.36740, in 3.599s\n",
      "[1809/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31049, val loss: 0.36740, in 3.700s\n",
      "[1810/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31046, val loss: 0.36739, in 4.271s\n",
      "[1811/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31045, val loss: 0.36738, in 4.909s\n",
      "[1812/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.31042, val loss: 0.36737, in 3.775s\n",
      "[1813/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31040, val loss: 0.36735, in 3.561s\n",
      "[1814/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31038, val loss: 0.36735, in 3.645s\n",
      "[1815/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31037, val loss: 0.36736, in 3.739s\n",
      "[1816/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31035, val loss: 0.36735, in 3.921s\n",
      "[1817/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31032, val loss: 0.36735, in 3.930s\n",
      "[1818/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31031, val loss: 0.36735, in 3.546s\n",
      "[1819/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31028, val loss: 0.36736, in 3.678s\n",
      "[1820/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.31026, val loss: 0.36735, in 4.020s\n",
      "[1821/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31024, val loss: 0.36731, in 3.497s\n",
      "[1822/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31023, val loss: 0.36731, in 3.101s\n",
      "[1823/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31021, val loss: 0.36730, in 2.183s\n",
      "[1824/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31019, val loss: 0.36730, in 2.890s\n",
      "[1825/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.31016, val loss: 0.36727, in 3.766s\n",
      "[1826/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.31014, val loss: 0.36726, in 3.722s\n",
      "[1827/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31011, val loss: 0.36723, in 3.707s\n",
      "[1828/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31009, val loss: 0.36722, in 3.933s\n",
      "[1829/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.31007, val loss: 0.36722, in 3.722s\n",
      "[1830/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.31005, val loss: 0.36721, in 3.659s\n",
      "[1831/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.31003, val loss: 0.36721, in 3.601s\n",
      "[1832/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.31001, val loss: 0.36722, in 3.671s\n",
      "[1833/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.30999, val loss: 0.36722, in 3.764s\n",
      "[1834/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.30997, val loss: 0.36721, in 3.890s\n",
      "[1835/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.30994, val loss: 0.36721, in 3.310s\n",
      "[1836/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.30991, val loss: 0.36721, in 3.563s\n",
      "[1837/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.30989, val loss: 0.36720, in 4.389s\n",
      "[1838/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.30987, val loss: 0.36719, in 3.728s\n",
      "[1839/5000] 1 tree, 31 leaves, max depth = 8, train loss: 0.30985, val loss: 0.36717, in 3.782s\n",
      "[1840/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.30983, val loss: 0.36716, in 3.728s\n",
      "[1841/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.30981, val loss: 0.36714, in 3.658s\n",
      "[1842/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.30979, val loss: 0.36713, in 3.832s\n",
      "[1843/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.30977, val loss: 0.36713, in 4.734s\n",
      "[1844/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.30975, val loss: 0.36712, in 4.238s\n",
      "[1845/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.30973, val loss: 0.36712, in 3.779s\n",
      "[1846/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.30971, val loss: 0.36713, in 3.969s\n",
      "[1847/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.30969, val loss: 0.36713, in 3.701s\n",
      "[1848/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.30968, val loss: 0.36712, in 2.851s\n",
      "[1849/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.30966, val loss: 0.36712, in 2.144s\n",
      "[1850/5000] 1 tree, 31 leaves, max depth = 19, train loss: 0.30964, val loss: 0.36711, in 3.647s\n",
      "[1851/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.30963, val loss: 0.36711, in 3.835s\n",
      "[1852/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.30961, val loss: 0.36711, in 3.774s\n",
      "[1853/5000] 1 tree, 31 leaves, max depth = 18, train loss: 0.30959, val loss: 0.36709, in 3.888s\n",
      "[1854/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.30957, val loss: 0.36710, in 3.614s\n",
      "[1855/5000] 1 tree, 31 leaves, max depth = 10, train loss: 0.30954, val loss: 0.36708, in 3.507s\n",
      "[1856/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.30952, val loss: 0.36707, in 3.465s\n",
      "[1857/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.30950, val loss: 0.36707, in 3.680s\n",
      "[1858/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.30949, val loss: 0.36706, in 3.412s\n",
      "[1859/5000] 1 tree, 31 leaves, max depth = 11, train loss: 0.30947, val loss: 0.36707, in 3.450s\n",
      "[1860/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.30944, val loss: 0.36707, in 5.272s\n",
      "[1861/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.30943, val loss: 0.36706, in 3.525s\n",
      "[1862/5000] 1 tree, 31 leaves, max depth = 13, train loss: 0.30941, val loss: 0.36707, in 3.674s\n",
      "[1863/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.30940, val loss: 0.36708, in 3.112s\n",
      "[1864/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.30937, val loss: 0.36709, in 3.644s\n",
      "[1865/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.30936, val loss: 0.36708, in 3.903s\n",
      "[1866/5000] 1 tree, 31 leaves, max depth = 16, train loss: 0.30933, val loss: 0.36708, in 3.754s\n",
      "[1867/5000] 1 tree, 31 leaves, max depth = 17, train loss: 0.30931, val loss: 0.36706, in 3.757s\n",
      "[1868/5000] 1 tree, 31 leaves, max depth = 12, train loss: 0.30929, val loss: 0.36707, in 3.785s\n",
      "[1869/5000] 1 tree, 31 leaves, max depth = 9, train loss: 0.30926, val loss: 0.36710, in 3.830s\n",
      "[1870/5000] 1 tree, 31 leaves, max depth = 14, train loss: 0.30925, val loss: 0.36710, in 3.999s\n",
      "[1871/5000] 1 tree, 31 leaves, max depth = 15, train loss: 0.30922, val loss: 0.36710, in 3.649s\n",
      "Fit 1871 trees in 7256.789 s, (58001 total leaves)\n",
      "Time spent computing histograms: 2867.444s\n",
      "Time spent finding best splits:  1874.563s\n",
      "Time spent applying splits:      1959.194s\n",
      "Time spent predicting:           31.314s\n",
      "Finished in 2:00:56.968261\n"
     ]
    }
   ],
   "source": [
    "# instantiate bdt\n",
    "muBDT = HistGradientBoostingClassifier(max_iter=5000, tol=5e-8, verbose=1)\n",
    "\n",
    "# training\n",
    "start_time = time.time()\n",
    "muBDT.fit(X_train, y_train, train_weights)\n",
    "end_time = time.time()\n",
    "duration = timedelta(seconds=end_time-start_time)\n",
    "print('Finished in {0}'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to separate signal and background events\n",
    "def sig_bkg_split(X, y, weights):\n",
    "    '''\n",
    "    Splits X and y into signal and background sets with weights\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - X (DataFrame): features\n",
    "    - y (DataFrame): signal indicator (1 if signal, 0 if background)\n",
    "    - weights (DataFrame): weights of events\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    - X_sig, X_bkg, w_sig, w_bkg (dataFrame tuple): data organized according to signal/background status \n",
    "    '''\n",
    "    # get signal and background mask\n",
    "    sig_mask = y.loc[y.values==1].index\n",
    "    bkg_mask = y.loc[y.values==0].index\n",
    "\n",
    "    return X.loc[sig_mask], X.loc[bkg_mask], weights.loc[sig_mask], weights.loc[bkg_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and testing background/signal sets\n",
    "train_sig, train_bkg, train_sig_weights, train_bkg_weights = sig_bkg_split(X_train, y_train, train_weights)\n",
    "test_sig, test_bkg, test_sig_weights, test_bkg_weights = sig_bkg_split(X_test, y_test, test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted probabilities\n",
    "train_sig_probs = muBDT.predict_proba(train_sig)[:, 1]\n",
    "train_bkg_probs = muBDT.predict_proba(train_bkg)[:, 1]\n",
    "test_sig_probs = muBDT.predict_proba(test_sig)[:, 1]\n",
    "test_bkg_probs = muBDT.predict_proba(test_bkg)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting probability scores\n",
    "def gen_hist(axs, xlabel, scale, train_sig_probs, train_bkg_probs, test_sig_probs, test_bkg_probs,\n",
    "             train_sig_weights, train_bkg_weights, test_sig_weights, test_bkg_weights, decorate=True,\n",
    "             *args, **kwargs):\n",
    "    '''\n",
    "    Plots signal probability histograms weighted according to weights.\n",
    "    Parameters\n",
    "    ----------\n",
    "    - axs: list of matplotlib axes\n",
    "        axes on which to plot\n",
    "    - xlabel: str\n",
    "        label for x-axis\n",
    "    - scale: str 'lin' or 'log'\n",
    "        scale for y-axis\n",
    "    - train_sig_probs, ... test_bkg_probs: ndarrays\n",
    "        BDT's predicted signal probability for each of train/test sig/bkg sets\n",
    "    - train_sig_weights, ... test_bkg_weights: ndarrays\n",
    "        weights associated with each train/test sig/bkg sets\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    - axs (matplotlib.pyplot.axes): axes with histogram attached\n",
    "    '''\n",
    "\n",
    "    # plot histograms\n",
    "    axs[0].hist(train_sig_probs, weights=train_sig_weights, label='Muon samples', *args, **kwargs)\n",
    "    axs[0].hist(train_bkg_probs, weights=train_bkg_weights, label='Neutrino samples', *args, **kwargs)\n",
    "    if decorate:\n",
    "        axs[0].set_title('Training sets')\n",
    "        #axs[0].legend()\n",
    "    \n",
    "    axs[1].hist(test_sig_probs, weights=test_sig_weights, label='Muon samples', *args, **kwargs)\n",
    "    axs[1].hist(test_bkg_probs, weights=test_bkg_weights, label='Neutrino samples', *args, **kwargs)\n",
    "    if decorate:\n",
    "        axs[1].set_title('Test sets')\n",
    "        #axs[1].legend()\n",
    "    \n",
    "    # formatting\n",
    "    axs[1].set_xlabel(xlabel)\n",
    "    axs[0].set_yscale(scale)\n",
    "    axs[1].set_yscale(scale)\n",
    "    \n",
    "    return axs\n",
    "\n",
    "# plotting probability scores\n",
    "def gen_hist_sing(ax, xlabel, scale, train_sig_probs, train_bkg_probs, test_sig_probs, test_bkg_probs,\n",
    "             train_sig_weights, train_bkg_weights, test_sig_weights, test_bkg_weights, decorate=True,\n",
    "             *args, **kwargs):\n",
    "    '''\n",
    "    Plots signal probability histograms weighted according to weights.\n",
    "    Parameters\n",
    "    ----------\n",
    "    - ax: matplotlib axes\n",
    "        axes on which to plot\n",
    "    - xlabel: str\n",
    "        label for x-axis\n",
    "    - scale: str 'lin' or 'log'\n",
    "        scale for y-axis\n",
    "    - train_sig_probs, ... test_bkg_probs: ndarrays\n",
    "        BDT's predicted signal probability for each of train/test sig/bkg sets\n",
    "    - train_sig_weights, ... test_bkg_weights: ndarrays\n",
    "        weights associated with each train/test sig/bkg sets\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    - ax (matplotlib.pyplot.axes): axes with histogram attached\n",
    "    '''\n",
    "    \n",
    "    ax.hist(test_sig_probs, weights=test_sig_weights, label='Muon samples', *args, **kwargs)\n",
    "    ax.hist(test_bkg_probs, weights=test_bkg_weights, label='Neutrino samples', *args, **kwargs)\n",
    "    # formatting\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_yscale(scale)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn0AAAGHCAYAAADFkuQvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3X24XXV95/3PhyDCIB4qwY4mxIBBLRorekq1caZI1RuViLZUwTo+UTLMXarGh2vCrS0ZHYdUq1EGrEaJiFXAoVYTxeJdqEUzYBOEGpDSZhDhAMqDckAIz9/5Y69FVtZZa+21z35ae+/367rOlbPXXmvt3zlLko/f35MjQgAAABhvewy7AQAAAOg/Qh8AAMAEIPQBAABMAEIfAADABCD0AQAATABCHwAAwAQg9AFACdsLbP/K9pJengsAw0DoAzA2ktCVfj1me2fm9R91er+IeDQinhQRN/Xy3EGx/X3bbxt2OwA0w57DbgAA9EpEPCn93vaNkv44Iv6+7Hzbe0bEI4NoGwAMG5U+ABPD9n+3fYHt82zfK+nNtl9i+wrbd9u+zfYZtp+QnL+n7bC9NHn918n737Z9r+3LbR/c6bnJ+6+y/a+2Z23/T9tbyqpytl9s+4e277H9c9sfy7y3ItP+q23/x+T4X0h6iaTPJJXOT9reI2nT7cnn/sj2Yb3/TQNoIkIfgEnzeklfkTQl6QJJj0h6l6SFklZIOlrSf664/k2S/kzSUyTdJOnDnZ5r+6mSvirp/cnn/kTSERX3+Z+SPhYRT5a0TNKFyX0OkrRJ0mnJZ6yR9DXbB0TEf5V0uaSTk27nd0t6laQXSzpU0q9JOl7SLyo+F8AYIfQBmDTfj4jNEfFYROyMiK0R8YOIeCQibpC0QdLvVlx/YURsi4iHJX1Z0gvmce4xkq6OiG8k762XdGfFfR6WdGgS5u6NiB8kx98iaVNEXJz8PH8n6Z/VCq5l93mypOdIUkT8OCJ+VvG5AMYIoQ/ApLk5+8L2c2x/y/bPbN8j6UNqVd/KZEPS/ZKeVHZixblPz7YjIkLSTMV93i7pMEnX2/4n269Ojj9D0glJ1+7dtu9Wq5L39KKbRMR3JH1G0l9J+rntz9jer+JzAYwRQh+ASRO515+VdI2kZUn36Z9Lcp/bcJukxekL25a0qOzkiLg+Io6X9FRJH5f0N7b3Vis4fiEi9s987RsR6Zi//M+qiPhkRLxQ0vPUCpLv6dlPBaDRCH0AJt1+kmYl3Wf7N1Q9nq9XvinphbZX2t5TrTGFB5adbPs/2V4YEY8lbQ1Jj0n6kqTX235Fsk7g3rZfZjut9P1c0iGZ+xyRfO0p6T5JD0l6tC8/IYDGIfQBmHTvlfRWSfeqVfW7oN8fGBE/l/RGSZ+QdJekZ0q6StKDJZe8WtJ1yYzjv5T0xoh4KCJuVGtiyp9JukOtySLv1a6/2z+pXd2/n5C0v6SzJd0t6Ua1Ko7re/3zAWgmt4aSAACGxfYCSbdKOi4ivjfs9gAYT1T6AGAIbB9te8r2E9Wq1D0i6Z+G3CwAY4zQBwDD8VJJN6i1VMvRkl4XEWXduwDQNbp3AQAAJgCVPgAAgAlA6AMAAJgAew67AU1he6Wklfvtt99Jz3rWs4bdHAAAgLauvPLKOyOidJ3PLMb05UxPT8e2bduG3QwAAIC2bF8ZEdN1zqV7FwAAYAIQ+gAAACYAoS+R7IG5YXZ2dthNAQAA6DlCXyIiNkfEqqmpqWE3BQAAoOcIfcOyfnnrCwAAYABYsmVYZm8adgsAAMAEodIHAAAwAQh9CSZyAACAcUboSzCRAwAAjDNCHwAAwAQg9AEAAEwAQh8AAMAEIPQN09QSae0U6/UBAIC+G/t1+mwfIukDkqYi4rhht2c3q7e3/lzL5BEAANBfI1nps73R9u22r8kdP9r29bZ32F4jSRFxQ0ScOJyWAgAANMNIhj5J50g6OnvA9gJJZ0l6laTDJJ1g+7DBNw0AAKB5RjL0RcRlkn6RO3yEpB1JZe8hSedLOrbO/Wyvsr3N9rY77rijx62tgbF9AACgz0Yy9JVYJOnmzOsZSYtsH2D7M5IOt31q0YURsSEipiNi+sADDxxEW3e3eru0dpb9eAEAQN+M00QOFxyLiLhL0sltL7ZXSlq5bNmynjestrTiN7Vk1yQPAAAwUlasu1S33L1Ti/bfR1vWHDXs5jxunCp9M5IOyrxeLOnWIbVlfqj4AQAw8m65e6duXPca3XL3zmE3ZTfjFPq2SjrU9sG295J0vKRNdS9m710AADDORjL02T5P0uWSnm17xvaJEfGIpFMkXSzpOklfjYhrO7jnStsbZmdn+9PoTkwtYVIHAADoqZEMfRFxQkQ8LSKeEBGLI+Ls5PhFEfGsiHhmRHykw3s2p9KXXbSZ8AcAAHpgJENfPzSq0iftGt8nEf4AAEDXCH2JRlX6srLhj+AHAADmaZyWbOlKI5ZsqbJ6eyv0ZffpZWkXAABQE5W+RGMrfVlp1S/9koqrf2k4pDIIAMBArVh3qRbtv8+wm1GISt8oK6r+Sckiz7NzjwMAgL5K1+hrIkJfovHdu2WqunfZ4QMAgIHI7sLRVIS+RERslrR5enr6pGG3pWfSoLd+eeuL4AcAQE9lw15TK3wpQt8kyHYDp1W/9cvLt3ujMggAQKk06EkaibCXIvRNimzVLw1/a0vWJMyOBUzDIUEQADDBRjXoZRH6EiM7pq9TdYJbOhbw8e9nd58wQgAEAIypbLjLGtWgl0XoS4zlmL75Kgp02WP5ruKsdJkYQiEAYESMQxWvDkIfOpfdGziV7QZOxwrSNQwAaIiyCp403kEvi9CH7mSDXXavYKl1nPUCAQADVhTwJiXYVSH0Yf6mlrT+zE8Iya4PmH2dfk/VDwDQJSp3nSP0Yf7Kwlv+ePZ1Gv6qun4ZFwgASIzzxIpBI/QlJmb27rBlq4Bls4Kz6wcyLhAAxlZVtS5FuOsdQl+C2bsDUlUFzM4KlnYPh4wLBICRRDdscxD60Bx19hFOv8/vKkIlEAAGpk6FLkWwaw5CH0ZDWUUwnURStHYgXcMA0JG6YY4gN5oIfRg9VYtH58cI0jUMYAJ1UonLIsyNt7EPfbb3lfRpSQ9J+m5EfHnITUI/FQXCbNdw9hjVPwANNt/gJhHeUGwkQ5/tjZKOkXR7RDwvc/xoSZ+StEDS5yNinaTfl3RhRGy2fYEkQt+kKQp3RbOGs93BEl3DALq2Yt2lkqQta47qOMQR3NBrIxn6JJ0j6UxJ56YHbC+QdJakV0iakbTV9iZJiyWl/2o/OthmorGqxgim6wSWLSkDYKx1U2HLW7T/PpKkpWu+RYjD0I1k6IuIy2wvzR0+QtKOiLhBkmyfL+lYtQLgYklXS9pjgM3EqKhaRqZqYeksAiHQKHSNAnONZOgrsUjSzZnXM5J+W9IZks60/RpJm4sutL1K0ipJWrJkSZ+biZGVX1g6qygQFnUbEwwx4dIwtmj/fbRlzVGF7/UCwQ2Ya5xCnwuORUTcJ+ntVRdGxAbbt0lauddee72oL63D6KuzjmA2EKZBcPamXbOIi6qE2XukIbHd5wFDULUdlqSOlvpYse5SLV3zrcL3APTHOIW+GUkHZV4vlnRr3YvZkQNdqRPQHt9pZLb4/WxIzIbIOvemmjix2u12kK2mdVtJKwtl6WSFTgJbvsoHoP/GKfRtlXSo7YMl3SLpeElvqnsxe++i57LBTeosjOXXHczOKM5/RrpfcdmahATCocmGrF4HsFRVdSxfTetXJY0AB4yGkQx9ts+TdKSkhbZnJJ0WEWfbPkXSxWot2bIxIq4dYjMx6ToNWPmQmL1HdkZxVtH6g/nZxkWBsCgIjnk4LBpLlg9enXRT1pENWYMKYFmEMQBZIxn6IuKEkuMXSbponvekexfDVRW06oawsqVopNaf65eXB8H02Prlu87rszqD+quCWLdjyfLBaz7dlHURwAAM20iGvn6gexcjqag6mCpaiiYfBKW5i1Kv3r5bGFyx7lJdsPMkLfadu93uNh2op63dsdux+S4+WzWovyqI9XosGcEMwDhzRAy7DY0yPT0d27Zt6/8HrZ0qH9APtNHNKv9Z33/iOyVJL33wjDnHdwt5RV2+a6e09IGv7Hbo8r3fpadN7dO+SjjmXckAILUW5e73MA7bV0bEdJ1zqfQBXWrXRSmp1gD+9Po6Ia53q/y3rrux5HilqSW6cWpN8RZ2RTOPs0vRVE08AQD0BaEvQfcu8uGtbgWtXRelpFoD+NPrR2atsnx3cb5ynd3CTmqdUzT7uGgyCtU/AOg5undz6N4dHUUD/TsNbFn5a4sqd+hSnW7dutvcZSuHdBcDaCC6dzGxiro6i96bT4VN0m7Vtm6qZQS9PqoTyIrOKdrNJN+VnM48zi9Z0yl2RAEwpgh9Cbp3ey9fMUu/z3eBSt2NUcuGNALbmGq3m0mqaMma/D3aVRHb7YiSH79YVGEkOAJoIEJfgnX65q9qYkK++kYow7zMJzyVdQfXGXuY3xElezw/CSX7fTYQlu2xDABDQujDHPNda60MQQ+NUBYc6y6KXbTYdSpbGUxDZfb87LjDvDrjG6uqigBQE6EPhVtRjcTsUWCQiha7Lnsve6xqhrM0d/Zy1dI22XGL2TBZ1gYAyCD0JSZhTF+7blgAfdAujOWXrclPUMkey94vvSZbPaya+VwUDrPnU0EExh6hLzFuY/qKAh7hDmig+c5oLpJWBrOylcE04GW7jcu6o/P3yLejaJkcls4BGo3QNyboogUmTHYcYdWkkbJxiflw2G7ySvYe2cCYP7/OTiu9CIcETKBjhL4xccvdOwl5wCSpmmRS55pO75sGv3w1seieU0ta11Z1JafhsO5i3HlFW/nRXQ1UIvSNsGx1L13nDsAE6le4yd63k32S81v0ZSelZJWtv1i0BE5+BnQ24NbpriYQAoS+1ChM5KALF8DIyE84qTonL78ETrsZ0EWBsmr2dDZUVrUDGDOEvkRTJ3Lkq3mEPABDkQ1i/b6uanmcovt3cq+sorGQVXs6z6dayNhDNAihr+EYqwegEeYbWPoddOZz/3wQrVoyp6zSWLe7u2jsITAkhL6Gyu5bCwDooU6DYtlklWxwLJtBnV1rMT+5pR2qhOgxQl8DrVh3qSRR4QOApsqOGZSKxxrmz6+zm0p+/+ayKiGBEPNA6GsgunQBYER0EriKdlMp2pEl7VLOj1es2qIvfb8qCBIUJ97Yhz7bh0j6gKSpiDhu2O2pQpcuAEyYsvBVdDwbEosmsLQbP8j4wonX6NBne6OkYyTdHhHPyxw/WtKnJC2Q9PmIWFd2j4i4QdKJti/sd3vnKxv2qPABwJib70xoaW4YLBormD2Wre4Vofo3URod+iSdI+lMSeemB2wvkHSWpFdImpG01fYmtQLg6bnr3xERtw+mqfNHdy4ATJBOw1VVSFy9fW7lLnssre5lu4uzXcr5rfNYxHqsNTr0RcRltpfmDh8haUdSwZPt8yUdGxGnq1UV7JjtVZJWSdKSJfP4f14AAPRLu+BVFArzx7L3aLd2YafL0vQCFceBaHToK7FI0s2Z1zOSfrvsZNsHSPqIpMNtn5qEw91ExAZJGyRpeno6ettcAAD6qCgk9bKaWHd/5PkGt+wMaMYb9tUohj4XHCsNahFxl6ST2950SNuwrVh3KRM3AADD1W4twrL9kbOyXclVaxLmw2HRNnroi1EMfTOSDsq8Xizp1iG1pWuM5wMANFI3u7CkaxKmsotYF+10goEYxdC3VdKhtg+WdIuk4yW9qdubNnXvXQAAGqdoR5JseCvq+pV2r+i1qy4ytq/nGh36bJ8n6UhJC23PSDotIs62fYqki9WasbsxIq7twWcNpXsXAICRk19ous6OJJ3ct6iLuGgHE3Sk0aEvIk4oOX6RpIt6/FlU+gAAaIKipWjK9jdOMQO4rT2G3YCmsL3S9obZWQaTAgAwdGlXb1rhy0rHA2bfSyeEtAuHE4zQl4iIzRGxamqK6eIAANQytaR/EzFWb999zcDs51QFvDQslgXGCdbo7t1BYkwfAAAdGkQ3avYz6qzjV3Z+WffvBI0VJPQlGNMHAEDD5WcN57eUqzo/rQ52OlZwjBD6hmjpmm+xMDMAAHXlq3HtqnP5WcYTjtCXGEb3LosyAwAwAHXHHWa7gKWxmw3MRI4EEzkAABhTq7fvCm5Vs4KzE0TGcDYwlT4AADA5sgtAZ8cH5scKjiFCHwAAmDxVXbZj0p2bR/dugsWZAQDAOCP0JRjTBwAAxhmhDwAAYAIQ+gAAACYAoQ8AAGACEPoSTOQAAADjjCVbEuy9CwAA5sjv9zvCu3RQ6QMAACizentrZ45U2S4d6WLPRTt9NASVPgAAgHbaVfbSbdvWNnfpNyp9AAAAnajav7fBqPQBAAB0Iq36NbiqV2TsK322X2f7c7a/YfuVw24PAAAYE1NLRqra1+jQZ3uj7dttX5M7frTt623vsL2m6h4R8fWIOEnS2yS9sY/NBQAAk2T19uJJHQ3V9O7dcySdKenc9IDtBZLOkvQKSTOSttreJGmBpNNz178jIm5Pvv9gch0AAMDEaXToi4jLbC/NHT5C0o6IuEGSbJ8v6diIOF3SMfl72LakdZK+HRE/7G+LAQAAmqnR3bslFkm6OfN6JjlW5k8lvVzScbZPLjrB9irb22xvu+OOO3rXUgAAgIZodKWvhAuORdnJEXGGpDOqbhgRG2zfJmnlXnvt9aIu2wcAANA4o1jpm5F0UOb1Ykm3dnvTiNgcEaumpkZr+jUAAEAdoxj6tko61PbBtveSdLykTd3e1PZK2xtmZ2fbnwwAACDN3Zu3wRrdvWv7PElHSlpoe0bSaRFxtu1TJF2s1ozdjRFx7RCbCQAAJlW77dkapNGhLyJOKDl+kaSLevxZmyVtnp6ePqmX9wUAAGiCUeze7Qu6dwEAwDgj9CWYyAEAAMYZoQ8AAGACEPoSdO8CAIBxRuhL0L0LAADGWdvQZ/tLdY4BAACguepU+p6bfWF7gaSx26qM7l0AADDOSkOf7VNt3yvp+bbvSb7ulXS7pG8MrIUDQvcuAAAYZ6WhLyJOj4j9JH0sIp6cfO0XEQdExKkDbCMAAAC61HZHjog41fYiSc/Inh8Rl/WzYQAAAOidtqHP9jpJx0v6saRHk8MhaaxCn+2VklYuW7Zs2E0BAADouTp7775e0rMj4sF+N2aY2HsXAACMszqzd2+Q9IR+NwQAAAD9U6fSd7+kq21fIunxal9EvLNvrQIAAEBP1Ql9m5IvAAAAjKg6s3e/OIiGDBsTOQAAwDirsw3bT2zfkP8aROMGicWZAQDAOKvTvTud+X5vSX8o6Sn9aQ4AAAD6oW2lLyLuynzdEhGflHTUANoGAACAHqmzOPMLMy/3UKvyt1/fWgQAAICeq9O9+/HM949IulHSG/rSGgAAAPRFndm7LxtEQ/rF9m9IepekhZIuiYi/GnKTAAAABq7O7N0p25+wvS35+rjtgUxxtb3R9u22r8kdP9r29bZ32F5TdY+IuC4iTlarOjlddS4AAMC4qrMN20ZJ96oVmt4g6R5JX+hnozLOkXR09oDtBZLOkvQqSYdJOsH2YbaX2/5m7uupyTWvlfR9SZcMqN0AAACNUmdM3zMj4g8yr/+b7av71aCsiLjM9tLc4SMk7YiIGyTJ9vmSjo2I0yUdU3KfTZI22f6WpK/k37e9StIqSVqyZEnP2g8AANAUdSp9O22/NH1he4Wknf1rUluLJN2ceT2THCtk+0jbZ9j+rKSLis6JiA0RMR0R0wceeGBvWwsAACbH1BJp/fJht6JQnUrff5H0xcw4vl9KelvfWtSeC45F2ckR8V1J3217U7ZhAwAA3Vq9XVrbzN296szevVrSb9p+cvL6nr63qtqMpIMyrxdLunVIbQEAABgJdWbv/g/b+0fEPRFxj+1fs/3fB9G4ElslHWr7YNt7STpe0qZub8reuwAAYJzVGdP3qoi4O30REb+U9Or+NWkX2+dJulzSs23P2D4xIh6RdIqkiyVdJ+mrEXFtDz5rpe0Ns7Oz3d4KAACgceqM6Vtg+4kR8aAk2d5H0hP726yWiDih5PhFKpmU0cVnbZa0eXp6+qRe3hcAAKAJ6oS+v5Z0ie0vqDVh4h2SvtjXVg0BEzkAAMA4c0TpxNddJ9lHS3q5WjNnvxMRF/e7YcNi+w5JPx3ARy2UdOcAPgf18UyaiefSPDyTZuK5NM8gnskzIqLWenO1Qh96z/a2iGBbuAbhmTQTz6V5eCbNxHNpnqY9kzoTOQAAADDiCH0AAAATgNA3PBuG3QDMwTNpJp5L8/BMmonn0jyNeialY/psb1f19mbP71ejAAAA0FtVS7Yck/z5J8mfX0r+/CNJ9/etRQAAAOi5trN3bW+JiBXtjgEAAKC56ozp29f2S9MXtn9H0r79axIAAAB6rc6OHCdK2mh7Sq0xfrNq7coBAACAEVF7cWbbT07On+1vkwAAANBrbbt3bf+67bMlXRARs7YPs33iANoGAACAHqkzpu8cSRdLenry+l8lvbtfDQIAAEDv1Ql9CyPiq5Iek6SIeETSo31tFQAAAHqqTui7z/YBShZqtv1itSZzAAAAYETUCX3vlbRJ0jNtb5F0rqR39rVVADAAtn+V+XrM9s7M6z/q4r5X2H5zL9ua3Pdk23/f6/sCmAxtl2yJiCtt/66kZ0uypOsj4uG+twwA+iwinpR+b/tGSX8cEYQqAGOpzuzd/6PWX4TXRsQ1EfGw7W8OoG0AMFS2F9j+M9s32L7T9pdt75+8t6/t823/wvbdtn9g+9dsf1zSb0n6fFIx/HjBfQuvTd57iu1zbf/M9s22T7O9h+3DJX1S0pHJfX+WnH+s7X+xfW9yPj0xAArV6d59WNLLbH/B9l7JsUV9bBMANMX7Jb1S0kslLVbr78P1yXt/rFZvySJJCyWdIumhiHivpK1q/Z/lJyWv8wqvTd77slrjpg+RdISk10n6TxFxlVorJ3w3ue+/T87fKOktEbGfpBdI+l6PfnYAY6ZO6Ls/It4o6TpJ37P9DCWTOgBgzP1nSWsi4taIeEDSf5P0RttWKwAeKOmZEfFIRGyNiPtq3rfw2uTv1/8o6T0RcX9E3CbpDEnHV9zrEUnPtb1fRNyVhEMAmKNO6LMkRcRHJf1/aq3Zt7ifjQKAYUuC3UGSLkq6YO+WdJVaf28eIOlsSf8o6ULbM7b/h+0FNW9fdu0zJO0t6Y7MZ35K0q9X3Ot1kv5A0k22L7U9PY8fF8AEqBP6/jz9JiIukfT/SDqzby0CgAaI1h6Vt0g6KiL2z3ztHRF3RsSDEfHnEfEctapzf6hdFbnK3pCKa2+W9CtJv5b5vCdHxAvL7hsRl0fEMWoFw+9IOq/7nx7AOCoNfbafk3x7i+0Xpl9q/T9cJnIAmASfkbTO9kGSZPuptlcm37882ZZyD0n3qNXNmi5c/3O1xuQVKrs2In4i6QpJH7W9XzKB41DbL83c9yDbT0jus6/t45O90R+WdK9YPB9AiapKXzr4+OMFX3/Z53YBQBN8VNLfS7rU9r2S/rektOq2SNI31Apa10i6SNJXk/fWS3qL7V/a/mjBfauuPUHS/pL+RdIvJF2gXd27fyfpRkm3255Jjr1D0k/VmvzxFklv7eonBjC23OrBAAAAwDgrXZzZ9u9XXRgRX+t9cwAAANAPVTtyrKx4LyQR+gAAAEYE3bsAAAAToO3eu5Jk+zWSnqvW+lGSpIj4UL8aBQAAgN6qs/fuZyS9UdKfqrVQ8x+qtYAoAAAARkTb7l3bP4qI52f+fJKkr0XEKwfTxMFauHBhLF26dNjNAAAAaOvKK6+8MyIOrHNune7dncmf99t+uqS7JB0838Y13dKlS7Vt27ZhNwMAAKAt2z+te26d0PdN2/tL+pikH6o1c/fz82wbAAAAhqBt6IuIDyff/o3tb0raOyJm+9uswUu2Vlq5bNmyYTcFAACg59qGPtsLJL1G0tL0fNuKiE/0t2mDFRGbJW2enp4+adhtAQAA6LU63bubJT0gabukx/rbHAAAAPRDndC3OCKe3/eWTJr1y1t/rt4+3HYAAICJ0HadPknftj2Wy7MM1exNrS8AAIABqFPpu0LS39reQ9LDai3QHBHx5L62DAAAAD1TJ/R9XNJLJG0PNuoFAAAYSXW6d/9N0jXjHvhsr7S9YXZ27FajAQAAqFXpu03Sd21/W9KD6UGWbAEAABgddULfT5KvvZIvAAAAjJjK0JcszPykiHj/gNoDAACAPqgc0xcRj0p64YDaAgAAgD6p0717te1Nkv6XpPvSgxHxtb61CgAAAD1VJ/Q9RdJdko7KHAtJhL5uTS2R1k61/mRnDgAA0EdtQ19EvH0QDZlIadBbOzXcdgAAgLHXdp0+24tt/63t223/3Pbf2F48iMb1gu1DbJ9t+8JhtwUAAGBY6izO/AVJmyQ9XdIiSZuTY0Nje2MSQq/JHT/a9vW2d9heI0kRcUNEnDiclgIAADRDndB3YER8ISIeSb7OkXRgn9vVzjmSjs4eSJaXOUvSqyQdJukE24cNvmkAAADNUyf03Wn7zbYXJF9vVmtix9BExGWSfpE7fISkHUll7yFJ50s6duCNAwAAaKA6oe8dkt4g6Wdqbcl2XHKsaRZJujnzekbSItsH2P6MpMNtn1p0oe1VtrfZ3nbHHXcMoq27S2fxrl8++M8GAAAToc7s3ZskvXYAbemWC45FRNwl6eSqCyNig+3bJK3ca6+9XtSX1lVhFi8AAOiz0tBn+88rrouI+HAf2tONGUkHZV4vlnRr3YsjYrOkzdPT0yf1umG1sW4fAAAjb8W6S3XL3Tu1aP99tGXNUe0vGJCq7t37Cr4k6URJ/7XP7ZqPrZIOtX2w7b0kHa/WrONabK+0vWF2drZvDWxr9XZp7aw0e9Pw2gAAALpyy907deO61+iWu3cOuym7KQ19EfHx9EvSBkn7SHq7WhMkDhlQ+wrZPk/S5ZKebXvG9okR8YikUyRdLOk6SV+NiGvr3jMiNkfEqqkpulgBAMD4qRzTZ/spkt4j6Y8kfVHSCyPil4NoWJWIOKHk+EWSLhpwc3pvaknG48gJAAAcjUlEQVRrUgddvAAAoEdKK322P6ZWl+m9kpZHxNomBL5+aUT3bmr1drp4AQBAT1WN6XuvWrtwfFDSrbbvSb7utX3PYJo3OHTvAgCAcVbavRsRddbwGxu2V0pauWzZsmE3BQAAoOcmKthVaWylb/1yFm4GAABdI/Q1Vbpmn8QyLgAAoGttd+TAkORn7jKjFwAAdIFKX6JRs3eLMKMXAAB0gdCXaOyYPgAAMDJWrLtUi/bfZ9jNKET3LgAAQI+kW7A1EaEvMRJLtmQnd2SPMc4PAIChWrHuUt1y987GVvkkQt/jImKzpM3T09MnDbstpYrCXRoC1y+fO+aPQAgAwEA0ucKXIvSNi9mbWku7ZKVr/BH+AADoubS6J6nRFb4UoW/UpV2+U0vmvpcGvfXLWe4FAIAeyXblNr26l0XoG3V1gtzq7XPHAgIAgLay1bzUqIW9FKEvMRITObqRrQhS8QMAoNKoVvOqEPoSIzGRoxvZrt52VT+CIQBggoxTNa8KoW/S1AlzdAUDAMZcfhLGuAW8IoQ+AAAw9vLVvEkJelmEPvReumYg3cQAgCGaxGpeFUIf5ppasmuJl6JFn7Pn5UPd+uWtP9fO0k0MAOi77ISLLWuOIuhVIPRhruwSL0WLPqfWTs2t6mXPz24bR9UPANBD+dm1K9ZdqqVrvkXQq0DoS4z9ki2dqlr0OXuO1Ap52d0/UtmQV1b1SyuD2XOLjgEAJlK+cpdW8yTtFu62rDlqKO0bJYS+xNgv2dKpuos+1z2/bJ3Aoq7jsu5kAMBYqeqaTWUrd9lqHiGvc4Q+DEYa9OqO8+tmMWkmkgBA4xQFPEkddc0S9LpD6MNgFYW5omNVITEb6qTdAx4TSQBgaIoqdamisXdpiCPMDQahD4OV3xkkG/TahbRs2EvHEUpzxxTWqe5RDQSASvnKXNF7eXUmURDwhofQh+GoG7SyVcD8TOJOxhTmpffKBk2CIIAJU7RgsaTCWbFZzJAdTYQ+NFu2Mlg1k7hIp+MCi4IgAIyJOvvLMit2vBH60BxVy8TMp/JW1G2cHw84LqhSAhOnavxcEbpeQehDc/Q7rGTHAKayu4/kz20XosrWExxGAKNKCYyNsnXp2lXpgHbGPvTZ3lfSpyU9JOm7EfHlITcJw1K0u0h295FUdtHpqhBVtp4gAQyYeEXBrez9vLJ16Qh46NZIhj7bGyUdI+n2iHhe5vjRkj4laYGkz0fEOkm/L+nCiNhs+wJJhL5J0253kfz72epc0bjAbCVv1BaSphsY6EjRDNY63apFwa3s/Sp0t6KXRjL0STpH0pmSzk0P2F4g6SxJr5A0I2mr7U2SFktK/3V7dLDNRCO0CzdV7+eXmJF2LRmTPT6IpWJ6EdjSKmSn7QbGSFlXqaQ5M1lvuXvnnBmsnVbdCG5oipEMfRFxme2lucNHSNoRETdIku3zJR2rVgBcLOlqSXsU3c/2KkmrJGnJkjEb4I/eKAtGZaEwK18ZLOv6Tc/LyoayXnYbd7pDCjAE6UzSbGiqO3mhKMRl38uHtqJZqyvWXfr4fQhuGAcjGfpKLJJ0c+b1jKTflnSGpDNtv0bS5qILI2KDpA2SND09HX1uJ8ZRVbWsblgrGnNIKENDVAWwuvugthvnVnRfSbt1jdatshWFuCpFbSHoYdyMU+hzwbGIiPskvb3txfZKSSuXLVvW84ZhQrUbS9iJonUKi2YPtxuDCBSoE97S97PbZ2W7Plesu7R0lmmq3Ti3ovPmi8AGzDVOoW9G0kGZ14sl3Vr34ojYLGnz9PT0Sb1uGCZUvvpXFLrKln3JK6oCFk0iKeq2ZTbxRCqqzFWdd+O61zwewrLXlk1kSMNf9rxOZpkSyoDBG6fQt1XSobYPlnSLpOMlvanuxVT60HdFwa7b2b+9riaWTRSpG06ZHdxWp12ide+RP5atzGXl133L3iNbyZNUGuLoCgVG00iGPtvnSTpS0kLbM5JOi4izbZ8i6WK1lmzZGBHX1r0nlT4MVH5P4TrnFR0rC1Zli05XnVdVEWwXTrNhb8yqinU3na9aRDer3X6m871H/lhZqKyqyBHcgPE2kqEvIk4oOX6RpIvmc08qfRiobBirCkhFoa1OBW319t2XZak6r2hx6uxM5E72La5SVC2sW0EsUbcLMz03G9463fVg6ZpvFW5OP99FdDsNZHXv0e53QbADJtdIhr5+oNKHoellF21WnTGFRZ+fD2X5imSdLtxscMwey1cMH68O7jr3Nh2olzzwqcquy6rZnVnZ86Xdx62lkxDS+7cLW+lnlb3fizBFIAPQT4Q+YNgGNfat3VqDOa1gtU6StGjvfbRFr2/N0HzgJi194Cv6frxTi9dO6TYdqKflr33wU7rlgVz35APSjXu/abfuyC3J52craDfu/abCSQX5rsu6y3bMnPZMbfGdSajdPmfcmlQvbBHIAIw6Ql+C7l2MgzoD/PPnSnMrYtnlONJzs1rHW+89LanS1VpLbf0S3ag3SVNLtOLBTz1+3W7nr911j8fHpj3xXdJ6acuazgLyljVHSWvv3DXOcP1ybXngJunXS5a0mU8A77KLuvZnMEEGQJcIfQm6dzFKypbUyG8ZVbaNlFQ+Hk1ScSVs/RJtmX393G7i5PWNa2usq5ZZUmbL2qOktTW7S9f2aI/joskq3S5pM4j9l1l2B0APEPqAGuoss1EWxKTiraCk4gkE7SYV5JfjyM7azG8ZVXcbqVpdlx12D1dqN46xqLKVHydYtAB10Xud6lXlblDVuUFUGgGMBUJfgu7d0Tbftc/qXldn54Gitc3abQVVNEatatxa1XIcI7V2WlVASYPg2tndJ5Lkrymq1qXWL6+3ZE2R+VTuipbRqbPPctmaiJ2ExUFUGgGMBUJfgu7d0ZaGsuzg/6rqWnpN1XIcRdd0uvPAfJbP6LoiN+qyQWe+1auipWj6qWgnlCppICwKp3TlAugTQh8aq2wNtrJuz/TPdoGsqPrWbjmOrIkIXqMgv57gfK5td10vu42LdBpO6y663U5+P+ZBTxJhYgowFIQ+DExRiKsay5ZOQsiel52YUGS+S28Q5EZQN2EhOxawKvjlu43bBbSiIFpnB5W62oXEdmGqbOeUQVcWqWYCQ0HoSzCmrzt1xsZlq3PZ86vGsuWPZScmAJXqVPPmu0RLWbCq2kElWTJmtwpbr1V1G2ff7xcqeECjEfoSjOmr1m7/UUltx9T1YhN3KnKore6OJEWqAmM3Vaqq0NVpIMyen5/MUVQRbFfV7IV2v5t+h14AlQh9mKNq/9GqTeLT7zvZMQEYmHaVpzrdsNmw0un2eXW2weukCpcNkHUCaK+qfN1U8/pdaQRQidCHOVW8bsbMUYnDyKoTYLqZWdzpOofdTFSZj6LQWxTwejkeLx+c+9E1XPQz1D0GjBlC3wRoN96uaBcHAEPWLgx2U3XMXpf/vOzaiFUBr6oymp1lXNWlm/1MqX2YzM6mbhfOyiatSHN/rrqf3w1CJRqA0JcYl4kcRQGvbBuuVJ0dGwA0RNVkkayiHUw6uVe78FN1XnZMYZ3KYLsQlA9wddrXSVdyN93OdXdEmU+FNB8U2X0FXSL0JcZlIkdRwCPUAROo22DQSdWwqJqXrz52WoXMV/XyoSzf/d2uqtiNqipdv3ZEKao+Zj+LyiHmgdA3pgh4ALpSts5fPlBlt82rur7Xkz6y9+ukqphVt1u81+MY88vpFFXw2v387ZbnKVP0WVQQJwahb0xku3UBoKeqxu/1OijMd3xiXdngWtUt3m6s4nwVLafTTbWw011dij6L/ZsnBqFvhOV3s2CJFAB9McgK0Hw+q5Ou5LoVxHZjFat0MuGkH+j6RQlC3wjpZGkVAJgY/ag+zmfJnKIJJ9nZ0P1SNGmnF93RnYZHwmbjEfpGSBryimbgAgAqdNptPJ/QUlRFHET46ddndDqWkT2VG4/Ql2jqki35Ltz0T9bTA4AO9DN8zXccYtVWeuOKSSNDRehLNHXJlqIuXGbmAkCDzDfAZCuDaTdwqun7E8+3K3c+4ZZu454h9DUUs3EBoIHqLHpd9x5FO6IMQp19ptuZ724tvf4sdITQ11BM0gCABupFiOn0HtkQNd9u4KJqWbst77KzoTsJce3u3+tQiNoIfQAANFnRQtSdKppkUhUms+fX3Zqvrrr369cOKxOM0NdAK9ZdSrcuAGCuTiaNtFtMOr8rRz+rb/MJcN3siYxChL4GomsXAFCok0DWyW4dva7m5RHgGoHQ1yBM3gAANFq/u1yb1KU7hrOGxz702T5E0gckTUXEccNuTxUqfACAnup0DcGq89NjnVTsqkJc0YSOJs3UbVJbeqTRoc/2RknHSLo9Ip6XOX60pE9JWiDp8xGxruweEXGDpBNtX9jv9gIA0CidVqiqzp/PrGOpPCT2u0sZczQ69Ek6R9KZks5ND9heIOksSa+QNCNpq+1NagXA03PXvyMibh9MUwEAmDBVlcEx6RIdJ40OfRFxme2lucNHSNqRVPBk+3xJx0bE6WpVBUcOY/kAACOpX9W6ut3BvdakMYV90OjQV2KRpJszr2ck/XbZybYPkPQRSYfbPjUJh/lzVklaJUlLlgz+QTOWDwAw0nodkopC3XwCZqeTMcZwHF/WKIY+FxyLspMj4i5JJ1fdMCI2SNogSdPT06X3AgAABZralTvmIa5Tewy7AfMwI+mgzOvFkm7t9qa2V9reMDs72HWEWIgZAIAOpItOt5PdSg6SRjP0bZV0qO2Dbe8l6XhJm7q9aURsjohVU1OD/X8Dt9y9U1vWHDXQzwQAoDHSsXp1l5ZZvb16D+J0d5H03DqyO5KMsUZ379o+T9KRkhbanpF0WkScbfsUSRerNWN3Y0Rc24PPWilp5bJly7q9FQAAqKsXXcPp2D0pCZElvXZphTD/mROyY0ijQ19EnFBy/CJJF/X4szZL2jw9PX1SL+8LAAD6JDtRo05oq6oQToBGh75BotIHAMCIyC7fMgEVul4h9CWo9AEAMCLmsztIdsxev9f7ayhCHwAAGG9F4a5qGZcxndBB6EvQvQsAACSNbQVwFJds6YthLdkCAACGIO3yrbPmn7RrWZe65zcQoQ8AAEye1dtbk0DqzuhNl3UZ4RnAdO8m6N4FAGACjen4vSJU+hJ07wIAMIFWbx/bMXx5hD4AAIAJQOgboqVrvqVF++8z7GYAAIAJwJi+xDDG9N247jUD+ywAADAP+YWdpd23f0u7houONQyVvgRj+gAAwBzpLN9skCuayTsCs3sJfQAAABOA7l0AAIC6ipZ4Wb98JJZ+IfQBAADUVTReL+3abTi6dxO2V9reMDvb/IcGAADQKUJfgokcAABgnBH6AAAAJgChDwAAYAIQ+gAAACYAoQ8AAGACEPoAAADmo2iLtgZjnb7EMPbeBQAAI6yhe+yWodKXYMkWAAAwzgh9AAAAE4DQBwAAMAEIfQAAABOA0AcAADABCH0AAAATgNAHAAAwAcY+9Nl+ne3P2f6G7VcOuz0AAADD0OjQZ3uj7dttX5M7frTt623vsL2m6h4R8fWIOEnS2yS9sY/NBQAAaKym78hxjqQzJZ2bHrC9QNJZkl4haUbSVtubJC2QdHru+ndExO3J9x9MrgMAAJg4jQ59EXGZ7aW5w0dI2hERN0iS7fMlHRsRp0s6Jn8P25a0TtK3I+KH/W0xAABAMzW6e7fEIkk3Z17PJMfK/Kmkl0s6zvbJRSfYXmV7m+1td9xxR+9aCgAAJsvUEmntlLR++bBbMkejK30lXHAsyk6OiDMknVF1w4jYIGmDJE1PT5feCwAAoNLq7a0/104Ntx0FRrHSNyPpoMzrxZJu7famtlfa3jA7O9vtrQAAABpnFEPfVkmH2j7Y9l6Sjpe0qdubRsTmiFg1NdW8ZA4AANCtRoc+2+dJulzSs23P2D4xIh6RdIqkiyVdJ+mrEXFtDz6LSh8AABhbjR7TFxEnlBy/SNJFPf6szZI2T09Pn9TL+wIAADRBoyt9g0SlDwAAjDNHMFk1y/Ydkn46gI9aKOnOAXwO6uOZNBPPpXl4Js3Ec2meQTyTZ0TEgXVOJPQNie1tETE97HZgF55JM/Fcmodn0kw8l+Zp2jOhexcAAGACEPoAAAAmAKFveDYMuwGYg2fSTDyX5uGZNBPPpXka9UwY0wcAADABqPQBAABMAEJfn9k+2vb1tnfYXlPw/hNtX5C8/wPbSwffyslS45m8x/aPbf/I9iW2nzGMdk6Sds8kc95xtsN2Y2bDjbM6z8X2G5L/Xq61/ZVBt3HS1Pj7a4ntf7B9VfJ32KuH0c5JYnuj7dttX1Pyvm2fkTyzH9l+4aDbmCL09ZHtBZLOkvQqSYdJOsH2YbnTTpT0y4hYJmm9pL8YbCsnS81ncpWk6Yh4vqQLJX10sK2cLDWfiWzvJ+mdkn4w2BZOpjrPxfahkk6VtCIinivp3QNv6ASp+d/KB9XanvRwtfam//RgWzmRzpF0dMX7r5J0aPK1StJfDaBNhQh9/XWEpB0RcUNEPCTpfEnH5s45VtIXk+8vlPR7tj3ANk6ats8kIv4hIu5PXl4hafGA2zhp6vx3IkkfViuAPzDIxk2wOs/lJElnRcQvJSkibh9wGydNnWcSkp6cfD8l6dYBtm8iRcRlkn5Rccqxks6Nlisk7W/7aYNp3e4Iff21SNLNmdczybHCcyLiEUmzkg4YSOsmU51nknWipG/3tUVo+0xsHy7poIj45iAbNuHq/LfyLEnPsr3F9hW2q6od6F6dZ7JW0pttz6i1R/2fDqZpqNDpvzt9s+cwPnSCFFXs8tOl65yD3qn9+7b9ZknTkn63ry1C5TOxvYdaQx/eNqgGQVK9/1b2VKvL6ki1KuLfs/28iLi7z22bVHWeyQmSzomIj9t+iaQvJc/ksf43DyUa8+88lb7+mpF0UOb1Ys0ttT9+ju091SrHV5WJ0Z06z0S2Xy7pA5JeGxEPDqhtk6rdM9lP0vMkfdf2jZJeLGkTkzn6ru7fX9+IiIcj4ieSrlcrBKI/6jyTEyV9VZIi4nJJe6u1/yuGp9a/O4NA6OuvrZIOtX2w7b3UGlS7KXfOJklvTb4/TtKlweKJ/dT2mSRdiZ9VK/AxRqn/Kp9JRMxGxMKIWBoRS9UaZ/naiNg2nOZOjDp/f31d0sskyfZCtbp7bxhoKydLnWdyk6TfkyTbv6FW6LtjoK1E3iZJb0lm8b5Y0mxE3DaMhtC920cR8YjtUyRdLGmBpI0Rca3tD0naFhGbJJ2tVvl9h1oVvuOH1+LxV/OZfEzSkyT9r2ROzU0R8dqhNXrM1XwmGLCaz+ViSa+0/WNJj0p6f0TcNbxWj7eaz+S9kj5ne7VaXYhvo5DQX7bPU2uIw8JkLOVpkp4gSRHxGbXGVr5a0g5J90t6+3Bayo4cAAAAE4HuXQAAgAlA6AMAAJgAhD4AAIAJQOgDAACYAIQ+AACACUDoAwAAmACEPgAAgAlA6ANGlO1HbV9t+59t/9D27xS8d23y/nts72H7gOT41bZ/ZvuWzOu9+tjWtbbfl3n9vyvO3d/2/9vtZ/SK7aW2r+nVNdmf3favssfn+7P3W7t2VT3Ppsn/zpM/O37GwCgi9AGja2dEvCAiflPSqZJOL3jvuZJeodZq8KdFxF3J8RdI+oyk9enriHiokw9PthSa198hEfE7FW/vL2mgwaebn6VTZT97cnzgP3tNle1q8zwba1TbDcwXoQ9oONvftf3s5PsDSioST5b0y6Lrk/2DV0k6xcm+cjU+c6ntf7H9Rds/sn2h7X+XHL/O9qcl/VDSQbbfbPufkmrhZ20vSO7xAdvX2/57Sc/O3T9bbXlL8hn/bPtLktZJemZyv48l53T8GfP8Wd5j+5rk692Z2+yZvz5z/6/bvjKpqq5qd032Zy/4nez2s9v+sO13Zc75iO13Flxb9vv5i2yFLqmGvrfsmszv5HPJz/Md2/sUPZOi52l7X9vfSp7lNbbfWPIsPp+8/2XbL7e9xfa/2T4ic941meveZ3tt8v2cZ1TR7kpFz8L2Ibavsv1bVb9bYCRFBF988dXgL0kzkvZIvn+ZpPOS7x+VdLWkf5E0K+lFmWt+VXCfX0r69czrtZLeV/KZS9Xat3NF8nqjpPclxx+T9OLk+G9I2izpCcnrT0t6i6QXSdou6d+pFUh3ZD8rbZ+k50q6XtLC5PVTks+4JnPuvD5jHj9Ler991dp7+VpJh5ddn7n/U5I/95F0jaQDqq7JPpv89wU/+1JJP0y+30PS/5F0QO7nK/z9JN8fLukfM+f+WNKSit/pUkmPSHpBcvyrkt6cb1fB7zh9nn8g6XOZ41MFz+IRScuTn+fK5HdjScdK+nrmvOzv4X1q/e+16hnNaXdVW3PtXpo8u2dLuipzn9LfLV98jeIXlT6gwWw/Q9ItEfFYcuj5kn6UfJ924T5H0tGSzrUrK3m1qnwZN0fEluT7v5b00uT7n0bEFcn3v6fWP8RbbV+dvD5E0n+Q9LcRcX9E3CNpU8lnHCXpwoi4U5Ii4hcF53T7GXV/lpcm97svIn4l6WvJZ1RdL0nvtP3Pkq6QdJCkQ2tcU0tE3CjpLtuHS3qlpKsi4q7caWW/H0XEVZKeavvptn9T0i8j4qaqayT9JCKuTr6/Uq1AVNd2SS9PKoz/ISJmC875SURsT/43fa2kSyIikmvbfVbVM+qm3ZJ0oKRvqBUW0/tU/Z6AkbPnsBsAoNILtCvkSa1/gC7InxQRl9teqNY/XLfn37d9iFqVwTnvVYiS1/dlby3pixFxau7z3l1wfRHXOK/bz1DBeWU/S0fX2z5S0sslvSQi7rf9XUl7t/nMTn1e0tsk/Xu1qmJ5hb+fjAslHZdcf37VNbaXSnowc+hRtSqYtUTEv9p+kVpjSE+3/Z2I+FDutOz9H8u8fky7/k16RLsPP0p/p1XPqLDdtv9E0knJ8VdXXD8r6WZJK9QKo+nnVf1ugZFCpQ9ott9U8g+e7UPV6gLbnj/J9nMkLZCUrwLJ9oFqTdo4M6mo1LXE9kuS70+Q9P2Ccy6RdJztpyaf9ZSkOnmZpNfb3sf2fpJWlnzGJZLeYPuA9HpJ90rar4efUfdnuUzS69wa77evpNdL+l6b66fUqp7dnzyDF3f4mXn5n12S/latSu5vSbq44Jqy30/qfEnHqxX8Lqx5TZ12zWH76ZLuj4i/lvSXkl7Y7poSP1erQnmA7SdKOiY5XvWMCkXEWbFrstKtFac+JOl1kt5i+03JsU5/T0CjUekDmu0FknYm3Yc/knSdpLdK+rCkfZIuJ6lVkXhrRDyavE7fe4JaVZMvSfpEh599naS32v6spH+T9FeSnpo9ISJ+bPuDkr7j1uzXhyX9SURcYfsCtcYc/lQl/zBHxLW2PyLpH20/qlb35duSgf3XSPp2RLy/m8/o4Gf5oe1zJP1TcujzEXFVUv0qul6S/k7SybZ/pNbYxCsytyy7plRE3JX/2SPiIdv/IOnuzPPNXlP4DJLfSfo73k+tYQK3tbnmZ3XbVfIjLJf0MduPJff8L+1+5pLPe9j2hyT9QNJP1Bq32u4ZdS0i7rN9jKT/3/Z9EfGNqt8tMGrc2f/xBzBItndIOjwi7h3w5y6V9M2IeN4gP7cfRv1nScLGDyX9YUT827DbA2B00b0LNFRSnXls0IEPzWH7MLVmJV9C4APQLSp9AAAAE4BKHwAAwAQg9AEAAEwAQh8AAMAEIPQBAABMAEIfAADABCD0AQAATABCHwAAwAQg9AEAAEyA/wu83YlZ6QlUPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "for cum in [True, False]:\n",
    "    for scale in ['linear', 'log']:\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "        axs = gen_hist(axs, '$\\\\mu$BDT predicted probability event is muon-like', scale,\n",
    "                       train_sig_probs, train_bkg_probs, test_sig_probs, test_bkg_probs,\n",
    "                       train_sig_weights, train_bkg_weights, test_sig_weights, test_bkg_weights, \n",
    "                       bins=300, histtype='step', density=True, cumulative=cum)\n",
    "        \n",
    "        fig.text(0.04, 0.5, 'Normalized count', va='center', rotation='vertical')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to compute results of two-sample Kolmogorov-Smirnov test\n",
    "# see https://stackoverflow.com/questions/40044375/how-to-calculate-the-kolmogorov-smirnov-statistic-between-two-weighted-samples\n",
    "def ks_test_weighted(data1, data2, wei1, wei2, alpha=0.05):\n",
    "    # compute k-s test statistic\n",
    "    ix1 = np.argsort(data1)\n",
    "    ix2 = np.argsort(data2)\n",
    "    data1 = data1[ix1]\n",
    "    data2 = data2[ix2]\n",
    "    wei1 = wei1[ix1]\n",
    "    wei2 = wei2[ix2]\n",
    "    data = np.concatenate([data1, data2])\n",
    "    cwei1 = np.hstack([0, np.cumsum(wei1)/sum(wei1)])\n",
    "    cwei2 = np.hstack([0, np.cumsum(wei2)/sum(wei2)])\n",
    "    cdf1we = cwei1[[np.searchsorted(data1, data, side='right')]]\n",
    "    cdf2we = cwei2[[np.searchsorted(data2, data, side='right')]]\n",
    "    statistic = np.max(np.abs(cdf1we - cdf2we))\n",
    "    \n",
    "    # compute p-value\n",
    "    pvalue = 1 - kstwobign.cdf(statistic)\n",
    "    \n",
    "    return statistic, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvillarreal/.local/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n",
      "/home/jvillarreal/.local/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muon K-S test statistic, p-value: (0.004494199708250324, 1.0)\n",
      "neutrino K-S test statistic, p-value: (0.0730103493674169, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# report result of K-S test\n",
    "ks_sig = ks_test_weighted(train_sig_probs, test_sig_probs, \n",
    "                          train_sig_weights.reset_index(drop=True).values, \n",
    "                          test_sig_weights.reset_index(drop=True).values)\n",
    "ks_bkg = ks_test_weighted(train_bkg_probs, test_bkg_probs, \n",
    "                          train_bkg_weights.reset_index(drop=True).values, \n",
    "                          test_bkg_weights.reset_index(drop=True).values)\n",
    "\n",
    "print('muon K-S test statistic, p-value:', ks_sig)\n",
    "print('neutrino K-S test statistic, p-value:', ks_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# proceedings plot\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "# plotting differential distribution\n",
    "ax = gen_hist_sing(ax, '$\\\\mu$BDT predicted probability event is muon-like', 'symlog',\n",
    "               train_sig_probs, train_bkg_probs, test_sig_probs, test_bkg_probs,\n",
    "               train_sig_weights, train_bkg_weights, test_sig_weights, test_bkg_weights, \n",
    "               bins=300, histtype='step', density=True, cumulative=True)\n",
    "\n",
    "# set yticks\n",
    "ticks = np.concatenate(([0], np.logspace(-1, 0, 5)))\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(['0', '$10^{-1}$', '', '', '', '$10^0$'])\n",
    "\n",
    "# axis labels\n",
    "fig.text(0.06, 0.5, 'Cumulative probability density', va='center', rotation='vertical')\n",
    "\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "# manual legend\n",
    "legend_elements = [Patch(facecolor='white', edgecolor='C0', label='Muon samples'),\n",
    "                   Patch(facecolor='white', edgecolor='C1', label='Neutrino samples')]\n",
    "\n",
    "fig.legend(handles=legend_elements, ncol=2, loc=(0.335, 0.005))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "corr = ax.matshow(X.drop(columns='norm-rate').corr())\n",
    "\n",
    "cb = plt.colorbar(corr, ax=ax)\n",
    "ax.set_xticks(np.arange(0, 21))\n",
    "ax.set_xticklabels(X.drop(columns='norm-rate').columns, rotation='vertical', minor=False)\n",
    "ax.set_yticks(np.arange(0, 21))\n",
    "ax.set_yticklabels(X.drop(columns='norm-rate').columns, minor=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ZTravel', 'COGZ', 'COGZSigma', 'RLogL', 'RecoZenith', 'QTot', 'LDir_A',\n",
       "       'NDirPulse_A', 'NDirDOM_A', 'NDirStr_A', 'LDir_B', 'NDirPulse_B',\n",
       "       'NDirDOM_B', 'NDirStr_B', 'LDir_C', 'NDirPulse_C', 'NDirStr_C',\n",
       "       'LDir_E', 'NDirPulse_E', 'NDirStr_E', 'RecoAngSep', 'norm-rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484596, 22)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZTravel</th>\n",
       "      <th>COGZ</th>\n",
       "      <th>COGZSigma</th>\n",
       "      <th>RLogL</th>\n",
       "      <th>RecoZenith</th>\n",
       "      <th>QTot</th>\n",
       "      <th>LDir_A</th>\n",
       "      <th>NDirPulse_A</th>\n",
       "      <th>NDirDOM_A</th>\n",
       "      <th>NDirStr_A</th>\n",
       "      <th>...</th>\n",
       "      <th>LDir_C</th>\n",
       "      <th>NDirPulse_C</th>\n",
       "      <th>NDirStr_C</th>\n",
       "      <th>LDir_E</th>\n",
       "      <th>NDirPulse_E</th>\n",
       "      <th>NDirStr_E</th>\n",
       "      <th>RecoAngSep</th>\n",
       "      <th>norm-rate</th>\n",
       "      <th>muon</th>\n",
       "      <th>solar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.181664</td>\n",
       "      <td>195.756485</td>\n",
       "      <td>37.022224</td>\n",
       "      <td>33.874021</td>\n",
       "      <td>2.016922</td>\n",
       "      <td>9.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>111.748897</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.811024</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.185846e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.323990</td>\n",
       "      <td>-464.713231</td>\n",
       "      <td>33.373538</td>\n",
       "      <td>11.684740</td>\n",
       "      <td>2.099566</td>\n",
       "      <td>15.725</td>\n",
       "      <td>142.279987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.279987</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.073092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>4.625277e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.034170</td>\n",
       "      <td>-466.306037</td>\n",
       "      <td>52.105987</td>\n",
       "      <td>12.071475</td>\n",
       "      <td>1.492967</td>\n",
       "      <td>12.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.965718</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222.568092</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.348411</td>\n",
       "      <td>1.171941e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.293069</td>\n",
       "      <td>-462.026478</td>\n",
       "      <td>37.073835</td>\n",
       "      <td>10.617668</td>\n",
       "      <td>2.625600</td>\n",
       "      <td>19.375</td>\n",
       "      <td>74.020239</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.686728</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.107589</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.095909</td>\n",
       "      <td>8.185290e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.637226</td>\n",
       "      <td>-425.194122</td>\n",
       "      <td>75.872357</td>\n",
       "      <td>10.144056</td>\n",
       "      <td>2.269713</td>\n",
       "      <td>28.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.763115</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.239432</td>\n",
       "      <td>1.411252e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZTravel        COGZ  COGZSigma      RLogL  RecoZenith    QTot  \\\n",
       "0  16.181664  195.756485  37.022224  33.874021    2.016922   9.025   \n",
       "1  30.323990 -464.713231  33.373538  11.684740    2.099566  15.725   \n",
       "2  33.034170 -466.306037  52.105987  12.071475    1.492967  12.050   \n",
       "3  30.293069 -462.026478  37.073835  10.617668    2.625600  19.375   \n",
       "4  56.637226 -425.194122  75.872357  10.144056    2.269713  28.125   \n",
       "\n",
       "       LDir_A  NDirPulse_A  NDirDOM_A  NDirStr_A  ...        LDir_C  \\\n",
       "0         NaN          1.0        1.0        1.0  ...    111.748897   \n",
       "1  142.279987          2.0        2.0        2.0  ...    142.279987   \n",
       "2         NaN          1.0        1.0        1.0  ...    109.965718   \n",
       "3   74.020239          3.0        3.0        1.0  ...    129.686728   \n",
       "4         NaN          0.0        0.0        0.0  ...           NaN   \n",
       "\n",
       "   NDirPulse_C  NDirStr_C      LDir_E  NDirPulse_E  NDirStr_E  RecoAngSep  \\\n",
       "0          2.0        2.0  155.811024          9.0        2.0    0.000000   \n",
       "1          7.0        3.0  186.073092         15.0        4.0    0.000553   \n",
       "2          2.0        2.0  222.568092         14.0        4.0    0.348411   \n",
       "3          6.0        2.0  174.107589         23.0        3.0    0.095909   \n",
       "4          0.0        0.0  295.763115         27.0        7.0    0.239432   \n",
       "\n",
       "      norm-rate  muon  solar  \n",
       "0  8.185846e-08     1      0  \n",
       "1  4.625277e-08     1      0  \n",
       "2  1.171941e-07     1      0  \n",
       "3  8.185290e-09     1      0  \n",
       "4  1.411252e-07     1      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = X.copy()\n",
    "data_final['muon'] = y_muon\n",
    "data_final['solar'] = y_solar\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26904767, 0.73095233],\n",
       "       [0.82212818, 0.17787182],\n",
       "       [0.27599656, 0.72400344],\n",
       "       ...,\n",
       "       [0.94968088, 0.05031912],\n",
       "       [0.93682825, 0.06317175],\n",
       "       [0.95463742, 0.04536258]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = muBDT.predict_proba(X.drop(columns='norm-rate'))\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZTravel</th>\n",
       "      <th>COGZ</th>\n",
       "      <th>COGZSigma</th>\n",
       "      <th>RLogL</th>\n",
       "      <th>RecoZenith</th>\n",
       "      <th>QTot</th>\n",
       "      <th>LDir_A</th>\n",
       "      <th>NDirPulse_A</th>\n",
       "      <th>NDirDOM_A</th>\n",
       "      <th>NDirStr_A</th>\n",
       "      <th>...</th>\n",
       "      <th>NDirPulse_C</th>\n",
       "      <th>NDirStr_C</th>\n",
       "      <th>LDir_E</th>\n",
       "      <th>NDirPulse_E</th>\n",
       "      <th>NDirStr_E</th>\n",
       "      <th>RecoAngSep</th>\n",
       "      <th>norm-rate</th>\n",
       "      <th>muon</th>\n",
       "      <th>solar</th>\n",
       "      <th>muon_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.181664</td>\n",
       "      <td>195.756485</td>\n",
       "      <td>37.022224</td>\n",
       "      <td>33.874021</td>\n",
       "      <td>2.016922</td>\n",
       "      <td>9.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.811024</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.185846e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.323990</td>\n",
       "      <td>-464.713231</td>\n",
       "      <td>33.373538</td>\n",
       "      <td>11.684740</td>\n",
       "      <td>2.099566</td>\n",
       "      <td>15.725</td>\n",
       "      <td>142.279987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.073092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>4.625277e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.034170</td>\n",
       "      <td>-466.306037</td>\n",
       "      <td>52.105987</td>\n",
       "      <td>12.071475</td>\n",
       "      <td>1.492967</td>\n",
       "      <td>12.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222.568092</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.348411</td>\n",
       "      <td>1.171941e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.293069</td>\n",
       "      <td>-462.026478</td>\n",
       "      <td>37.073835</td>\n",
       "      <td>10.617668</td>\n",
       "      <td>2.625600</td>\n",
       "      <td>19.375</td>\n",
       "      <td>74.020239</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.107589</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.095909</td>\n",
       "      <td>8.185290e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.637226</td>\n",
       "      <td>-425.194122</td>\n",
       "      <td>75.872357</td>\n",
       "      <td>10.144056</td>\n",
       "      <td>2.269713</td>\n",
       "      <td>28.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.763115</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.239432</td>\n",
       "      <td>1.411252e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZTravel        COGZ  COGZSigma      RLogL  RecoZenith    QTot  \\\n",
       "0  16.181664  195.756485  37.022224  33.874021    2.016922   9.025   \n",
       "1  30.323990 -464.713231  33.373538  11.684740    2.099566  15.725   \n",
       "2  33.034170 -466.306037  52.105987  12.071475    1.492967  12.050   \n",
       "3  30.293069 -462.026478  37.073835  10.617668    2.625600  19.375   \n",
       "4  56.637226 -425.194122  75.872357  10.144056    2.269713  28.125   \n",
       "\n",
       "       LDir_A  NDirPulse_A  NDirDOM_A  NDirStr_A    ...      NDirPulse_C  \\\n",
       "0         NaN          1.0        1.0        1.0    ...              2.0   \n",
       "1  142.279987          2.0        2.0        2.0    ...              7.0   \n",
       "2         NaN          1.0        1.0        1.0    ...              2.0   \n",
       "3   74.020239          3.0        3.0        1.0    ...              6.0   \n",
       "4         NaN          0.0        0.0        0.0    ...              0.0   \n",
       "\n",
       "   NDirStr_C      LDir_E  NDirPulse_E  NDirStr_E  RecoAngSep     norm-rate  \\\n",
       "0        2.0  155.811024          9.0        2.0    0.000000  8.185846e-08   \n",
       "1        3.0  186.073092         15.0        4.0    0.000553  4.625277e-08   \n",
       "2        2.0  222.568092         14.0        4.0    0.348411  1.171941e-07   \n",
       "3        2.0  174.107589         23.0        3.0    0.095909  8.185290e-09   \n",
       "4        0.0  295.763115         27.0        7.0    0.239432  1.411252e-07   \n",
       "\n",
       "   muon  solar  muon_prob  \n",
       "0     1      0   0.730952  \n",
       "1     1      0   0.177872  \n",
       "2     1      0   0.724003  \n",
       "3     1      0   0.867594  \n",
       "4     1      0   0.455943  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final['muon_prob'] = probs[:, 1]\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv('data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/data/user/jvillarreal/solar_atmospherics/bdt/train_index.npy', np.array(X_train.index))\n",
    "np.save('/data/user/jvillarreal/solar_atmospherics/bdt/test_index.npy', np.array(X_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
